
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>chunker: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">github.com/dan-solli/gognee/pkg/chunker/chunker.go (92.3%)</option>
				
				<option value="file1">github.com/dan-solli/gognee/pkg/embeddings/ollama.go (0.0%)</option>
				
				<option value="file2">github.com/dan-solli/gognee/pkg/embeddings/openai.go (85.4%)</option>
				
				<option value="file3">github.com/dan-solli/gognee/pkg/extraction/entities.go (100.0%)</option>
				
				<option value="file4">github.com/dan-solli/gognee/pkg/extraction/relations.go (97.7%)</option>
				
				<option value="file5">github.com/dan-solli/gognee/pkg/gognee/decay.go (100.0%)</option>
				
				<option value="file6">github.com/dan-solli/gognee/pkg/gognee/errors.go (100.0%)</option>
				
				<option value="file7">github.com/dan-solli/gognee/pkg/gognee/gognee.go (72.4%)</option>
				
				<option value="file8">github.com/dan-solli/gognee/pkg/gognee/trace.go (48.4%)</option>
				
				<option value="file9">github.com/dan-solli/gognee/pkg/llm/ollama.go (0.0%)</option>
				
				<option value="file10">github.com/dan-solli/gognee/pkg/llm/openai.go (90.6%)</option>
				
				<option value="file11">github.com/dan-solli/gognee/pkg/metrics/metrics.go (100.0%)</option>
				
				<option value="file12">github.com/dan-solli/gognee/pkg/search/decay.go (81.2%)</option>
				
				<option value="file13">github.com/dan-solli/gognee/pkg/search/graph.go (90.7%)</option>
				
				<option value="file14">github.com/dan-solli/gognee/pkg/search/hybrid.go (82.9%)</option>
				
				<option value="file15">github.com/dan-solli/gognee/pkg/search/search.go (75.0%)</option>
				
				<option value="file16">github.com/dan-solli/gognee/pkg/search/vector.go (82.4%)</option>
				
				<option value="file17">github.com/dan-solli/gognee/pkg/store/memory.go (71.6%)</option>
				
				<option value="file18">github.com/dan-solli/gognee/pkg/store/memory_vector.go (100.0%)</option>
				
				<option value="file19">github.com/dan-solli/gognee/pkg/store/sqlite.go (80.2%)</option>
				
				<option value="file20">github.com/dan-solli/gognee/pkg/store/sqlite_vec_cgo.go (50.0%)</option>
				
				<option value="file21">github.com/dan-solli/gognee/pkg/store/sqlite_vector.go (69.6%)</option>
				
				<option value="file22">github.com/dan-solli/gognee/pkg/store/tracker.go (0.0%)</option>
				
				<option value="file23">github.com/dan-solli/gognee/pkg/store/vector.go (100.0%)</option>
				
				<option value="file24">github.com/dan-solli/gognee/pkg/trace/exporter.go (64.7%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package chunker

import (
        "crypto/sha256"
        "encoding/hex"
        "fmt"
        "strings"
        "unicode"
)

// Chunk represents a single chunk of text with metadata
type Chunk struct {
        ID         string
        Text       string
        Index      int
        TokenCount int
}

// Chunker splits text into overlapping chunks with sentence boundary awareness
type Chunker struct {
        MaxTokens int // Maximum tokens per chunk (default: 512)
        Overlap   int // Token overlap between chunks (default: 50)
}

// Chunk splits the input text into chunks
func (c *Chunker) Chunk(text string) []Chunk <span class="cov8" title="1">{
        if text == "" </span><span class="cov8" title="1">{
                return []Chunk{}
        }</span>

        // Apply defaults if not set
        <span class="cov8" title="1">maxTokens := c.MaxTokens
        if maxTokens == 0 </span><span class="cov0" title="0">{
                maxTokens = 512
        }</span>
        <span class="cov8" title="1">overlap := c.Overlap
        if overlap == 0 </span><span class="cov0" title="0">{
                overlap = 50
        }</span>

        // Split text into sentences for boundary awareness
        <span class="cov8" title="1">sentences := splitSentences(text)
        if len(sentences) == 0 </span><span class="cov0" title="0">{
                return []Chunk{}
        }</span>

        <span class="cov8" title="1">var chunks []Chunk
        var currentChunk []string
        var currentTokenCount int

        for _, sentence := range sentences </span><span class="cov8" title="1">{
                sentenceTokens := countTokens(sentence)

                // If adding this sentence would exceed max tokens, finalize current chunk
                if currentTokenCount+sentenceTokens &gt; maxTokens &amp;&amp; len(currentChunk) &gt; 0 </span><span class="cov8" title="1">{
                        chunkText := strings.Join(currentChunk, " ")
                        chunks = append(chunks, Chunk{
                                ID:         generateChunkID(chunkText, len(chunks)),
                                Text:       chunkText,
                                Index:      len(chunks),
                                TokenCount: currentTokenCount,
                        })

                        // Keep overlap tokens for next chunk
                        currentChunk = getOverlapSentences(currentChunk, overlap)
                        currentTokenCount = countTokensForSentences(currentChunk)
                }</span>

                <span class="cov8" title="1">currentChunk = append(currentChunk, sentence)
                currentTokenCount += sentenceTokens</span>
        }

        // Add final chunk if there's remaining content
        <span class="cov8" title="1">if len(currentChunk) &gt; 0 </span><span class="cov8" title="1">{
                chunkText := strings.Join(currentChunk, " ")
                chunks = append(chunks, Chunk{
                        ID:         generateChunkID(chunkText, len(chunks)),
                        Text:       chunkText,
                        Index:      len(chunks),
                        TokenCount: currentTokenCount,
                })
        }</span>

        <span class="cov8" title="1">return chunks</span>
}

// splitSentences splits text into sentences based on common terminators
func splitSentences(text string) []string <span class="cov8" title="1">{
        // Simple sentence splitting on ., !, ? followed by space or end
        var sentences []string
        var current strings.Builder

        runes := []rune(text)
        for i := 0; i &lt; len(runes); i++ </span><span class="cov8" title="1">{
                current.WriteRune(runes[i])

                // Check for sentence terminators
                if runes[i] == '.' || runes[i] == '!' || runes[i] == '?' </span><span class="cov8" title="1">{
                        // Check if followed by space/end
                        if i+1 &gt;= len(runes) || unicode.IsSpace(runes[i+1]) </span><span class="cov8" title="1">{
                                sentence := strings.TrimSpace(current.String())
                                if sentence != "" </span><span class="cov8" title="1">{
                                        sentences = append(sentences, sentence)
                                }</span>
                                <span class="cov8" title="1">current.Reset()</span>
                        }
                }
        }

        // Add any remaining text
        <span class="cov8" title="1">if current.Len() &gt; 0 </span><span class="cov8" title="1">{
                sentence := strings.TrimSpace(current.String())
                if sentence != "" </span><span class="cov8" title="1">{
                        sentences = append(sentences, sentence)
                }</span>
        }

        // Fallback: if no sentences detected, treat whole text as one sentence
        <span class="cov8" title="1">if len(sentences) == 0 &amp;&amp; strings.TrimSpace(text) != "" </span><span class="cov0" title="0">{
                sentences = append(sentences, strings.TrimSpace(text))
        }</span>

        <span class="cov8" title="1">return sentences</span>
}

// countTokens estimates token count using word-based heuristic
// Note: This is an approximation. For accurate token counting, use a proper tokenizer.
func countTokens(text string) int <span class="cov8" title="1">{
        words := strings.Fields(text)
        return len(words)
}</span>

// countTokensForSentences counts total tokens for a slice of sentences
func countTokensForSentences(sentences []string) int <span class="cov8" title="1">{
        total := 0
        for _, s := range sentences </span><span class="cov8" title="1">{
                total += countTokens(s)
        }</span>
        <span class="cov8" title="1">return total</span>
}

// getOverlapSentences returns the last N tokens worth of sentences for overlap
func getOverlapSentences(sentences []string, overlapTokens int) []string <span class="cov8" title="1">{
        if overlapTokens == 0 || len(sentences) == 0 </span><span class="cov0" title="0">{
                return []string{}
        }</span>

        // Count backwards from end to get ~overlapTokens
        <span class="cov8" title="1">totalTokens := 0
        startIdx := len(sentences)

        for i := len(sentences) - 1; i &gt;= 0; i-- </span><span class="cov8" title="1">{
                tokens := countTokens(sentences[i])
                if totalTokens+tokens &gt; overlapTokens &amp;&amp; startIdx != len(sentences) </span><span class="cov8" title="1">{
                        break</span>
                }
                <span class="cov8" title="1">totalTokens += tokens
                startIdx = i</span>
        }

        <span class="cov8" title="1">return sentences[startIdx:]</span>
}

// generateChunkID creates a deterministic ID using content hash and index
func generateChunkID(text string, index int) string <span class="cov8" title="1">{
        hash := sha256.Sum256([]byte(text))
        hashStr := hex.EncodeToString(hash[:8]) // Use first 8 bytes for brevity
        return fmt.Sprintf("%s-%d", hashStr, index)
}</span>
</pre>
		
		<pre class="file" id="file1" style="display: none">// Package embeddings provides Ollama embedding client implementation
package embeddings

import (
        "bytes"
        "context"
        "encoding/json"
        "fmt"
        "io"
        "net/http"
        "time"
)

// OllamaClient implements EmbeddingClient using local Ollama API
type OllamaClient struct {
        baseURL string
        model   string
        client  *http.Client
}

// NewOllamaClient creates a new Ollama embedding client
// baseURL is typically "http://localhost:11434"
// model is the embedding model name, e.g. "nomic-embed-text"
func NewOllamaClient(baseURL, model string) *OllamaClient <span class="cov0" title="0">{
        return &amp;OllamaClient{
                baseURL: baseURL,
                model:   model,
                client: &amp;http.Client{
                        Timeout: 60 * time.Second,
                },
        }
}</span>

type ollamaEmbedRequest struct {
        Model  string `json:"model"`
        Prompt string `json:"prompt"`
}

type ollamaEmbedResponse struct {
        Embedding []float64 `json:"embedding"`
}

// EmbedOne generates an embedding for a single text
func (c *OllamaClient) EmbedOne(ctx context.Context, text string) ([]float32, error) <span class="cov0" title="0">{
        reqBody := ollamaEmbedRequest{
                Model:  c.model,
                Prompt: text,
        }

        jsonData, err := json.Marshal(reqBody)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("marshal request: %w", err)
        }</span>

        <span class="cov0" title="0">req, err := http.NewRequestWithContext(ctx, "POST", c.baseURL+"/api/embeddings", bytes.NewReader(jsonData))
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("create request: %w", err)
        }</span>
        <span class="cov0" title="0">req.Header.Set("Content-Type", "application/json")

        resp, err := c.client.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("ollama request failed: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                body, _ := io.ReadAll(resp.Body)
                return nil, fmt.Errorf("ollama returned %d: %s", resp.StatusCode, string(body))
        }</span>

        <span class="cov0" title="0">var result ollamaEmbedResponse
        if err := json.NewDecoder(resp.Body).Decode(&amp;result); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("decode response: %w", err)
        }</span>

        // Convert float64 to float32
        <span class="cov0" title="0">embedding := make([]float32, len(result.Embedding))
        for i, v := range result.Embedding </span><span class="cov0" title="0">{
                embedding[i] = float32(v)
        }</span>

        <span class="cov0" title="0">return embedding, nil</span>
}

// Embed generates embeddings for multiple texts
func (c *OllamaClient) Embed(ctx context.Context, texts []string) ([][]float32, error) <span class="cov0" title="0">{
        embeddings := make([][]float32, len(texts))
        for i, text := range texts </span><span class="cov0" title="0">{
                emb, err := c.EmbedOne(ctx, text)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("embed text %d: %w", i, err)
                }</span>
                <span class="cov0" title="0">embeddings[i] = emb</span>
        }
        <span class="cov0" title="0">return embeddings, nil</span>
}
</pre>
		
		<pre class="file" id="file2" style="display: none">package embeddings

import (
        "bytes"
        "context"
        "encoding/json"
        "fmt"
        "io"
        "net/http"
)

const (
        defaultOpenAIURL  = "https://api.openai.com/v1/embeddings"
        defaultModel      = "text-embedding-3-small"
        defaultMaxRetries = 3
)

// OpenAIClient implements EmbeddingClient using OpenAI's API
type OpenAIClient struct {
        APIKey     string
        Model      string
        BaseURL    string
        HTTPClient *http.Client
}

// NewOpenAIClient creates a new OpenAI embedding client
func NewOpenAIClient(apiKey string) *OpenAIClient <span class="cov8" title="1">{
        return &amp;OpenAIClient{
                APIKey:     apiKey,
                Model:      defaultModel,
                BaseURL:    defaultOpenAIURL,
                HTTPClient: http.DefaultClient,
        }
}</span>

type openAIRequest struct {
        Input []string `json:"input"`
        Model string   `json:"model"`
}

type openAIResponse struct {
        Data []struct {
                Embedding []float32 `json:"embedding"`
                Index     int       `json:"index"`
        } `json:"data"`
        Error *openAIError `json:"error,omitempty"`
}

type openAIError struct {
        Message string `json:"message"`
        Type    string `json:"type"`
        Code    string `json:"code"`
}

// Embed generates embeddings for multiple texts
func (c *OpenAIClient) Embed(ctx context.Context, texts []string) ([][]float32, error) <span class="cov8" title="1">{
        if len(texts) == 0 </span><span class="cov8" title="1">{
                return [][]float32{}, nil
        }</span>

        <span class="cov8" title="1">reqBody := openAIRequest{
                Input: texts,
                Model: c.Model,
        }

        bodyBytes, err := json.Marshal(reqBody)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to marshal request: %w", err)
        }</span>

        <span class="cov8" title="1">req, err := http.NewRequestWithContext(ctx, "POST", c.BaseURL, bytes.NewReader(bodyBytes))
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create request: %w", err)
        }</span>

        <span class="cov8" title="1">req.Header.Set("Content-Type", "application/json")
        req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", c.APIKey))

        resp, err := c.HTTPClient.Do(req)
        if err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("request failed: %w", err)
        }</span>
        <span class="cov8" title="1">defer resp.Body.Close()

        bodyBytes, err = io.ReadAll(resp.Body)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to read response: %w", err)
        }</span>

        <span class="cov8" title="1">if resp.StatusCode != http.StatusOK </span><span class="cov8" title="1">{
                var apiResp openAIResponse
                if err := json.Unmarshal(bodyBytes, &amp;apiResp); err == nil &amp;&amp; apiResp.Error != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("API error (%d): %s", resp.StatusCode, apiResp.Error.Message)
                }</span>
                <span class="cov8" title="1">return nil, fmt.Errorf("API error (%d): %s", resp.StatusCode, string(bodyBytes))</span>
        }

        <span class="cov8" title="1">var apiResp openAIResponse
        if err := json.Unmarshal(bodyBytes, &amp;apiResp); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to unmarshal response: %w", err)
        }</span>

        <span class="cov8" title="1">if apiResp.Error != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("API error: %s", apiResp.Error.Message)
        }</span>

        // Extract embeddings in correct order
        <span class="cov8" title="1">embeddings := make([][]float32, len(texts))
        for _, data := range apiResp.Data </span><span class="cov8" title="1">{
                if data.Index &gt;= len(embeddings) </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("invalid embedding index: %d", data.Index)
                }</span>
                <span class="cov8" title="1">embeddings[data.Index] = data.Embedding</span>
        }

        <span class="cov8" title="1">return embeddings, nil</span>
}

// EmbedOne generates an embedding for a single text
func (c *OpenAIClient) EmbedOne(ctx context.Context, text string) ([]float32, error) <span class="cov8" title="1">{
        embeddings, err := c.Embed(ctx, []string{text})
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">if len(embeddings) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no embeddings returned")
        }</span>

        <span class="cov8" title="1">return embeddings[0], nil</span>
}
</pre>
		
		<pre class="file" id="file3" style="display: none">// Package extraction provides entity and relationship extraction from text
package extraction

import (
        "context"
        "fmt"
        "log"

        "github.com/dan-solli/gognee/pkg/llm"
)

// Entity represents a named entity extracted from text
type Entity struct {
        Name        string `json:"name"`
        Type        string `json:"type"`
        Description string `json:"description"`
}

// Valid entity types from the roadmap
var validEntityTypes = map[string]bool{
        // Original 7 types
        "Person":     true,
        "Concept":    true,
        "System":     true,
        "Decision":   true,
        "Event":      true,
        "Technology": true,
        "Pattern":    true,
        // Additional 9 types (added in v1.0.1)
        "Problem":      true,
        "Goal":         true,
        "Location":     true,
        "Organization": true,
        "Document":     true,
        "Process":      true,
        "Requirement":  true,
        "Feature":      true,
        "Task":         true,
}

// entityExtractionPrompt is the prompt template for entity extraction
const entityExtractionPrompt = `You are a knowledge graph construction assistant.

Extract all meaningful entities from this text. For each entity, provide:
- name: The entity name
- type: One of [Person, Concept, System, Decision, Event, Technology, Pattern, Problem, Goal, Location, Organization, Document, Process, Requirement, Feature, Task]
- description: Brief description (1 sentence)

Text:
---
%s
---

Return ONLY valid JSON array:
[{"name": "...", "type": "...", "description": "..."}, ...]`

// EntityExtractor extracts entities from text using an LLM
type EntityExtractor struct {
        LLM llm.LLMClient
}

// NewEntityExtractor creates a new entity extractor
func NewEntityExtractor(llmClient llm.LLMClient) *EntityExtractor <span class="cov8" title="1">{
        return &amp;EntityExtractor{
                LLM: llmClient,
        }
}</span>

// Extract extracts entities from the given text
func (e *EntityExtractor) Extract(ctx context.Context, text string) ([]Entity, error) <span class="cov8" title="1">{
        if text == "" </span><span class="cov8" title="1">{
                return []Entity{}, nil
        }</span>

        <span class="cov8" title="1">prompt := fmt.Sprintf(entityExtractionPrompt, text)

        var entities []Entity
        if err := e.LLM.CompleteWithSchema(ctx, prompt, &amp;entities); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to extract entities: %w", err)
        }</span>

        // Validate entities
        <span class="cov8" title="1">for i, entity := range entities </span><span class="cov8" title="1">{
                // Check required fields
                if entity.Name == "" </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("entity at index %d has empty name", i)
                }</span>
                <span class="cov8" title="1">if entity.Type == "" </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("entity at index %d (%s) has empty type", i, entity.Name)
                }</span>
                <span class="cov8" title="1">if entity.Description == "" </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("entity at index %d (%s) has empty description", i, entity.Name)
                }</span>

                // Normalize unknown types to Concept with warning
                <span class="cov8" title="1">if !validEntityTypes[entity.Type] </span><span class="cov8" title="1">{
                        log.Printf("gognee: entity %q has unrecognized type %q, normalizing to Concept", entity.Name, entity.Type)
                        entities[i].Type = "Concept"
                }</span>
        }

        <span class="cov8" title="1">return entities, nil</span>
}
</pre>
		
		<pre class="file" id="file4" style="display: none">package extraction

import (
        "context"
        "fmt"
        "strings"

        "github.com/dan-solli/gognee/pkg/llm"
)

// Triplet represents a relationship between two entities
type Triplet struct {
        Subject  string `json:"subject"`
        Relation string `json:"relation"`
        Object   string `json:"object"`
}

// relationExtractionPrompt is the prompt template for relationship extraction
const relationExtractionPrompt = `You are a knowledge graph construction assistant.

Given this text and the entities already extracted, identify relationships between them.
Express each relationship as a triplet: (subject, relation, object)

IMPORTANT: Use ONLY entity names from the "Known entities" list below. Do not create new entities or use partial names.

Use clear, consistent relation names like:
- USES, DEPENDS_ON, CREATED_BY, CONTAINS, IS_A, RELATES_TO, MENTIONS

Text:
---
%s
---

Known entities: %s

Return ONLY valid JSON array where subject and object are exact matches from the Known entities list:
[{"subject": "...", "relation": "...", "object": "..."}, ...]`

// RelationExtractor extracts relationships between entities from text using an LLM
type RelationExtractor struct {
        LLM llm.LLMClient
}

// NewRelationExtractor creates a new relation extractor
func NewRelationExtractor(llmClient llm.LLMClient) *RelationExtractor <span class="cov8" title="1">{
        return &amp;RelationExtractor{
                LLM: llmClient,
        }
}</span>

// Extract extracts relationships from the given text using the provided entities
func (r *RelationExtractor) Extract(ctx context.Context, text string, entities []Entity) ([]Triplet, error) <span class="cov8" title="1">{
        // Return empty result for empty text or no entities
        if text == "" || len(entities) == 0 </span><span class="cov8" title="1">{
                return []Triplet{}, nil
        }</span>

        // Build entity names list for the prompt
        <span class="cov8" title="1">entityNames := buildEntityNamesList(entities)

        // Build the prompt
        prompt := fmt.Sprintf(relationExtractionPrompt, text, entityNames)

        // Call the LLM
        var triplets []Triplet
        if err := r.LLM.CompleteWithSchema(ctx, prompt, &amp;triplets); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to extract relationships: %w", err)
        }</span>

        // Build entity lookup map for case-insensitive matching
        <span class="cov8" title="1">entityLookup := buildEntityLookup(entities)

        // Validate and process triplets
        validatedTriplets, err := validateAndProcessTriplets(triplets, entityLookup)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Deduplicate triplets
        <span class="cov8" title="1">result := deduplicateTriplets(validatedTriplets)

        return result, nil</span>
}

// buildEntityNamesList creates a comma-separated list of entity names for the prompt
func buildEntityNamesList(entities []Entity) string <span class="cov8" title="1">{
        names := make([]string, len(entities))
        for i, entity := range entities </span><span class="cov8" title="1">{
                names[i] = entity.Name
        }</span>
        <span class="cov8" title="1">return strings.Join(names, ", ")</span>
}

// buildEntityLookup creates a case-insensitive lookup map of entity names
func buildEntityLookup(entities []Entity) map[string]bool <span class="cov8" title="1">{
        lookup := make(map[string]bool)
        for _, entity := range entities </span><span class="cov8" title="1">{
                // Store lowercase version for case-insensitive matching
                lookup[strings.ToLower(strings.TrimSpace(entity.Name))] = true
        }</span>
        <span class="cov8" title="1">return lookup</span>
}

// validateAndProcessTriplets validates each triplet and ensures linking to known entities
// Invalid triplets are filtered out rather than causing the entire extraction to fail
func validateAndProcessTriplets(triplets []Triplet, entityLookup map[string]bool) ([]Triplet, error) <span class="cov8" title="1">{
        result := make([]Triplet, 0, len(triplets))

        for _, triplet := range triplets </span><span class="cov8" title="1">{
                // Trim whitespace
                subject := strings.TrimSpace(triplet.Subject)
                relation := strings.TrimSpace(triplet.Relation)
                object := strings.TrimSpace(triplet.Object)

                // Skip triplets with empty fields
                if subject == "" || relation == "" || object == "" </span><span class="cov8" title="1">{
                        continue</span>
                }

                // Filter mode: skip triplets referencing unknown entities (case-insensitive)
                <span class="cov8" title="1">if !entityLookup[strings.ToLower(subject)] </span><span class="cov8" title="1">{
                        continue</span>
                }

                <span class="cov8" title="1">if !entityLookup[strings.ToLower(object)] </span><span class="cov8" title="1">{
                        continue</span>
                }

                // Add validated and trimmed triplet
                <span class="cov8" title="1">result = append(result, Triplet{
                        Subject:  subject,
                        Relation: relation,
                        Object:   object,
                })</span>
        }

        <span class="cov8" title="1">return result, nil</span>
}

// deduplicateTriplets removes duplicate triplets, preserving first occurrence order
// Comparison is case-insensitive for subject and object (matching entity linking behavior)
func deduplicateTriplets(triplets []Triplet) []Triplet <span class="cov8" title="1">{
        seen := make(map[string]bool)
        result := make([]Triplet, 0, len(triplets))

        for _, triplet := range triplets </span><span class="cov8" title="1">{
                // Create a normalized key for comparison (case-insensitive)
                key := strings.ToLower(triplet.Subject) + "|" +
                        strings.ToLower(triplet.Relation) + "|" +
                        strings.ToLower(triplet.Object)

                if !seen[key] </span><span class="cov8" title="1">{
                        seen[key] = true
                        result = append(result, triplet)
                }</span>
        }

        <span class="cov8" title="1">return result</span>
}
</pre>
		
		<pre class="file" id="file5" style="display: none">package gognee

import (
        "math"
        "time"
)

// calculateDecay computes the exponential decay multiplier for a node based on its age.
// Uses the formula: score_multiplier = 0.5^(age_days / half_life_days)
//
// Parameters:
//   - nodeAge: The age of the node (time since creation or last access)
//   - halfLifeDays: The number of days after which the score is halved
//
// Returns:
//   - A multiplier between 0 and 1 to apply to the node's search score
//   - Returns 1.0 for negative ages (defensive)
//   - Returns 1.0 for zero half-life (defensive)
func calculateDecay(nodeAge time.Duration, halfLifeDays int) float64 <span class="cov8" title="1">{
        // Handle edge cases
        if nodeAge &lt; 0 </span><span class="cov8" title="1">{
                return 1.0 // No decay for negative age (shouldn't happen but be defensive)
        }</span>
        <span class="cov8" title="1">if halfLifeDays &lt;= 0 </span><span class="cov8" title="1">{
                return 1.0 // No decay for zero/negative half-life
        }</span>

        // Convert nodeAge to days (float64 for precision)
        <span class="cov8" title="1">ageDays := nodeAge.Hours() / 24.0

        // Apply exponential decay formula: 0.5^(age_days / half_life_days)
        exponent := ageDays / float64(halfLifeDays)
        multiplier := math.Pow(0.5, exponent)

        return multiplier</span>
}
</pre>
		
		<pre class="file" id="file6" style="display: none">package gognee

import (
        "context"
        "errors"
        "net"
        "strings"
)

// Error type constants for classification
const (
        ErrTypeNetwork    = "network"
        ErrTypeTimeout    = "timeout"
        ErrTypeLLM        = "llm"
        ErrTypeDatabase   = "database"
        ErrTypeValidation = "validation"
        ErrTypeUnknown    = "unknown"
)

// ClassifyError inspects an error and returns its type classification.
// This enables grouping errors by category in metrics and traces.
func ClassifyError(err error) string <span class="cov8" title="1">{
        if err == nil </span><span class="cov8" title="1">{
                return ""
        }</span>

        <span class="cov8" title="1">errStr := err.Error()
        errStrLower := strings.ToLower(errStr)

        // Check for timeout errors
        if errors.Is(err, context.DeadlineExceeded) || strings.Contains(errStrLower, "timeout") || strings.Contains(errStrLower, "deadline exceeded") </span><span class="cov8" title="1">{
                return ErrTypeTimeout
        }</span>

        // Check for network errors
        <span class="cov8" title="1">var netErr *net.OpError
        if errors.As(err, &amp;netErr) </span><span class="cov8" title="1">{
                return ErrTypeNetwork
        }</span>
        <span class="cov8" title="1">if strings.Contains(errStrLower, "connection refused") ||
                strings.Contains(errStrLower, "connection reset") ||
                strings.Contains(errStrLower, "no such host") ||
                strings.Contains(errStrLower, "network is unreachable") ||
                strings.Contains(errStrLower, "dial tcp") ||
                strings.Contains(errStrLower, "eof") </span><span class="cov8" title="1">{
                return ErrTypeNetwork
        }</span>

        // Check for LLM/API errors (OpenAI specific)
        <span class="cov8" title="1">if strings.Contains(errStrLower, "api error") ||
                strings.Contains(errStrLower, "rate limit") ||
                strings.Contains(errStrLower, "invalid response") ||
                strings.Contains(errStrLower, "embedding") ||
                strings.Contains(errStrLower, "openai") ||
                strings.Contains(errStrLower, "model") &amp;&amp; strings.Contains(errStrLower, "not found") </span><span class="cov8" title="1">{
                return ErrTypeLLM
        }</span>

        // Check for database errors (SQLite specific)
        <span class="cov8" title="1">if strings.Contains(errStrLower, "sql") ||
                strings.Contains(errStrLower, "database") ||
                strings.Contains(errStrLower, "constraint") ||
                strings.Contains(errStrLower, "unique") &amp;&amp; strings.Contains(errStrLower, "failed") </span><span class="cov8" title="1">{
                return ErrTypeDatabase
        }</span>

        // Check for validation errors
        <span class="cov8" title="1">if strings.Contains(errStrLower, "validation") ||
                strings.Contains(errStrLower, "invalid") ||
                strings.Contains(errStrLower, "required") ||
                strings.Contains(errStrLower, "cannot be empty") ||
                strings.Contains(errStrLower, "must be") </span><span class="cov8" title="1">{
                return ErrTypeValidation
        }</span>

        // Default to unknown
        <span class="cov8" title="1">return ErrTypeUnknown</span>
}
</pre>
		
		<pre class="file" id="file7" style="display: none">// Package gognee provides a knowledge graph memory system for AI assistants
package gognee

import (
        "context"
        "crypto/sha256"
        "database/sql"
        "fmt"
        "strings"
        "time"

        "github.com/dan-solli/gognee/pkg/chunker"
        "github.com/dan-solli/gognee/pkg/embeddings"
        "github.com/dan-solli/gognee/pkg/extraction"
        "github.com/dan-solli/gognee/pkg/llm"
        "github.com/dan-solli/gognee/pkg/metrics"
        "github.com/dan-solli/gognee/pkg/search"
        "github.com/dan-solli/gognee/pkg/store"
        tracepkg "github.com/dan-solli/gognee/pkg/trace"
        "github.com/google/uuid"
)

// Config holds configuration for the Gognee system
type Config struct {
        // OpenAI API key for embeddings and LLM
        OpenAIKey string

        // Embedding model (default: "text-embedding-3-small")
        EmbeddingModel string

        // LLM model for entity extraction (default: "gpt-4o-mini")
        LLMModel string

        // Chunk size in tokens (default: 512)
        ChunkSize int

        // Chunk overlap in tokens (default: 50)
        ChunkOverlap int

        // DBPath is the path to the SQLite database file.
        // If empty or ":memory:", an in-memory database is used.
        DBPath string

        // DecayEnabled enables time-based memory decay scoring (default: false)
        DecayEnabled bool

        // DecayHalfLifeDays is the number of days after which a node's score is halved (default: 30)
        DecayHalfLifeDays int

        // DecayBasis determines decay calculation: "access" (last access time) or "creation" (creation time)
        // Default: "access"
        DecayBasis string
}

// Gognee is the main entry point for the memory system
type Gognee struct {
        config            Config
        chunker           *chunker.Chunker
        embeddings        embeddings.EmbeddingClient
        llm               llm.LLMClient
        graphStore        store.GraphStore
        vectorStore       store.VectorStore
        memoryStore       *store.SQLiteMemoryStore
        searcher          search.Searcher
        entityExtractor   *extraction.EntityExtractor
        relationExtractor *extraction.RelationExtractor
        buffer            []AddedDocument
        lastCognified     time.Time
        metricsCollector  metrics.Collector // Optional metrics collector
        traceExporter     tracepkg.Exporter // Optional trace exporter (Plan 016 M4)
}

// AddedDocument represents a document added to the buffer for processing
type AddedDocument struct {
        Text    string
        Source  string
        AddedAt time.Time
}

// AddOptions configures the Add() method
type AddOptions struct {
        Source string
}

// CognifyOptions configures the Cognify() method
type CognifyOptions struct {
        // SkipProcessed enables incremental mode, skipping previously processed documents.
        // Default: true (incremental by default). Use pointer to distinguish unset from explicit false.
        // When true, documents are identified by content hash (SHA-256).
        // Documents with matching hash are skipped unless Force is true.
        SkipProcessed *bool

        // Force reprocesses all documents regardless of cached state.
        // Overrides SkipProcessed when true.
        // Use after changing chunker settings or to rebuild the knowledge graph.
        Force bool

        // TraceEnabled enables detailed timing instrumentation for performance analysis.
        // Default: false (off by default to minimize overhead).
        // When enabled, timing spans are collected and returned in CognifyResult.Trace.
        TraceEnabled bool
}

// CognifyResult reports the outcome of a Cognify() operation
type CognifyResult struct {
        DocumentsProcessed int // Documents actually processed (chunked + extracted)
        DocumentsSkipped   int // Documents skipped due to incremental caching
        ChunksProcessed    int
        ChunksFailed       int
        NodesCreated       int
        EdgesCreated       int
        EdgesSkipped       int             // Count of edges skipped due to entity lookup failure or ambiguity
        Errors             []error         // Includes details of skipped edges ("skipped edge" in message)
        Trace              *OperationTrace // Timing data (populated when CognifyOptions.TraceEnabled is true)
}

// SearchResponse wraps search results with optional timing trace
type SearchResponse struct {
        Results []search.SearchResult // The search results
        Trace   *OperationTrace       // Timing data (populated when SearchOptions.TraceEnabled is true)
}

// Stats reports basic telemetry about the knowledge graph
type Stats struct {
        NodeCount     int64
        EdgeCount     int64
        MemoryCount   int64
        BufferedDocs  int
        LastCognified time.Time
}

// PruneOptions configures the Prune() method
type PruneOptions struct {
        // MaxAgeDays prunes nodes older than this many days (based on decay basis).
        // If zero, this criterion is not used.
        MaxAgeDays int

        // MinDecayScore prunes nodes with decay score below this threshold.
        // If zero, this criterion is not used.
        // Score is calculated using current decay settings.
        MinDecayScore float64

        // DryRun reports what would be pruned without actually deleting.
        DryRun bool
}

// PruneResult reports the outcome of a Prune() operation
type PruneResult struct {
        NodesEvaluated int      // Total number of nodes considered
        NodesPruned    int      // Number of nodes deleted
        EdgesPruned    int      // Number of edges deleted (via cascade)
        NodeIDs        []string // IDs of pruned nodes (for verification)
}

// New creates a new Gognee instance using OpenAI clients
func New(cfg Config) (*Gognee, error) <span class="cov8" title="1">{
        // Initialize embeddings client
        embeddingsClient := embeddings.NewOpenAIClient(cfg.OpenAIKey)
        if cfg.EmbeddingModel != "" </span><span class="cov8" title="1">{
                embeddingsClient.Model = cfg.EmbeddingModel
        }</span>

        // Initialize LLM client
        <span class="cov8" title="1">llmClient := llm.NewOpenAILLM(cfg.OpenAIKey)
        if cfg.LLMModel != "" </span><span class="cov8" title="1">{
                llmClient.Model = cfg.LLMModel
        }</span>

        <span class="cov8" title="1">return NewWithClients(cfg, embeddingsClient, llmClient)</span>
}

// NewWithClients creates a new Gognee instance with custom embedding and LLM clients.
// This allows using alternative providers like Ollama for local inference.
func NewWithClients(cfg Config, embClient embeddings.EmbeddingClient, llmClient llm.LLMClient) (*Gognee, error) <span class="cov8" title="1">{
        // Apply defaults
        if cfg.ChunkSize == 0 </span><span class="cov8" title="1">{
                cfg.ChunkSize = 512
        }</span>
        <span class="cov8" title="1">if cfg.ChunkOverlap == 0 </span><span class="cov8" title="1">{
                cfg.ChunkOverlap = 50
        }</span>
        <span class="cov8" title="1">if cfg.DecayBasis == "" </span><span class="cov8" title="1">{
                cfg.DecayBasis = "access"
        }</span>

        // Validate decay configuration (before applying half-life default)
        <span class="cov8" title="1">if cfg.DecayEnabled </span><span class="cov8" title="1">{
                if cfg.DecayHalfLifeDays &lt; 0 </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("DecayHalfLifeDays must be positive, got %d", cfg.DecayHalfLifeDays)
                }</span>
                <span class="cov8" title="1">if cfg.DecayBasis != "access" &amp;&amp; cfg.DecayBasis != "creation" </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("DecayBasis must be 'access' or 'creation', got %q", cfg.DecayBasis)
                }</span>
        }

        // Apply half-life default after validation
        <span class="cov8" title="1">if cfg.DecayHalfLifeDays == 0 </span><span class="cov8" title="1">{
                cfg.DecayHalfLifeDays = 30
        }</span>

        // Initialize GraphStore
        <span class="cov8" title="1">dbPath := cfg.DBPath
        if dbPath == "" </span><span class="cov8" title="1">{
                dbPath = ":memory:"
        }</span>
        <span class="cov8" title="1">graphStore, err := store.NewSQLiteGraphStore(dbPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to initialize graph store: %w", err)
        }</span>

        // Initialize VectorStore
        // Use SQLiteVectorStore for persistent databases, MemoryVectorStore for :memory:
        <span class="cov8" title="1">var vectorStore store.VectorStore
        if dbPath == ":memory:" </span><span class="cov8" title="1">{
                vectorStore = store.NewMemoryVectorStore()
        }</span> else<span class="cov0" title="0"> {
                // Share the database connection from GraphStore
                vectorStore = store.NewSQLiteVectorStore(graphStore.DB())
        }</span>

        // Initialize extractors
        <span class="cov8" title="1">entityExtractor := extraction.NewEntityExtractor(llmClient)
        relationExtractor := extraction.NewRelationExtractor(llmClient)

        // Initialize searcher
        baseSearcher := search.NewHybridSearcher(embClient, vectorStore, graphStore)

        // Wrap with DecayingSearcher if decay is enabled
        var searcher search.Searcher
        if cfg.DecayEnabled </span><span class="cov8" title="1">{
                searcher = search.NewDecayingSearcher(baseSearcher, graphStore, cfg.DecayEnabled, cfg.DecayHalfLifeDays, cfg.DecayBasis)
        }</span> else<span class="cov8" title="1"> {
                searcher = baseSearcher
        }</span>

        // Initialize MemoryStore (shares DB connection with GraphStore)
        <span class="cov8" title="1">memoryStore := store.NewSQLiteMemoryStore(graphStore.DB())

        // Initialize chunker
        c := &amp;chunker.Chunker{
                MaxTokens: cfg.ChunkSize,
                Overlap:   cfg.ChunkOverlap,
        }

        return &amp;Gognee{
                config:            cfg,
                chunker:           c,
                embeddings:        embClient,
                llm:               llmClient,
                graphStore:        graphStore,
                vectorStore:       vectorStore,
                memoryStore:       memoryStore,
                searcher:          searcher,
                entityExtractor:   entityExtractor,
                relationExtractor: relationExtractor,
                buffer:            make([]AddedDocument, 0),
                lastCognified:     time.Time{},
                metricsCollector:  nil, // Set via WithMetricsCollector
                traceExporter:     nil, // Set via WithTraceExporter (Plan 016 M4)
        }, nil</span>
}

// WithMetricsCollector sets the metrics collector for this Gognee instance
func (g *Gognee) WithMetricsCollector(collector metrics.Collector) *Gognee <span class="cov0" title="0">{
        g.metricsCollector = collector
        return g
}</span>

// WithTraceExporter sets the trace exporter for this Gognee instance (Plan 016 M4)
func (g *Gognee) WithTraceExporter(exporter tracepkg.Exporter) *Gognee <span class="cov0" title="0">{
        g.traceExporter = exporter
        return g
}</span>

// GetChunker returns the configured chunker
func (g *Gognee) GetChunker() *chunker.Chunker <span class="cov8" title="1">{
        return g.chunker
}</span>

// GetEmbeddings returns the configured embeddings client
func (g *Gognee) GetEmbeddings() embeddings.EmbeddingClient <span class="cov8" title="1">{
        return g.embeddings
}</span>

// GetLLM returns the configured LLM client
func (g *Gognee) GetLLM() llm.LLMClient <span class="cov8" title="1">{
        return g.llm
}</span>

// GetGraphStore returns the configured graph store
func (g *Gognee) GetGraphStore() store.GraphStore <span class="cov8" title="1">{
        return g.graphStore
}</span>

// GetVectorStore returns the configured vector store
func (g *Gognee) GetVectorStore() store.VectorStore <span class="cov8" title="1">{
        return g.vectorStore
}</span>

// normalizeEntityName applies normalization for entity lookup matching.
// Normalization: ToLower() + TrimSpace() + collapse internal whitespace
func normalizeEntityName(name string) string <span class="cov8" title="1">{
        // Trim leading/trailing whitespace
        normalized := strings.TrimSpace(name)
        // Convert to lowercase for case-insensitive matching
        normalized = strings.ToLower(normalized)
        // Collapse internal whitespace
        fields := strings.Fields(normalized)
        return strings.Join(fields, " ")
}</span>

// buildEntityTypeMap creates a map from normalized entity names to their types.
// Returns the map and a set of ambiguous names (names that map to multiple types).
func buildEntityTypeMap(entities []extraction.Entity) (map[string]string, map[string]bool) <span class="cov8" title="1">{
        entityMap := make(map[string]string)
        typeCounts := make(map[string]map[string]bool) // normalized name -&gt; set of types

        for _, entity := range entities </span><span class="cov8" title="1">{
                normalized := normalizeEntityName(entity.Name)
                if normalized == "" </span><span class="cov0" title="0">{
                        continue</span> // Skip empty names
                }

                // Track all types seen for this normalized name
                <span class="cov8" title="1">if typeCounts[normalized] == nil </span><span class="cov8" title="1">{
                        typeCounts[normalized] = make(map[string]bool)
                }</span>
                <span class="cov8" title="1">typeCounts[normalized][entity.Type] = true</span>
        }

        // Build entity map, marking ambiguous names
        <span class="cov8" title="1">ambiguous := make(map[string]bool)
        for normalized, types := range typeCounts </span><span class="cov8" title="1">{
                if len(types) &gt; 1 </span><span class="cov8" title="1">{
                        // Multiple types for same name = ambiguous
                        ambiguous[normalized] = true
                }</span> else<span class="cov8" title="1"> {
                        // Single type - safe to use
                        for typ := range types </span><span class="cov8" title="1">{
                                entityMap[normalized] = typ
                                break</span>
                        }
                }
        }

        <span class="cov8" title="1">return entityMap, ambiguous</span>
}

// lookupEntityType looks up the entity type by name using the entity map.
// Returns empty string if not found or ambiguous.
func lookupEntityType(name string, entityMap map[string]string, ambiguous map[string]bool) (string, bool) <span class="cov8" title="1">{
        normalized := normalizeEntityName(name)

        if ambiguous[normalized] </span><span class="cov8" title="1">{
                return "", false // Ambiguous - multiple types
        }</span>

        <span class="cov8" title="1">typ, found := entityMap[normalized]
        return typ, found</span>
}

// Add buffers text for processing via Cognify()
func (g *Gognee) Add(ctx context.Context, text string, opts AddOptions) error <span class="cov8" title="1">{
        if strings.TrimSpace(text) == "" </span><span class="cov8" title="1">{
                return fmt.Errorf("text cannot be empty")
        }</span>

        <span class="cov8" title="1">doc := AddedDocument{
                Text:    text,
                Source:  opts.Source,
                AddedAt: time.Now(),
        }
        g.buffer = append(g.buffer, doc)
        return nil</span>
}

// BufferedCount returns the number of documents currently in the buffer
func (g *Gognee) BufferedCount() int <span class="cov8" title="1">{
        return len(g.buffer)
}</span>

// Cognify processes all buffered documents through the extraction pipeline
func (g *Gognee) Cognify(ctx context.Context, opts CognifyOptions) (*CognifyResult, error) <span class="cov8" title="1">{
        startTime := time.Now()
        operationID := uuid.New().String() // Generate operation ID for trace correlation

        result := &amp;CognifyResult{
                Errors: make([]error, 0),
        }

        // Initialize trace if enabled
        var trace *OperationTrace
        if opts.TraceEnabled </span><span class="cov0" title="0">{
                trace = newTrace()
                result.Trace = trace
        }</span>

        // No-op if buffer is empty
        <span class="cov8" title="1">if len(g.buffer) == 0 </span><span class="cov8" title="1">{
                return result, nil
        }</span>

        // Apply default for SkipProcessed (incremental by default)
        <span class="cov8" title="1">skipProcessed := true
        if opts.SkipProcessed != nil </span><span class="cov0" title="0">{
                skipProcessed = *opts.SkipProcessed
        }</span>

        // Try to get DocumentTracker interface from graphStore (optional)
        // If not available, incremental mode is disabled
        <span class="cov8" title="1">tracker, _ := g.graphStore.(store.DocumentTracker)

        // Process each document
        for _, doc := range g.buffer </span><span class="cov8" title="1">{
                // Compute document hash for identity
                hash := computeDocumentHash(doc.Text)

                // Check if document is already processed (incremental mode)
                // Only if tracker is available and incremental mode is enabled
                if tracker != nil &amp;&amp; skipProcessed &amp;&amp; !opts.Force </span><span class="cov8" title="1">{
                        processed, err := tracker.IsDocumentProcessed(ctx, hash)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("failed to check document processed status: %w", err)
                        }</span>

                        <span class="cov8" title="1">if processed </span><span class="cov0" title="0">{
                                result.DocumentsSkipped++
                                continue</span> // Skip this document
                        }
                }

                // Track chunks for this document
                <span class="cov8" title="1">docChunkCount := 0
                result.DocumentsProcessed++

                // Chunk the text
                chunkTimer := newSpanTimer("chunk", trace, opts.TraceEnabled)
                chunks := g.chunker.Chunk(doc.Text)
                chunkTimer.finish(true, nil, map[string]int64{"chunkCount": int64(len(chunks))})

                // Process each chunk
                for _, chunk := range chunks </span><span class="cov8" title="1">{
                        result.ChunksProcessed++
                        docChunkCount++

                        // Extract entities
                        extractTimer := newSpanTimer("extract", trace, opts.TraceEnabled)
                        entities, err := g.entityExtractor.Extract(ctx, chunk.Text)
                        if err != nil </span><span class="cov8" title="1">{
                                extractTimer.finish(false, err, nil)
                                result.ChunksFailed++
                                result.Errors = append(result.Errors, fmt.Errorf("entity extraction failed for chunk %s: %w", chunk.ID, err))
                                continue</span>
                        }

                        // Build entity name-&gt;type lookup map before processing triplets
                        <span class="cov8" title="1">entityMap, ambiguous := buildEntityTypeMap(entities)

                        // Extract relations
                        triplets, err := g.relationExtractor.Extract(ctx, chunk.Text, entities)
                        if err != nil </span><span class="cov0" title="0">{
                                extractTimer.finish(false, err, nil)
                                result.ChunksFailed++
                                result.Errors = append(result.Errors, fmt.Errorf("relation extraction failed for chunk %s: %w", chunk.ID, err))
                                // Continue with entities only if relations fail
                        }</span> else<span class="cov8" title="1"> {
                                extractTimer.finish(true, nil, map[string]int64{
                                        "entityCount":   int64(len(entities)),
                                        "relationCount": int64(len(triplets)),
                                })
                        }</span>

                        // Create nodes for each entity
                        <span class="cov8" title="1">graphWriteTimer := newSpanTimer("write-graph", trace, opts.TraceEnabled)
                        embedTimer := newSpanTimer("embed", trace, opts.TraceEnabled)
                        vectorWriteTimer := newSpanTimer("write-vector", trace, opts.TraceEnabled)

                        // Collect all entity texts for batch embedding (Plan 019: M1)
                        var textsToEmbed []string
                        var entityIndices []int
                        for i, entity := range entities </span><span class="cov8" title="1">{
                                text := strings.TrimSpace(entity.Name + " " + entity.Description)
                                if text != "" </span><span class="cov8" title="1">{
                                        textsToEmbed = append(textsToEmbed, text)
                                        entityIndices = append(entityIndices, i)
                                }</span>
                        }

                        // Batch embed all entities in single API call (Plan 019: M2)
                        <span class="cov8" title="1">var embeddings [][]float32
                        var embedErr error
                        if len(textsToEmbed) &gt; 0 </span><span class="cov8" title="1">{
                                embeddings, embedErr = g.embeddings.Embed(ctx, textsToEmbed)
                                if embedErr != nil </span><span class="cov8" title="1">{
                                        embedTimer.finish(false, embedErr, nil)
                                        result.ChunksFailed++
                                        result.Errors = append(result.Errors, fmt.Errorf("batch embedding failed for chunk %s: %w", chunk.ID, embedErr))
                                        // Continue without embeddings - nodes will be created but not indexed
                                }</span> else<span class="cov8" title="1"> {
                                        embedTimer.finish(true, nil, map[string]int64{"embeddingCount": int64(len(embeddings))})
                                }</span>
                        }

                        // Create nodes and assign embeddings (Plan 019: M3)
                        <span class="cov8" title="1">nodesAdded := 0
                        for i, entity := range entities </span><span class="cov8" title="1">{
                                nodeID := generateDeterministicNodeID(entity.Name, entity.Type)
                                node := &amp;store.Node{
                                        ID:          nodeID,
                                        Name:        entity.Name,
                                        Type:        entity.Type,
                                        Description: entity.Description,
                                        CreatedAt:   time.Now(),
                                        Metadata:    make(map[string]interface{}),
                                }

                                // Add to graph store
                                if err := g.graphStore.AddNode(ctx, node); err != nil </span><span class="cov8" title="1">{
                                        result.Errors = append(result.Errors, fmt.Errorf("failed to add node %s: %w", entity.Name, err))
                                        continue</span>
                                }
                                <span class="cov8" title="1">result.NodesCreated++
                                nodesAdded++

                                // Find embedding for this entity from batch results
                                var embedding []float32
                                if embedErr == nil </span><span class="cov8" title="1">{
                                        // Find index in entityIndices that corresponds to this entity
                                        for j, entityIdx := range entityIndices </span><span class="cov8" title="1">{
                                                if entityIdx == i &amp;&amp; j &lt; len(embeddings) </span><span class="cov8" title="1">{
                                                        embedding = embeddings[j]
                                                        break</span>
                                                }
                                        }
                                }

                                // Update node with embedding if available
                                <span class="cov8" title="1">if embedding != nil </span><span class="cov8" title="1">{
                                        node.Embedding = embedding
                                        if err := g.graphStore.AddNode(ctx, node); err != nil </span><span class="cov0" title="0">{
                                                result.Errors = append(result.Errors, fmt.Errorf("failed to update node embedding %s: %w", entity.Name, err))
                                                continue</span>
                                        }

                                        // Index in vector store
                                        <span class="cov8" title="1">if err := g.vectorStore.Add(ctx, nodeID, embedding); err != nil </span><span class="cov8" title="1">{
                                                result.Errors = append(result.Errors, fmt.Errorf("failed to index node %s in vector store: %w", entity.Name, err))
                                        }</span>
                                }
                        }

                        <span class="cov8" title="1">vectorWriteTimer.finish(true, nil, map[string]int64{"nodeUpserts": int64(nodesAdded)})

                        // Create edges for each triplet
                        edgesAdded := 0
                        for _, triplet := range triplets </span><span class="cov8" title="1">{
                                // Look up source entity type
                                sourceType, sourceFound := lookupEntityType(triplet.Subject, entityMap, ambiguous)
                                if !sourceFound </span><span class="cov0" title="0">{
                                        result.EdgesSkipped++
                                        if ambiguous[normalizeEntityName(triplet.Subject)] </span><span class="cov0" title="0">{
                                                result.Errors = append(result.Errors, fmt.Errorf("skipped edge %s-%s-%s: subject '%s' is ambiguous (multiple types)",
                                                        triplet.Subject, triplet.Relation, triplet.Object, triplet.Subject))
                                        }</span> else<span class="cov0" title="0"> {
                                                result.Errors = append(result.Errors, fmt.Errorf("skipped edge %s-%s-%s: subject '%s' not found in extracted entities",
                                                        triplet.Subject, triplet.Relation, triplet.Object, triplet.Subject))
                                        }</span>
                                        <span class="cov0" title="0">continue</span>
                                }

                                // Look up target entity type
                                <span class="cov8" title="1">targetType, targetFound := lookupEntityType(triplet.Object, entityMap, ambiguous)
                                if !targetFound </span><span class="cov8" title="1">{
                                        result.EdgesSkipped++
                                        if ambiguous[normalizeEntityName(triplet.Object)] </span><span class="cov8" title="1">{
                                                result.Errors = append(result.Errors, fmt.Errorf("skipped edge %s-%s-%s: object '%s' is ambiguous (multiple types)",
                                                        triplet.Subject, triplet.Relation, triplet.Object, triplet.Object))
                                        }</span> else<span class="cov0" title="0"> {
                                                result.Errors = append(result.Errors, fmt.Errorf("skipped edge %s-%s-%s: object '%s' not found in extracted entities",
                                                        triplet.Subject, triplet.Relation, triplet.Object, triplet.Object))
                                        }</span>
                                        <span class="cov8" title="1">continue</span>
                                }

                                // Generate edge IDs using correct entity types (FIX: was using empty string)
                                <span class="cov8" title="1">sourceID := generateDeterministicNodeID(triplet.Subject, sourceType)
                                targetID := generateDeterministicNodeID(triplet.Object, targetType)

                                edge := &amp;store.Edge{
                                        ID:        fmt.Sprintf("%s-%s-%s", sourceID, sanitizeRelation(triplet.Relation), targetID),
                                        SourceID:  sourceID,
                                        Relation:  triplet.Relation,
                                        TargetID:  targetID,
                                        Weight:    1.0,
                                        CreatedAt: time.Now(),
                                }

                                if err := g.graphStore.AddEdge(ctx, edge); err != nil </span><span class="cov8" title="1">{
                                        result.Errors = append(result.Errors, fmt.Errorf("failed to add edge %s-%s-%s: %w", triplet.Subject, triplet.Relation, triplet.Object, err))
                                        continue</span>
                                }
                                <span class="cov8" title="1">result.EdgesCreated++
                                edgesAdded++</span>
                        }

                        <span class="cov8" title="1">graphWriteTimer.finish(true, nil, map[string]int64{
                                "nodeUpserts": int64(nodesAdded),
                                "edgeUpserts": int64(edgesAdded),
                        })</span>
                }

                // Mark document as processed after successful processing (if tracker available)
                <span class="cov8" title="1">if tracker != nil </span><span class="cov8" title="1">{
                        if err := tracker.MarkDocumentProcessed(ctx, hash, doc.Source, docChunkCount); err != nil </span><span class="cov0" title="0">{
                                // Log but don't fail - tracking failure shouldn't break Cognify
                                result.Errors = append(result.Errors, fmt.Errorf("failed to mark document as processed: %w", err))
                        }</span>
                }
        }

        // Always clear buffer after processing (best-effort semantics)
        <span class="cov8" title="1">g.buffer = make([]AddedDocument, 0)
        g.lastCognified = time.Now()

        // Record metrics if collector is available
        if g.metricsCollector != nil </span><span class="cov0" title="0">{
                durationMs := time.Since(startTime).Milliseconds()
                status := "success"
                if len(result.Errors) &gt; 0 </span><span class="cov0" title="0">{
                        status = "error"
                }</span>
                <span class="cov0" title="0">g.metricsCollector.RecordOperation(ctx, "cognify", status, durationMs)

                // Record stage timings from trace if available
                if trace != nil </span><span class="cov0" title="0">{
                        for _, span := range trace.Spans </span><span class="cov0" title="0">{
                                g.metricsCollector.RecordStage(ctx, "cognify", span.Name, span.DurationMs)
                                if !span.OK </span><span class="cov0" title="0">{
                                        g.metricsCollector.RecordError(ctx, "cognify", span.ErrorType)
                                }</span>
                        }
                }
        }

        // Export trace if enabled (Plan 016 M4)
        <span class="cov8" title="1">if trace != nil </span><span class="cov0" title="0">{
                var err error
                if len(result.Errors) &gt; 0 </span><span class="cov0" title="0">{
                        err = result.Errors[0] // Use first error for classification
                }</span>
                <span class="cov0" title="0">g.exportTrace(ctx, operationID, "cognify", trace, startTime, err, map[string]interface{}{
                        "documentsProcessed": result.DocumentsProcessed,
                        "documentsSkipped":   result.DocumentsSkipped,
                        "nodesCreated":       result.NodesCreated,
                        "edgesCreated":       result.EdgesCreated,
                })</span>
        }

        <span class="cov8" title="1">return result, nil</span>
}

// Search queries the knowledge graph
func (g *Gognee) Search(ctx context.Context, query string, opts search.SearchOptions) (*SearchResponse, error) <span class="cov8" title="1">{
        startTime := time.Now()
        operationID := uuid.New().String() // Generate operation ID for trace correlation
        search.ApplyDefaults(&amp;opts)

        // Initialize trace if enabled
        var trace *OperationTrace
        var searchTimer *spanTimer
        if opts.TraceEnabled </span><span class="cov0" title="0">{
                trace = newTrace()
                searchTimer = newSpanTimer("search-vector", trace, true)
        }</span>

        // Apply default for IncludeMemoryIDs (true by default)
        <span class="cov8" title="1">includeMemoryIDs := true
        if opts.IncludeMemoryIDs != nil </span><span class="cov8" title="1">{
                includeMemoryIDs = *opts.IncludeMemoryIDs
        }</span>

        <span class="cov8" title="1">results, err := g.searcher.Search(ctx, query, opts)
        if err != nil </span><span class="cov0" title="0">{
                if searchTimer != nil </span><span class="cov0" title="0">{
                        searchTimer.finish(false, err, nil)
                }</span>
                // Record error metrics
                <span class="cov0" title="0">if g.metricsCollector != nil </span><span class="cov0" title="0">{
                        durationMs := time.Since(startTime).Milliseconds()
                        g.metricsCollector.RecordOperation(ctx, "search", "error", durationMs)
                        g.metricsCollector.RecordError(ctx, "search", "search_error")
                }</span>
                // Export trace on error (Plan 016 M4)
                <span class="cov0" title="0">if trace != nil </span><span class="cov0" title="0">{
                        g.exportTrace(ctx, operationID, "search", trace, startTime, err, map[string]interface{}{
                                "query": "(redacted)", // Don't include query text in trace
                        })
                }</span>
                <span class="cov0" title="0">return nil, err</span>
        }

        <span class="cov8" title="1">if searchTimer != nil </span><span class="cov0" title="0">{
                searchTimer.finish(true, nil, map[string]int64{"resultsReturned": int64(len(results))})
        }</span>

        // Update access times for returned results (for decay reinforcement)
        <span class="cov8" title="1">if len(results) &gt; 0 </span><span class="cov8" title="1">{
                nodeIDs := make([]string, len(results))
                for i, result := range results </span><span class="cov8" title="1">{
                        nodeIDs[i] = result.NodeID
                }</span>

                // Cast to SQLiteGraphStore to access UpdateAccessTime
                <span class="cov8" title="1">if sqlStore, ok := g.graphStore.(*store.SQLiteGraphStore); ok </span><span class="cov8" title="1">{
                        // Best-effort update - don't fail search if access tracking fails
                        _ = sqlStore.UpdateAccessTime(ctx, nodeIDs)
                }</span>

                // Enrich with memory provenance (batched query, no N+1)
                <span class="cov8" title="1">if includeMemoryIDs </span><span class="cov8" title="1">{
                        memoryMap, err := g.memoryStore.GetMemoriesByNodeIDBatched(ctx, nodeIDs)
                        if err != nil </span>{<span class="cov0" title="0">
                                // Log but don't fail - provenance enrichment is optional
                                // In production, could use a logger here
                        }</span> else<span class="cov8" title="1"> {
                                // Populate MemoryIDs for each result
                                for i := range results </span><span class="cov8" title="1">{
                                        if memIDs, ok := memoryMap[results[i].NodeID]; ok </span><span class="cov8" title="1">{
                                                results[i].MemoryIDs = memIDs
                                        }</span> else<span class="cov0" title="0"> {
                                                results[i].MemoryIDs = []string{} // Empty for legacy nodes
                                        }</span>
                                }
                        }
                }
        }

        // Record success metrics
        <span class="cov8" title="1">if g.metricsCollector != nil </span><span class="cov0" title="0">{
                durationMs := time.Since(startTime).Milliseconds()
                g.metricsCollector.RecordOperation(ctx, "search", "success", durationMs)

                // Record stage timings from trace if available
                if trace != nil </span><span class="cov0" title="0">{
                        for _, span := range trace.Spans </span><span class="cov0" title="0">{
                                g.metricsCollector.RecordStage(ctx, "search", span.Name, span.DurationMs)
                        }</span>
                }
        }

        // Export trace if enabled (Plan 016 M4)
        <span class="cov8" title="1">if trace != nil </span><span class="cov0" title="0">{
                g.exportTrace(ctx, operationID, "search", trace, startTime, nil, map[string]interface{}{
                        "resultsReturned": len(results),
                })
        }</span>

        <span class="cov8" title="1">return &amp;SearchResponse{
                Results: results,
                Trace:   trace,
        }, nil</span>
}

// Close releases all resources
func (g *Gognee) Close() error <span class="cov8" title="1">{
        g.buffer = make([]AddedDocument, 0)
        return g.graphStore.Close()
}</span>

// Stats returns basic telemetry
func (g *Gognee) Stats() (Stats, error) <span class="cov8" title="1">{
        ctx := context.Background()
        nodeCount, err := g.graphStore.NodeCount(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return Stats{}, fmt.Errorf("failed to get node count: %w", err)
        }</span>

        <span class="cov8" title="1">edgeCount, err := g.graphStore.EdgeCount(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return Stats{}, fmt.Errorf("failed to get edge count: %w", err)
        }</span>

        <span class="cov8" title="1">memoryCount, err := g.memoryStore.CountMemories(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return Stats{}, fmt.Errorf("failed to get memory count: %w", err)
        }</span>

        <span class="cov8" title="1">return Stats{
                NodeCount:     nodeCount,
                EdgeCount:     edgeCount,
                MemoryCount:   memoryCount,
                BufferedDocs:  len(g.buffer),
                LastCognified: g.lastCognified,
        }, nil</span>
}

// Prune removes old or low-scoring nodes from the knowledge graph.
// Edges connected to pruned nodes are also deleted (cascade).
// Use DryRun to preview what would be pruned without actually deleting.
func (g *Gognee) Prune(ctx context.Context, opts PruneOptions) (*PruneResult, error) <span class="cov8" title="1">{
        result := &amp;PruneResult{
                NodeIDs: make([]string, 0),
        }

        // Get all nodes for evaluation
        sqlStore, ok := g.graphStore.(*store.SQLiteGraphStore)
        if !ok </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("prune requires SQLiteGraphStore")
        }</span>

        // Query all nodes
        <span class="cov8" title="1">allNodes, err := sqlStore.GetAllNodes(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get nodes: %w", err)
        }</span>

        <span class="cov8" title="1">result.NodesEvaluated = len(allNodes)

        // Evaluate each node for pruning
        now := time.Now()
        nodesToPrune := make([]string, 0)

        for _, node := range allNodes </span><span class="cov8" title="1">{
                shouldPrune := false

                // Check MaxAgeDays criterion
                if opts.MaxAgeDays &gt; 0 </span><span class="cov8" title="1">{
                        var age time.Duration
                        if g.config.DecayBasis == "access" &amp;&amp; node.LastAccessedAt != nil </span><span class="cov0" title="0">{
                                age = now.Sub(*node.LastAccessedAt)
                        }</span> else<span class="cov8" title="1"> {
                                age = now.Sub(node.CreatedAt)
                        }</span>

                        <span class="cov8" title="1">ageDays := int(age.Hours() / 24)
                        if ageDays &gt; opts.MaxAgeDays </span><span class="cov8" title="1">{
                                shouldPrune = true
                        }</span>
                }

                // Check MinDecayScore criterion
                <span class="cov8" title="1">if opts.MinDecayScore &gt; 0 &amp;&amp; g.config.DecayEnabled </span><span class="cov0" title="0">{
                        var age time.Duration
                        if g.config.DecayBasis == "access" &amp;&amp; node.LastAccessedAt != nil </span><span class="cov0" title="0">{
                                age = now.Sub(*node.LastAccessedAt)
                        }</span> else<span class="cov0" title="0"> {
                                age = now.Sub(node.CreatedAt)
                        }</span>

                        <span class="cov0" title="0">decayScore := calculateDecay(age, g.config.DecayHalfLifeDays)
                        if decayScore &lt; opts.MinDecayScore </span><span class="cov0" title="0">{
                                shouldPrune = true
                        }</span>
                }

                <span class="cov8" title="1">if shouldPrune </span><span class="cov8" title="1">{
                        nodesToPrune = append(nodesToPrune, node.ID)
                }</span>
        }

        <span class="cov8" title="1">result.NodesPruned = len(nodesToPrune)
        result.NodeIDs = nodesToPrune

        // If dry run, stop here
        if opts.DryRun </span><span class="cov8" title="1">{
                // Estimate edges that would be pruned
                for _, nodeID := range nodesToPrune </span><span class="cov8" title="1">{
                        edges, err := g.graphStore.GetEdges(ctx, nodeID)
                        if err == nil </span><span class="cov8" title="1">{
                                result.EdgesPruned += len(edges)
                        }</span>
                }
                <span class="cov8" title="1">return result, nil</span>
        }

        // Actually prune nodes and edges
        <span class="cov8" title="1">for _, nodeID := range nodesToPrune </span><span class="cov8" title="1">{
                // Delete edges first (cascade)
                edges, err := g.graphStore.GetEdges(ctx, nodeID)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">result.EdgesPruned += len(edges)

                // Delete the edges
                for _, edge := range edges </span><span class="cov8" title="1">{
                        if err := sqlStore.DeleteEdge(ctx, edge.ID); err != nil </span><span class="cov0" title="0">{
                                // Continue on error to prune as much as possible
                                continue</span>
                        }
                }

                // Delete from vector store (ignore errors to prune as much as possible)
                <span class="cov8" title="1">_ = g.vectorStore.Delete(ctx, nodeID)

                // Delete the node
                if err := sqlStore.DeleteNode(ctx, nodeID); err != nil </span><span class="cov0" title="0">{
                        // Continue on error
                        continue</span>
                }
        }

        <span class="cov8" title="1">return result, nil</span>
}

// generateDeterministicNodeID creates a deterministic node ID from name and type
func generateDeterministicNodeID(name, nodeType string) string <span class="cov8" title="1">{
        // Normalize the name
        normalized := strings.ToLower(strings.TrimSpace(name))
        normalized = strings.Join(strings.Fields(normalized), " ") // Collapse spaces

        // Create the key
        key := normalized + "|" + nodeType

        // Hash with SHA-256
        hash := sha256.Sum256([]byte(key))

        // Return hex-encoded first 16 bytes (32 chars)
        return fmt.Sprintf("%x", hash[:16])
}</span>

// sanitizeRelation converts relation names to safe edge IDs
func sanitizeRelation(relation string) string <span class="cov8" title="1">{
        return strings.ToUpper(strings.ReplaceAll(relation, " ", "_"))
}</span>

// computeDocumentHash computes a SHA-256 hash of document text for identity.
// Used for document-level deduplication in incremental Cognify.
// Hash is computed on exact text without normalization to detect any changes.
func computeDocumentHash(text string) string <span class="cov8" title="1">{
        hash := sha256.Sum256([]byte(text))
        return fmt.Sprintf("%x", hash[:])
}</span>

// ========================================
// Memory CRUD APIs (v1.0.0)
// ========================================

// MemoryInput represents the input for creating a memory.
type MemoryInput struct {
        Topic     string
        Context   string
        Decisions []string
        Rationale []string
        Metadata  map[string]interface{}
        Source    string
        // TraceEnabled enables timing instrumentation (Plan 015)
        TraceEnabled bool
}

// MemoryResult reports the outcome of memory operations.
type MemoryResult struct {
        MemoryID     string
        NodesCreated int
        EdgesCreated int
        NodesDeleted int
        EdgesDeleted int
        Errors       []error
        // Trace contains timing data when TraceEnabled is true (Plan 015)
        Trace *OperationTrace
}

// AddMemory creates a new first-class memory with full CRUD support.
// Uses two-phase model: persist memory record  cognify  link provenance.
func (g *Gognee) AddMemory(ctx context.Context, input MemoryInput) (*MemoryResult, error) <span class="cov8" title="1">{
        startTime := time.Now()
        operationID := uuid.New().String() // Generate operation ID for trace correlation

        result := &amp;MemoryResult{
                Errors: make([]error, 0),
        }

        // Initialize trace if enabled (Plan 015 M2)
        var trace *OperationTrace
        if input.TraceEnabled </span><span class="cov0" title="0">{
                trace = newTrace()
                result.Trace = trace
        }</span>

        // Validate input
        <span class="cov8" title="1">if strings.TrimSpace(input.Topic) == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("topic cannot be empty")
        }</span>
        <span class="cov8" title="1">if strings.TrimSpace(input.Context) == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("context cannot be empty")
        }</span>

        // Compute doc_hash
        <span class="cov8" title="1">docHash := store.ComputeDocHash(input.Topic, input.Context, input.Decisions, input.Rationale)

        // **Phase 1: Short transaction - persist memory record**
        // Check for duplicate by doc_hash
        // For v1.0.0, we'll do a simple query to check existence
        // If exists, return existing memory_id

        existingQuery := `SELECT id FROM memories WHERE doc_hash = ? LIMIT 1`
        var existingID string
        err := g.memoryStore.DB().QueryRowContext(ctx, existingQuery, docHash).Scan(&amp;existingID)
        if err == nil </span><span class="cov8" title="1">{
                // Duplicate found
                result.MemoryID = existingID
                return result, nil
        }</span>
        // If error is not ErrNoRows, return error
        <span class="cov8" title="1">if err != sql.ErrNoRows </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to check for duplicate memory: %w", err)
        }</span>

        // Create memory record with status "pending"
        <span class="cov8" title="1">memoryID := uuid.New().String()
        memory := &amp;store.MemoryRecord{
                ID:        memoryID,
                Topic:     strings.TrimSpace(input.Topic),
                Context:   strings.TrimSpace(input.Context),
                Decisions: input.Decisions,
                Rationale: input.Rationale,
                Metadata:  input.Metadata,
                DocHash:   docHash,
                Source:    input.Source,
                Status:    "pending",
        }

        if err := g.memoryStore.AddMemory(ctx, memory); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to add memory record: %w", err)
        }</span>

        <span class="cov8" title="1">result.MemoryID = memoryID

        // **Phase 2: Cognify (outside transaction, idempotent)**
        cognifyTimer := newSpanTimer("cognify", trace, input.TraceEnabled)

        // Format text for cognify
        text := fmt.Sprintf("Topic: %s\n\n%s", input.Topic, input.Context)

        // Track created node/edge IDs
        createdNodeIDs := make([]string, 0)
        createdEdgeIDs := make([]string, 0)

        // Chunk the text
        chunks := g.chunker.Chunk(text)

        // Process each chunk
        for _, chunk := range chunks </span><span class="cov8" title="1">{
                // Extract entities
                entities, err := g.entityExtractor.Extract(ctx, chunk.Text)
                if err != nil </span><span class="cov8" title="1">{
                        result.Errors = append(result.Errors, fmt.Errorf("entity extraction failed for memory %s: %w", memoryID, err))
                        continue</span>
                }

                // Build entity name-&gt;type lookup map
                <span class="cov8" title="1">entityMap, ambiguous := buildEntityTypeMap(entities)

                // Extract relations
                triplets, err := g.relationExtractor.Extract(ctx, chunk.Text, entities)
                if err != nil </span><span class="cov0" title="0">{
                        result.Errors = append(result.Errors, fmt.Errorf("relation extraction failed for memory %s: %w", memoryID, err))
                        // Continue with entities only
                }</span>

                // Create nodes for each entity
                // First pass: collect texts for batch embedding
                <span class="cov8" title="1">entityTexts := make([]string, len(entities))
                for i, entity := range entities </span><span class="cov8" title="1">{
                        entityTexts[i] = entity.Name + " " + entity.Description
                }</span>

                // Batch embed all entities at once
                <span class="cov8" title="1">embeddings, err := g.embeddings.Embed(ctx, entityTexts)
                if err != nil </span><span class="cov0" title="0">{
                        result.Errors = append(result.Errors, fmt.Errorf("batch embed failed for memory %s: %w", memoryID, err))
                        // Continue without embeddings
                        embeddings = make([][]float32, len(entities))
                }</span>

                // Second pass: create nodes with embeddings
                <span class="cov8" title="1">for i, entity := range entities </span><span class="cov8" title="1">{
                        nodeID := generateDeterministicNodeID(entity.Name, entity.Type)
                        node := &amp;store.Node{
                                ID:          nodeID,
                                Name:        entity.Name,
                                Type:        entity.Type,
                                Description: entity.Description,
                                CreatedAt:   time.Now(),
                                Metadata:    make(map[string]interface{}),
                                Embedding:   embeddings[i],
                        }

                        // Add to graph store (upsert) with embedding
                        if err := g.graphStore.AddNode(ctx, node); err != nil </span><span class="cov0" title="0">{
                                result.Errors = append(result.Errors, fmt.Errorf("failed to add node %s: %w", entity.Name, err))
                                continue</span>
                        }
                        <span class="cov8" title="1">createdNodeIDs = append(createdNodeIDs, nodeID)
                        result.NodesCreated++

                        // Index in vector store
                        if len(embeddings[i]) &gt; 0 </span><span class="cov8" title="1">{
                                if err := g.vectorStore.Add(ctx, nodeID, embeddings[i]); err != nil </span><span class="cov0" title="0">{
                                        result.Errors = append(result.Errors, fmt.Errorf("failed to index node %s in vector store: %w", entity.Name, err))
                                }</span>
                        }
                }

                // Create edges for each triplet
                <span class="cov8" title="1">for _, triplet := range triplets </span><span class="cov8" title="1">{
                        // Look up source and target entity types
                        sourceType, sourceFound := lookupEntityType(triplet.Subject, entityMap, ambiguous)
                        if !sourceFound </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        <span class="cov8" title="1">targetType, targetFound := lookupEntityType(triplet.Object, entityMap, ambiguous)
                        if !targetFound </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        <span class="cov8" title="1">sourceID := generateDeterministicNodeID(triplet.Subject, sourceType)
                        targetID := generateDeterministicNodeID(triplet.Object, targetType)

                        edgeID := fmt.Sprintf("%s-%s-%s", sourceID, sanitizeRelation(triplet.Relation), targetID)
                        edge := &amp;store.Edge{
                                ID:        edgeID,
                                SourceID:  sourceID,
                                Relation:  triplet.Relation,
                                TargetID:  targetID,
                                Weight:    1.0,
                                CreatedAt: time.Now(),
                        }

                        if err := g.graphStore.AddEdge(ctx, edge); err != nil </span><span class="cov0" title="0">{
                                result.Errors = append(result.Errors, fmt.Errorf("failed to add edge: %w", err))
                                continue</span>
                        }
                        <span class="cov8" title="1">createdEdgeIDs = append(createdEdgeIDs, edgeID)
                        result.EdgesCreated++</span>
                }
        }

        // Finish cognify timer
        <span class="cov8" title="1">cognifyTimer.finish(true, nil, map[string]int64{
                "nodesCreated": int64(result.NodesCreated),
                "edgesCreated": int64(result.EdgesCreated),
        })

        // **Phase 3: Short transaction - link provenance and mark complete**
        if err := g.memoryStore.LinkProvenance(ctx, memoryID, createdNodeIDs, createdEdgeIDs); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to link provenance: %w", err)
        }</span>

        // Update memory status to "complete"
        <span class="cov8" title="1">completeStatus := "complete"
        updates := store.MemoryUpdate{
                Topic:   &amp;memory.Topic, // Keep same
                Context: &amp;memory.Context,
                Status:  &amp;completeStatus,
        }
        if err := g.memoryStore.UpdateMemory(ctx, memoryID, updates); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to mark memory complete: %w", err)
        }</span>

        // Record success metrics
        <span class="cov8" title="1">if g.metricsCollector != nil </span><span class="cov0" title="0">{
                durationMs := time.Since(startTime).Milliseconds()
                status := "success"
                if len(result.Errors) &gt; 0 </span><span class="cov0" title="0">{
                        status = "error"
                }</span>
                <span class="cov0" title="0">g.metricsCollector.RecordOperation(ctx, "add_memory", status, durationMs)

                // Record stage timings from trace if available
                if trace != nil </span><span class="cov0" title="0">{
                        for _, span := range trace.Spans </span><span class="cov0" title="0">{
                                g.metricsCollector.RecordStage(ctx, "add_memory", span.Name, span.DurationMs)
                                if !span.OK </span><span class="cov0" title="0">{
                                        g.metricsCollector.RecordError(ctx, "add_memory", span.ErrorType)
                                }</span>
                        }
                }
        }

        // Export trace if enabled (Plan 016 M4)
        <span class="cov8" title="1">if trace != nil </span><span class="cov0" title="0">{
                var err error
                if len(result.Errors) &gt; 0 </span><span class="cov0" title="0">{
                        err = result.Errors[0]
                }</span>
                <span class="cov0" title="0">g.exportTrace(ctx, operationID, "add_memory", trace, startTime, err, map[string]interface{}{
                        "memoryId":     result.MemoryID,
                        "nodesCreated": result.NodesCreated,
                        "edgesCreated": result.EdgesCreated,
                })</span>
        }

        <span class="cov8" title="1">return result, nil</span>
}

// GetMemory retrieves a memory by ID.
func (g *Gognee) GetMemory(ctx context.Context, id string) (*store.MemoryRecord, error) <span class="cov8" title="1">{
        return g.memoryStore.GetMemory(ctx, id)
}</span>

// ListMemories returns paginated memory summaries.
func (g *Gognee) ListMemories(ctx context.Context, opts store.ListMemoriesOptions) ([]store.MemorySummary, error) <span class="cov8" title="1">{
        return g.memoryStore.ListMemories(ctx, opts)
}</span>

// CountMemories returns the total number of memories in the store.
func (g *Gognee) CountMemories(ctx context.Context) (int64, error) <span class="cov0" title="0">{
        return g.memoryStore.CountMemories(ctx)
}</span>

// UpdateMemory applies partial updates to a memory and re-cognifies if content changed.
func (g *Gognee) UpdateMemory(ctx context.Context, id string, updates store.MemoryUpdate) (*MemoryResult, error) <span class="cov8" title="1">{
        result := &amp;MemoryResult{
                MemoryID: id,
                Errors:   make([]error, 0),
        }

        // Fetch existing memory
        existing, err := g.memoryStore.GetMemory(ctx, id)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Compute new doc_hash
        <span class="cov8" title="1">topic := existing.Topic
        context := existing.Context
        decisions := existing.Decisions
        rationale := existing.Rationale

        if updates.Topic != nil </span><span class="cov0" title="0">{
                topic = *updates.Topic
        }</span>
        <span class="cov8" title="1">if updates.Context != nil </span><span class="cov8" title="1">{
                context = *updates.Context
        }</span>
        <span class="cov8" title="1">if updates.Decisions != nil </span><span class="cov0" title="0">{
                decisions = *updates.Decisions
        }</span>
        <span class="cov8" title="1">if updates.Rationale != nil </span><span class="cov0" title="0">{
                rationale = *updates.Rationale
        }</span>

        <span class="cov8" title="1">newDocHash := store.ComputeDocHash(topic, context, decisions, rationale)

        // If hash unchanged, just update metadata/timestamps (no re-cognify)
        if newDocHash == existing.DocHash </span><span class="cov0" title="0">{
                if err := g.memoryStore.UpdateMemory(ctx, id, updates); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to update memory: %w", err)
                }</span>
                <span class="cov0" title="0">return result, nil</span>
        }

        // **Phase 1: Set status to "pending"**
        <span class="cov8" title="1">pendingUpdate := store.MemoryUpdate{
                Topic:   &amp;topic,
                Context: &amp;context,
                Status:  stringPtr("pending"),
        }
        pendingUpdate.Decisions = &amp;decisions
        pendingUpdate.Rationale = &amp;rationale
        if updates.Metadata != nil </span><span class="cov0" title="0">{
                pendingUpdate.Metadata = updates.Metadata
        }</span>

        // Update the memory with new content (will recompute hash in store)
        <span class="cov8" title="1">if err := g.memoryStore.UpdateMemory(ctx, id, pendingUpdate); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to update memory to pending: %w", err)
        }</span>

        // **Phase 2: Get old provenance, unlink, and GC candidates**
        <span class="cov8" title="1">oldNodeIDs, oldEdgeIDs, err := g.memoryStore.GetProvenanceByMemory(ctx, id)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get old provenance: %w", err)
        }</span>

        <span class="cov8" title="1">if err := g.memoryStore.UnlinkProvenance(ctx, id); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to unlink old provenance: %w", err)
        }</span>

        // GC candidates: old artifacts
        <span class="cov8" title="1">nodesDeleted, edgesDeleted, err := g.memoryStore.GarbageCollectCandidates(ctx, oldNodeIDs, oldEdgeIDs)
        if err != nil </span><span class="cov0" title="0">{
                result.Errors = append(result.Errors, fmt.Errorf("garbage collection failed: %w", err))
        }</span>
        <span class="cov8" title="1">result.NodesDeleted = nodesDeleted
        result.EdgesDeleted = edgesDeleted

        // **Phase 3: Re-cognify (same as AddMemory Phase 2)**
        text := fmt.Sprintf("Topic: %s\n\n%s", topic, context)
        createdNodeIDs := make([]string, 0)
        createdEdgeIDs := make([]string, 0)

        chunks := g.chunker.Chunk(text)
        for _, chunk := range chunks </span><span class="cov8" title="1">{
                entities, err := g.entityExtractor.Extract(ctx, chunk.Text)
                if err != nil </span><span class="cov0" title="0">{
                        result.Errors = append(result.Errors, fmt.Errorf("entity extraction failed: %w", err))
                        continue</span>
                }

                <span class="cov8" title="1">entityMap, ambiguous := buildEntityTypeMap(entities)

                triplets, err := g.relationExtractor.Extract(ctx, chunk.Text, entities)
                if err != nil </span><span class="cov0" title="0">{
                        result.Errors = append(result.Errors, fmt.Errorf("relation extraction failed: %w", err))
                }</span>

                // First pass: collect texts for batch embedding
                <span class="cov8" title="1">entityTexts := make([]string, len(entities))
                for i, entity := range entities </span><span class="cov8" title="1">{
                        entityTexts[i] = entity.Name + " " + entity.Description
                }</span>

                // Batch embed all entities at once
                <span class="cov8" title="1">embeddings, err := g.embeddings.Embed(ctx, entityTexts)
                if err != nil </span><span class="cov0" title="0">{
                        result.Errors = append(result.Errors, fmt.Errorf("batch embed failed: %w", err))
                        // Continue without embeddings
                        embeddings = make([][]float32, len(entities))
                }</span>

                // Second pass: create nodes with embeddings
                <span class="cov8" title="1">for i, entity := range entities </span><span class="cov8" title="1">{
                        nodeID := generateDeterministicNodeID(entity.Name, entity.Type)
                        node := &amp;store.Node{
                                ID:          nodeID,
                                Name:        entity.Name,
                                Type:        entity.Type,
                                Description: entity.Description,
                                CreatedAt:   time.Now(),
                                Metadata:    make(map[string]interface{}),
                                Embedding:   embeddings[i],
                        }

                        if err := g.graphStore.AddNode(ctx, node); err != nil </span><span class="cov0" title="0">{
                                result.Errors = append(result.Errors, fmt.Errorf("failed to add node: %w", err))
                                continue</span>
                        }
                        <span class="cov8" title="1">createdNodeIDs = append(createdNodeIDs, nodeID)
                        result.NodesCreated++

                        if len(embeddings[i]) &gt; 0 </span><span class="cov8" title="1">{
                                if err := g.vectorStore.Add(ctx, nodeID, embeddings[i]); err != nil </span><span class="cov0" title="0">{
                                        result.Errors = append(result.Errors, fmt.Errorf("failed to index node in vector store: %w", err))
                                }</span>
                        }
                }

                <span class="cov8" title="1">for _, triplet := range triplets </span><span class="cov0" title="0">{
                        sourceType, sourceFound := lookupEntityType(triplet.Subject, entityMap, ambiguous)
                        if !sourceFound </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        <span class="cov0" title="0">targetType, targetFound := lookupEntityType(triplet.Object, entityMap, ambiguous)
                        if !targetFound </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        <span class="cov0" title="0">sourceID := generateDeterministicNodeID(triplet.Subject, sourceType)
                        targetID := generateDeterministicNodeID(triplet.Object, targetType)
                        edgeID := fmt.Sprintf("%s-%s-%s", sourceID, sanitizeRelation(triplet.Relation), targetID)

                        edge := &amp;store.Edge{
                                ID:        edgeID,
                                SourceID:  sourceID,
                                Relation:  triplet.Relation,
                                TargetID:  targetID,
                                Weight:    1.0,
                                CreatedAt: time.Now(),
                        }

                        if err := g.graphStore.AddEdge(ctx, edge); err != nil </span><span class="cov0" title="0">{
                                result.Errors = append(result.Errors, fmt.Errorf("failed to add edge: %w", err))
                                continue</span>
                        }
                        <span class="cov0" title="0">createdEdgeIDs = append(createdEdgeIDs, edgeID)
                        result.EdgesCreated++</span>
                }
        }

        // **Phase 4: Link new provenance and mark complete**
        <span class="cov8" title="1">if err := g.memoryStore.LinkProvenance(ctx, id, createdNodeIDs, createdEdgeIDs); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to link new provenance: %w", err)
        }</span>

        <span class="cov8" title="1">completeUpdate := store.MemoryUpdate{
                Topic:   &amp;topic,
                Context: &amp;context,
                Status:  stringPtr("complete"),
        }
        if err := g.memoryStore.UpdateMemory(ctx, id, completeUpdate); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to mark memory complete: %w", err)
        }</span>

        <span class="cov8" title="1">return result, nil</span>
}

// DeleteMemory removes a memory and runs garbage collection on orphaned artifacts.
func (g *Gognee) DeleteMemory(ctx context.Context, id string) error <span class="cov8" title="1">{
        // Get provenance before delete
        nodeIDs, edgeIDs, err := g.memoryStore.GetProvenanceByMemory(ctx, id)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get provenance: %w", err)
        }</span>

        // Delete memory (CASCADE will remove provenance links)
        <span class="cov8" title="1">if err := g.memoryStore.DeleteMemory(ctx, id); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Run GC on candidates
        <span class="cov8" title="1">_, _, err = g.memoryStore.GarbageCollectCandidates(ctx, nodeIDs, edgeIDs)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("garbage collection failed: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// GarbageCollect manually triggers garbage collection.
// Returns counts of deleted nodes and edges.
func (g *Gognee) GarbageCollect(ctx context.Context) (nodesDeleted, edgesDeleted int, err error) <span class="cov8" title="1">{
        // For manual GC, we need to identify all orphaned artifacts
        // This is complex without tracking; for v1.0.0, this is a placeholder
        return 0, 0, fmt.Errorf("manual garbage collection not yet implemented; use DeleteMemory/UpdateMemory for automatic GC")
}</span>

// stringPtr returns a pointer to a string (helper for optional fields).
func stringPtr(s string) *string <span class="cov8" title="1">{
        return &amp;s
}</span>
</pre>
		
		<pre class="file" id="file8" style="display: none">package gognee

import (
        "context"
        "time"

        tracepkg "github.com/dan-solli/gognee/pkg/trace"
)

// OperationTrace captures timing and performance data for a Cognify or Search operation.
// This structure is stable and versioned to support downstream consumers.
type OperationTrace struct {
        // Spans contains timing data for each stage of the operation
        Spans []Span `json:"spans"`

        // TotalDurationMs is the total elapsed time for the operation in milliseconds
        TotalDurationMs int64 `json:"totalDurationMs"`
}

// Span represents a single timed stage within an operation.
// Stage names are stable and documented:
//   - "chunk": Text chunking
//   - "embed": Embedding generation
//   - "extract": Entity/relationship extraction
//   - "write-graph": Graph database writes
//   - "write-vector": Vector store writes
//   - "search-vector": Vector similarity search
//   - "search-expand": Graph traversal/expansion
type Span struct {
        // Name identifies the operation stage (see Span documentation for stable names)
        Name string `json:"name"`

        // DurationMs is the elapsed time for this span in milliseconds
        DurationMs int64 `json:"durationMs"`

        // OK indicates whether the span completed successfully
        OK bool `json:"ok"`

        // Error contains error message if OK is false (optional)
        Error string `json:"error,omitempty"`

        // ErrorType classifies the error for metrics (added in Plan 016 M3)
        ErrorType string `json:"errorType,omitempty"`

        // Counters provides additional metrics for the span (optional)
        // Example keys: "chunkCount", "nodeUpserts", "edgeUpserts", "resultsReturned"
        Counters map[string]int64 `json:"counters,omitempty"`
}

// newTrace creates a new OperationTrace with empty spans
func newTrace() *OperationTrace <span class="cov8" title="1">{
        return &amp;OperationTrace{
                Spans: make([]Span, 0),
        }
}</span>

// addSpan appends a completed span to the trace
func (t *OperationTrace) addSpan(span Span) <span class="cov8" title="1">{
        t.Spans = append(t.Spans, span)
        t.TotalDurationMs += span.DurationMs
}</span>

// spanTimer is a helper for measuring span duration
type spanTimer struct {
        name    string
        start   int64 // Unix time in milliseconds
        trace   *OperationTrace
        enabled bool
}

// newSpanTimer creates a timer for a named span
func newSpanTimer(name string, trace *OperationTrace, enabled bool) *spanTimer <span class="cov8" title="1">{
        if !enabled || trace == nil </span><span class="cov8" title="1">{
                return &amp;spanTimer{enabled: false}
        }</span>
        <span class="cov8" title="1">return &amp;spanTimer{
                name:    name,
                start:   timeNowMs(),
                trace:   trace,
                enabled: true,
        }</span>
}

// finish completes the span and records it to the trace
func (st *spanTimer) finish(ok bool, err error, counters map[string]int64) <span class="cov8" title="1">{
        if !st.enabled </span><span class="cov8" title="1">{
                return
        }</span>

        <span class="cov8" title="1">duration := timeNowMs() - st.start
        span := Span{
                Name:       st.name,
                DurationMs: duration,
                OK:         ok,
                Counters:   counters,
        }
        if err != nil </span><span class="cov8" title="1">{
                span.Error = err.Error()
                span.ErrorType = ClassifyError(err) // Classify error for metrics (Plan 016 M3)
        }</span>
        <span class="cov8" title="1">st.trace.addSpan(span)</span>
}

// timeNowMs returns current Unix time in milliseconds
func timeNowMs() int64 <span class="cov8" title="1">{
        return time.Now().UnixMilli()
}</span>

// exportTrace writes the trace to the configured exporter if available.
// This is called after operation completion (Cognify, Search, AddMemory).
func (g *Gognee) exportTrace(ctx context.Context, operationID, operation string, trace *OperationTrace, startTime time.Time, err error, ids map[string]interface{}) <span class="cov0" title="0">{
        if g.traceExporter == nil || trace == nil </span><span class="cov0" title="0">{
                return // Tracing not enabled
        }</span>

        <span class="cov0" title="0">status := "success"
        errorType := ""
        if err != nil </span><span class="cov0" title="0">{
                status = "error"
                errorType = ClassifyError(err)
        }</span>

        // Convert OperationTrace spans to tracepkg.SpanRecord
        <span class="cov0" title="0">spans := make([]tracepkg.SpanRecord, len(trace.Spans))
        for i, span := range trace.Spans </span><span class="cov0" title="0">{
                spans[i] = tracepkg.SpanRecord{
                        Name:       span.Name,
                        DurationMs: span.DurationMs,
                        OK:         span.OK,
                        ErrorType:  span.ErrorType,
                        Counters:   span.Counters,
                }
        }</span>

        <span class="cov0" title="0">record := &amp;tracepkg.TraceRecord{
                Timestamp:   startTime,
                OperationID: operationID,
                Operation:   operation,
                DurationMs:  trace.TotalDurationMs,
                Status:      status,
                Spans:       spans,
                ErrorType:   errorType,
                IDs:         ids,
        }

        // Export in background to avoid blocking operation completion
        go func() </span><span class="cov0" title="0">{
                exportCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
                defer cancel()

                if exportErr := g.traceExporter.Export(exportCtx, record); exportErr != nil </span><span class="cov0" title="0">{
                        // Log error but don't fail the operation
                        // TODO: Consider adding error callback or metrics for export failures
                        _ = exportErr
                }</span>
        }()
}
</pre>
		
		<pre class="file" id="file9" style="display: none">// Package llm provides Ollama LLM client implementation
package llm

import (
        "bytes"
        "context"
        "encoding/json"
        "fmt"
        "io"
        "net/http"
        "time"
)

// OllamaClient implements LLMClient using local Ollama API
type OllamaClient struct {
        baseURL string
        model   string
        client  *http.Client
}

// NewOllamaClient creates a new Ollama LLM client
// baseURL is typically "http://localhost:11434"
// model is the LLM model name, e.g. "mistral"
func NewOllamaClient(baseURL, model string) *OllamaClient <span class="cov0" title="0">{
        return &amp;OllamaClient{
                baseURL: baseURL,
                model:   model,
                client: &amp;http.Client{
                        Timeout: 300 * time.Second, // 5 minutes for slow local models
                },
        }
}</span>

type ollamaGenerateRequest struct {
        Model  string `json:"model"`
        Prompt string `json:"prompt"`
        Stream bool   `json:"stream"`
        Format string `json:"format,omitempty"`
}

type ollamaGenerateResponse struct {
        Response string `json:"response"`
        Done     bool   `json:"done"`
}

// Complete sends a prompt to the LLM and returns the raw completion text
func (c *OllamaClient) Complete(ctx context.Context, prompt string) (string, error) <span class="cov0" title="0">{
        reqBody := ollamaGenerateRequest{
                Model:  c.model,
                Prompt: prompt,
                Stream: false,
        }

        jsonData, err := json.Marshal(reqBody)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("marshal request: %w", err)
        }</span>

        <span class="cov0" title="0">req, err := http.NewRequestWithContext(ctx, "POST", c.baseURL+"/api/generate", bytes.NewReader(jsonData))
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("create request: %w", err)
        }</span>
        <span class="cov0" title="0">req.Header.Set("Content-Type", "application/json")

        resp, err := c.client.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("ollama request failed: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                body, _ := io.ReadAll(resp.Body)
                return "", fmt.Errorf("ollama returned %d: %s", resp.StatusCode, string(body))
        }</span>

        <span class="cov0" title="0">var result ollamaGenerateResponse
        if err := json.NewDecoder(resp.Body).Decode(&amp;result); err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("decode response: %w", err)
        }</span>

        <span class="cov0" title="0">return result.Response, nil</span>
}

// CompleteWithSchema sends a prompt and unmarshals the response into the provided schema
func (c *OllamaClient) CompleteWithSchema(ctx context.Context, prompt string, schema any) error <span class="cov0" title="0">{
        reqBody := ollamaGenerateRequest{
                Model:  c.model,
                Prompt: prompt,
                Stream: false,
                Format: "json",
        }

        jsonData, err := json.Marshal(reqBody)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("marshal request: %w", err)
        }</span>

        <span class="cov0" title="0">req, err := http.NewRequestWithContext(ctx, "POST", c.baseURL+"/api/generate", bytes.NewReader(jsonData))
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("create request: %w", err)
        }</span>
        <span class="cov0" title="0">req.Header.Set("Content-Type", "application/json")

        resp, err := c.client.Do(req)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("ollama request failed: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                body, _ := io.ReadAll(resp.Body)
                return fmt.Errorf("ollama returned %d: %s", resp.StatusCode, string(body))
        }</span>

        <span class="cov0" title="0">var result ollamaGenerateResponse
        if err := json.NewDecoder(resp.Body).Decode(&amp;result); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("decode response: %w", err)
        }</span>

        <span class="cov0" title="0">if err := json.Unmarshal([]byte(result.Response), schema); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("unmarshal schema: %w (response: %s)", err, result.Response)
        }</span>

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file10" style="display: none">package llm

import (
        "bytes"
        "context"
        "encoding/json"
        "fmt"
        "io"
        "math/rand"
        "net/http"
        "regexp"
        "strings"
        "time"
)

const (
        defaultOpenAIBaseURL = "https://api.openai.com/v1"
        defaultModel         = "gpt-4o-mini"
        maxRetries           = 3
        initialRetryDelay    = 1 * time.Second
        backoffFactor        = 2.0
)

// OpenAILLM implements LLMClient for OpenAI's Chat Completions API
type OpenAILLM struct {
        APIKey  string
        Model   string
        BaseURL string
        client  *http.Client
}

// NewOpenAILLM creates a new OpenAI LLM client
func NewOpenAILLM(apiKey string) *OpenAILLM <span class="cov8" title="1">{
        return &amp;OpenAILLM{
                APIKey:  apiKey,
                Model:   defaultModel,
                BaseURL: defaultOpenAIBaseURL,
                client:  &amp;http.Client{Timeout: 60 * time.Second},
        }
}</span>

type openAIRequest struct {
        Model    string    `json:"model"`
        Messages []message `json:"messages"`
}

type message struct {
        Role    string `json:"role"`
        Content string `json:"content"`
}

type openAIResponse struct {
        Choices []struct {
                Message message `json:"message"`
        } `json:"choices"`
        Error *struct {
                Message string `json:"message"`
                Type    string `json:"type"`
        } `json:"error,omitempty"`
}

// Complete sends a prompt to the OpenAI Chat Completions API and returns the response
func (o *OpenAILLM) Complete(ctx context.Context, prompt string) (string, error) <span class="cov8" title="1">{
        var lastErr error
        delay := initialRetryDelay

        for attempt := 0; attempt &lt;= maxRetries; attempt++ </span><span class="cov8" title="1">{
                if attempt &gt; 0 </span><span class="cov8" title="1">{
                        // Add jitter to delay: random value between 0.5x and 1.5x of delay
                        jitter := delay/2 + time.Duration(rand.Int63n(int64(delay)))
                        select </span>{
                        case &lt;-time.After(jitter):<span class="cov8" title="1"></span>
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                return "", ctx.Err()</span>
                        }
                        <span class="cov8" title="1">delay = time.Duration(float64(delay) * backoffFactor)</span>
                }

                <span class="cov8" title="1">result, err := o.makeRequest(ctx, prompt)
                if err == nil </span><span class="cov8" title="1">{
                        return result, nil
                }</span>

                <span class="cov8" title="1">lastErr = err

                // Check if we should retry
                if !shouldRetry(err) </span><span class="cov8" title="1">{
                        return "", err
                }</span>

                // Check if context is cancelled
                <span class="cov8" title="1">if ctx.Err() != nil </span><span class="cov8" title="1">{
                        return "", ctx.Err()
                }</span>
        }

        <span class="cov8" title="1">return "", fmt.Errorf("failed after %d retries: %w", maxRetries, lastErr)</span>
}

// CompleteWithSchema sends a prompt and unmarshals the JSON response into the provided schema
func (o *OpenAILLM) CompleteWithSchema(ctx context.Context, prompt string, schema any) error <span class="cov8" title="1">{
        response, err := o.Complete(ctx, prompt)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Strip markdown code fences if present (LLM sometimes wraps JSON in ```json ... ```)
        <span class="cov8" title="1">cleaned := stripMarkdownCodeFence(response)

        if err := json.Unmarshal([]byte(cleaned), schema); err != nil </span><span class="cov8" title="1">{
                return fmt.Errorf("failed to unmarshal LLM response: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// stripMarkdownCodeFence removes markdown code fences from LLM responses.
// Handles formats like: ```json\n...\n``` or ```\n...\n```
func stripMarkdownCodeFence(s string) string <span class="cov8" title="1">{
        s = strings.TrimSpace(s)

        // Regex to match ```json or ``` at start, and ``` at end
        // Pattern: optional ```json or ```, content, optional ```
        re := regexp.MustCompile("(?s)^```(?:json)?\\s*\n?(.*?)\\s*```$")
        if matches := re.FindStringSubmatch(s); len(matches) == 2 </span><span class="cov8" title="1">{
                return strings.TrimSpace(matches[1])
        }</span>

        <span class="cov8" title="1">return s</span>
}

func (o *OpenAILLM) makeRequest(ctx context.Context, prompt string) (string, error) <span class="cov8" title="1">{
        reqBody := openAIRequest{
                Model: o.Model,
                Messages: []message{
                        {
                                Role:    "user",
                                Content: prompt,
                        },
                },
        }

        jsonData, err := json.Marshal(reqBody)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to marshal request: %w", err)
        }</span>

        <span class="cov8" title="1">req, err := http.NewRequestWithContext(ctx, "POST", o.BaseURL+"/chat/completions", bytes.NewBuffer(jsonData))
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to create request: %w", err)
        }</span>

        <span class="cov8" title="1">req.Header.Set("Content-Type", "application/json")
        req.Header.Set("Authorization", "Bearer "+o.APIKey)

        resp, err := o.client.Do(req)
        if err != nil </span><span class="cov8" title="1">{
                return "", &amp;retryableError{err: fmt.Errorf("request failed: %w", err)}
        }</span>
        <span class="cov8" title="1">defer resp.Body.Close()

        body, err := io.ReadAll(resp.Body)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to read response body: %w", err)
        }</span>

        // Handle non-200 status codes
        <span class="cov8" title="1">if resp.StatusCode != http.StatusOK </span><span class="cov8" title="1">{
                // Retry on 429 (rate limit) and 5xx errors
                if resp.StatusCode == http.StatusTooManyRequests || resp.StatusCode &gt;= 500 </span><span class="cov8" title="1">{
                        return "", &amp;retryableError{err: fmt.Errorf("HTTP %d: %s", resp.StatusCode, string(body))}
                }</span>
                <span class="cov8" title="1">return "", fmt.Errorf("HTTP %d: %s", resp.StatusCode, string(body))</span>
        }

        <span class="cov8" title="1">var apiResp openAIResponse
        if err := json.Unmarshal(body, &amp;apiResp); err != nil </span><span class="cov8" title="1">{
                return "", fmt.Errorf("failed to unmarshal response: %w", err)
        }</span>

        <span class="cov8" title="1">if apiResp.Error != nil </span><span class="cov8" title="1">{
                return "", fmt.Errorf("OpenAI API error: %s", apiResp.Error.Message)
        }</span>

        <span class="cov8" title="1">if len(apiResp.Choices) == 0 </span><span class="cov8" title="1">{
                return "", fmt.Errorf("no completion choices returned")
        }</span>

        <span class="cov8" title="1">return apiResp.Choices[0].Message.Content, nil</span>
}

// retryableError indicates an error that should be retried
type retryableError struct {
        err error
}

func (e *retryableError) Error() string <span class="cov8" title="1">{
        return e.err.Error()
}</span>

func (e *retryableError) Unwrap() error <span class="cov0" title="0">{
        return e.err
}</span>

func shouldRetry(err error) bool <span class="cov8" title="1">{
        var retryErr *retryableError
        // Use type assertion to check for retryableError
        if re, ok := err.(*retryableError); ok </span><span class="cov8" title="1">{
                retryErr = re
        }</span>
        <span class="cov8" title="1">return retryErr != nil</span>
}
</pre>
		
		<pre class="file" id="file11" style="display: none">package metrics

import (
        "context"

        "github.com/prometheus/client_golang/prometheus"
)

// MetricsCollector provides Prometheus metrics collection for gognee operations
type MetricsCollector struct {
        operationsTotal   *prometheus.CounterVec
        operationDuration *prometheus.HistogramVec
        errorsTotal       *prometheus.CounterVec
        storageCount      *prometheus.GaugeVec
        registry          *prometheus.Registry
}

// NewCollector creates a new Prometheus metrics collector
func NewCollector() *MetricsCollector <span class="cov8" title="1">{
        registry := prometheus.NewRegistry()

        operationsTotal := prometheus.NewCounterVec(
                prometheus.CounterOpts{
                        Name: "gognee_operations_total",
                        Help: "Total number of gognee operations by type and status",
                },
                []string{"operation", "status"},
        )

        operationDuration := prometheus.NewHistogramVec(
                prometheus.HistogramOpts{
                        Name:    "gognee_operation_duration_seconds",
                        Help:    "Duration of gognee operations by type and stage",
                        Buckets: []float64{0.01, 0.05, 0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0},
                },
                []string{"operation", "stage"},
        )

        errorsTotal := prometheus.NewCounterVec(
                prometheus.CounterOpts{
                        Name: "gognee_errors_total",
                        Help: "Total number of errors by operation and error type",
                },
                []string{"operation", "error_type"},
        )

        storageCount := prometheus.NewGaugeVec(
                prometheus.GaugeOpts{
                        Name: "gognee_storage_count",
                        Help: "Current count of stored items by type",
                },
                []string{"type"},
        )

        registry.MustRegister(operationsTotal)
        registry.MustRegister(operationDuration)
        registry.MustRegister(errorsTotal)
        registry.MustRegister(storageCount)

        return &amp;MetricsCollector{
                operationsTotal:   operationsTotal,
                operationDuration: operationDuration,
                errorsTotal:       errorsTotal,
                storageCount:      storageCount,
                registry:          registry,
        }
}</span>

// RecordOperation records the completion of an operation
func (m *MetricsCollector) RecordOperation(ctx context.Context, operation string, status string, durationMs int64) <span class="cov8" title="1">{
        m.operationsTotal.WithLabelValues(operation, status).Inc()
}</span>

// RecordStage records the duration of a specific stage within an operation
func (m *MetricsCollector) RecordStage(ctx context.Context, operation string, stage string, durationMs int64) <span class="cov8" title="1">{
        m.operationDuration.WithLabelValues(operation, stage).Observe(float64(durationMs) / 1000.0)
}</span>

// RecordError records an error occurrence
func (m *MetricsCollector) RecordError(ctx context.Context, operation string, errorType string) <span class="cov8" title="1">{
        m.errorsTotal.WithLabelValues(operation, errorType).Inc()
}</span>

// SetStorageCount sets the current count for a storage type
func (m *MetricsCollector) SetStorageCount(ctx context.Context, storageType string, count int64) <span class="cov8" title="1">{
        m.storageCount.WithLabelValues(storageType).Set(float64(count))
}</span>

// Registry returns the Prometheus registry for HTTP exposure
func (m *MetricsCollector) Registry() *prometheus.Registry <span class="cov8" title="1">{
        return m.registry
}</span>
</pre>
		
		<pre class="file" id="file12" style="display: none">package search

import (
        "context"
        "math"
        "time"

        "github.com/dan-solli/gognee/pkg/store"
)

// DecayingSearcher is a decorator that applies time-based decay to search results.
// It wraps any Searcher implementation and modifies scores based on node age.
type DecayingSearcher struct {
        underlying   Searcher
        graphStore   store.GraphStore
        enabled      bool
        halfLifeDays int
        basis        string // "access" or "creation"
}

// NewDecayingSearcher creates a new decaying searcher wrapper.
//
// Parameters:
//   - underlying: The base searcher to wrap
//   - graphStore: Graph store for retrieving node timestamps
//   - enabled: Whether decay is enabled
//   - halfLifeDays: Number of days for half-life decay
//   - basis: "access" (use last_accessed_at) or "creation" (use created_at)
func NewDecayingSearcher(
        underlying Searcher,
        graphStore store.GraphStore,
        enabled bool,
        halfLifeDays int,
        basis string,
) *DecayingSearcher <span class="cov8" title="1">{
        return &amp;DecayingSearcher{
                underlying:   underlying,
                graphStore:   graphStore,
                enabled:      enabled,
                halfLifeDays: halfLifeDays,
                basis:        basis,
        }
}</span>

// Search performs search with decay applied to scores.
func (d *DecayingSearcher) Search(ctx context.Context, query string, opts SearchOptions) ([]SearchResult, error) <span class="cov8" title="1">{
        // Get underlying search results
        results, err := d.underlying.Search(ctx, query, opts)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // If decay is disabled, return results as-is
        <span class="cov8" title="1">if !d.enabled </span><span class="cov8" title="1">{
                return results, nil
        }</span>

        // Apply decay to each result
        <span class="cov8" title="1">now := time.Now()
        decayedResults := make([]SearchResult, 0, len(results))

        for _, result := range results </span><span class="cov8" title="1">{
                // Fetch node to get timestamps
                node, err := d.graphStore.GetNode(ctx, result.NodeID)
                if err != nil </span><span class="cov0" title="0">{
                        // On error, skip decay for this node but include it
                        decayedResults = append(decayedResults, result)
                        continue</span>
                }
                <span class="cov8" title="1">if node == nil </span><span class="cov0" title="0">{
                        // Node was deleted, skip it
                        continue</span>
                }

                // Determine age based on decay basis
                <span class="cov8" title="1">var age time.Duration
                if d.basis == "access" &amp;&amp; node.LastAccessedAt != nil </span><span class="cov8" title="1">{
                        // Use last access time
                        age = now.Sub(*node.LastAccessedAt)
                }</span> else<span class="cov8" title="1"> {
                        // Fall back to creation time (if access-based but never accessed, or creation-based)
                        age = now.Sub(node.CreatedAt)
                }</span>

                // Calculate decay multiplier
                <span class="cov8" title="1">decayMultiplier := d.calculateDecay(age)

                // Apply decay to score
                result.Score = result.Score * decayMultiplier

                // Optional: filter out results below minimum threshold
                // For now, keep all results (even very low scores)
                if result.Score &lt; 0.001 </span><span class="cov8" title="1">{
                        // Skip nodes with extremely low scores
                        continue</span>
                }

                <span class="cov8" title="1">decayedResults = append(decayedResults, result)</span>
        }

        <span class="cov8" title="1">return decayedResults, nil</span>
}

// calculateDecay computes the exponential decay multiplier.
// Formula: 0.5^(age_days / half_life_days)
func (d *DecayingSearcher) calculateDecay(age time.Duration) float64 <span class="cov8" title="1">{
        if age &lt; 0 </span><span class="cov0" title="0">{
                return 1.0
        }</span>
        <span class="cov8" title="1">if d.halfLifeDays &lt;= 0 </span><span class="cov0" title="0">{
                return 1.0
        }</span>

        <span class="cov8" title="1">ageDays := age.Hours() / 24.0
        exponent := ageDays / float64(d.halfLifeDays)
        return math.Pow(0.5, exponent)</span>
}
</pre>
		
		<pre class="file" id="file13" style="display: none">package search

import (
        "context"
        "errors"
        "sort"

        "github.com/dan-solli/gognee/pkg/store"
)

// ErrNoSeeds is returned when graph search is attempted without seed nodes.
var ErrNoSeeds = errors.New("graph search requires seed node IDs in SearchOptions.SeedNodeIDs")

// GraphSearcher performs graph traversal search from seed nodes.
type GraphSearcher struct {
        graphStore store.GraphStore
}

// NewGraphSearcher creates a new graph searcher.
func NewGraphSearcher(graphStore store.GraphStore) *GraphSearcher <span class="cov8" title="1">{
        return &amp;GraphSearcher{
                graphStore: graphStore,
        }
}</span>

// Search performs graph traversal from seed nodes.
// The query parameter is ignored (graph search uses opts.SeedNodeIDs).
func (g *GraphSearcher) Search(ctx context.Context, query string, opts SearchOptions) ([]SearchResult, error) <span class="cov8" title="1">{
        ApplyDefaults(&amp;opts)

        if len(opts.SeedNodeIDs) == 0 </span><span class="cov8" title="1">{
                return nil, ErrNoSeeds
        }</span>

        // Track nodes and their best scores
        <span class="cov8" title="1">nodeScores := make(map[string]nodeScore)
        visited := make(map[string]bool)

        // BFS traversal from all seeds
        type queueItem struct {
                nodeID string
                depth  int
        }
        queue := make([]queueItem, 0)

        // Initialize with seeds
        for _, seedID := range opts.SeedNodeIDs </span><span class="cov8" title="1">{
                seedNode, err := g.graphStore.GetNode(ctx, seedID)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">if seedNode != nil </span><span class="cov8" title="1">{
                        updateNodeScore(nodeScores, seedID, seedNode, 0)
                        queue = append(queue, queueItem{seedID, 0})
                        visited[seedID] = true
                }</span>
        }

        // BFS traversal
        <span class="cov8" title="1">for len(queue) &gt; 0 </span><span class="cov8" title="1">{
                current := queue[0]
                queue = queue[1:]

                // Stop if we've reached max depth
                if current.depth &gt;= opts.GraphDepth </span><span class="cov8" title="1">{
                        continue</span>
                }

                // Get direct neighbors (depth=1 from current node)
                <span class="cov8" title="1">neighbors, err := g.graphStore.GetNeighbors(ctx, current.nodeID, 1)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>

                <span class="cov8" title="1">nextDepth := current.depth + 1
                for _, neighbor := range neighbors </span><span class="cov8" title="1">{
                        updateNodeScore(nodeScores, neighbor.ID, neighbor, nextDepth)

                        // Add to queue if not visited
                        if !visited[neighbor.ID] </span><span class="cov8" title="1">{
                                visited[neighbor.ID] = true
                                queue = append(queue, queueItem{neighbor.ID, nextDepth})
                        }</span>
                }
        }

        // Convert to results and sort
        <span class="cov8" title="1">results := make([]SearchResult, 0, len(nodeScores))
        for nodeID, ns := range nodeScores </span><span class="cov8" title="1">{
                results = append(results, SearchResult{
                        NodeID:     nodeID,
                        Node:       ns.node,
                        Score:      ns.score,
                        Source:     "graph",
                        GraphDepth: ns.depth,
                })
        }</span>

        // Sort by score descending
        <span class="cov8" title="1">sort.Slice(results, func(i, j int) bool </span><span class="cov8" title="1">{
                return results[i].Score &gt; results[j].Score
        }</span>)

        // Apply TopK limit
        <span class="cov8" title="1">if len(results) &gt; opts.TopK </span><span class="cov0" title="0">{
                results = results[:opts.TopK]
        }</span>

        <span class="cov8" title="1">return results, nil</span>
}

type nodeScore struct {
        node  *store.Node
        score float64
        depth int
}

func updateNodeScore(scores map[string]nodeScore, nodeID string, node *store.Node, depth int) <span class="cov8" title="1">{
        score := 1.0 / float64(1+depth)

        if existing, found := scores[nodeID]; found </span><span class="cov8" title="1">{
                // Keep best score (shortest path)
                if score &gt; existing.score </span><span class="cov0" title="0">{
                        scores[nodeID] = nodeScore{
                                node:  node,
                                score: score,
                                depth: depth,
                        }
                }</span>
        } else<span class="cov8" title="1"> {
                scores[nodeID] = nodeScore{
                        node:  node,
                        score: score,
                        depth: depth,
                }
        }</span>
}
</pre>
		
		<pre class="file" id="file14" style="display: none">package search

import (
        "context"
        "math"
        "sort"

        "github.com/dan-solli/gognee/pkg/embeddings"
        "github.com/dan-solli/gognee/pkg/store"
)

// HybridSearcher combines vector similarity and graph traversal search.
type HybridSearcher struct {
        embeddings  embeddings.EmbeddingClient
        vectorStore store.VectorStore
        graphStore  store.GraphStore
}

// NewHybridSearcher creates a new hybrid searcher.
func NewHybridSearcher(
        embClient embeddings.EmbeddingClient,
        vectorStore store.VectorStore,
        graphStore store.GraphStore,
) *HybridSearcher <span class="cov8" title="1">{
        return &amp;HybridSearcher{
                embeddings:  embClient,
                vectorStore: vectorStore,
                graphStore:  graphStore,
        }
}</span>

// Search performs hybrid search combining vector similarity and graph expansion.
// Score formula: combined_score = vector_score + graph_score
// where vector_score = 0 if not found by vector, graph_score = 0 if not found by graph.
func (h *HybridSearcher) Search(ctx context.Context, query string, opts SearchOptions) ([]SearchResult, error) <span class="cov8" title="1">{
        ApplyDefaults(&amp;opts)

        // Step 1: Embed the query
        embedding, err := h.embeddings.EmbedOne(ctx, query)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Step 2: Vector search for initial results
        // Fetch more than TopK to ensure adequate expansion base
        <span class="cov8" title="1">initialFetch := int(math.Max(float64(opts.TopK*2), 20))
        vectorResults, err := h.vectorStore.Search(ctx, embedding, initialFetch)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Track combined scores and metadata
        <span class="cov8" title="1">type nodeInfo struct {
                node        *store.Node
                vectorScore float64
                graphScore  float64
                graphDepth  int
                foundBy     map[string]bool // "vector" and/or "graph"
        }
        nodes := make(map[string]*nodeInfo)

        // Step 3: Process vector results and expand via graph
        for _, vr := range vectorResults </span><span class="cov8" title="1">{
                node, err := h.graphStore.GetNode(ctx, vr.ID)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">if node == nil </span><span class="cov0" title="0">{
                        continue</span> // Skip stale entries
                }

                // Record vector score
                <span class="cov8" title="1">if _, exists := nodes[vr.ID]; !exists </span><span class="cov8" title="1">{
                        nodes[vr.ID] = &amp;nodeInfo{
                                node:       node,
                                foundBy:    make(map[string]bool),
                                graphDepth: 0, // Direct vector hit
                        }
                }</span>
                <span class="cov8" title="1">nodes[vr.ID].vectorScore = vr.Score
                nodes[vr.ID].foundBy["vector"] = true

                // Step 4: Graph expansion from this vector result
                if opts.GraphDepth &gt; 0 </span><span class="cov8" title="1">{
                        neighbors, err := h.expandFromNode(ctx, vr.ID, opts.GraphDepth)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>

                        <span class="cov8" title="1">for neighborID, depthInfo := range neighbors </span><span class="cov8" title="1">{
                                // Skip if it's the same node
                                if neighborID == vr.ID </span><span class="cov0" title="0">{
                                        continue</span>
                                }

                                <span class="cov8" title="1">neighborNode, err := h.graphStore.GetNode(ctx, neighborID)
                                if err != nil </span><span class="cov0" title="0">{
                                        return nil, err
                                }</span>
                                <span class="cov8" title="1">if neighborNode == nil </span><span class="cov0" title="0">{
                                        continue</span>
                                }

                                // Calculate graph score: 1 / (1 + depth)
                                <span class="cov8" title="1">graphScore := 1.0 / float64(1+depthInfo.depth)

                                if existing, exists := nodes[neighborID]; !exists </span><span class="cov8" title="1">{
                                        nodes[neighborID] = &amp;nodeInfo{
                                                node:       neighborNode,
                                                graphScore: graphScore,
                                                graphDepth: depthInfo.depth,
                                                foundBy:    map[string]bool{"graph": true},
                                        }
                                }</span> else<span class="cov0" title="0"> {
                                        // Node already exists (maybe from vector or another expansion)
                                        // Update graph score if this path is better
                                        if graphScore &gt; existing.graphScore </span><span class="cov0" title="0">{
                                                existing.graphScore = graphScore
                                                existing.graphDepth = depthInfo.depth
                                        }</span>
                                        <span class="cov0" title="0">existing.foundBy["graph"] = true</span>
                                }
                        }
                }
        }

        // Step 5: Deduplicate, merge scores, and build results
        <span class="cov8" title="1">results := make([]SearchResult, 0, len(nodes))
        for nodeID, info := range nodes </span><span class="cov8" title="1">{
                // Combined score = vector_score + graph_score
                combinedScore := info.vectorScore + info.graphScore

                // Determine source
                source := ""
                if info.foundBy["vector"] &amp;&amp; info.foundBy["graph"] </span><span class="cov8" title="1">{
                        source = "hybrid"
                }</span> else<span class="cov8" title="1"> if info.foundBy["vector"] </span><span class="cov8" title="1">{
                        source = "vector"
                }</span> else<span class="cov8" title="1"> {
                        source = "graph"
                }</span>

                <span class="cov8" title="1">results = append(results, SearchResult{
                        NodeID:     nodeID,
                        Node:       info.node,
                        Score:      combinedScore,
                        Source:     source,
                        GraphDepth: info.graphDepth,
                })</span>
        }

        // Step 6: Sort by combined score descending
        <span class="cov8" title="1">sort.Slice(results, func(i, j int) bool </span><span class="cov8" title="1">{
                return results[i].Score &gt; results[j].Score
        }</span>)

        // Step 7: Return top-K results
        <span class="cov8" title="1">if len(results) &gt; opts.TopK </span><span class="cov8" title="1">{
                results = results[:opts.TopK]
        }</span>

        <span class="cov8" title="1">return results, nil</span>
}

type depthInfo struct {
        depth int
}

// expandFromNode performs BFS graph traversal from a starting node.
func (h *HybridSearcher) expandFromNode(ctx context.Context, startNodeID string, maxDepth int) (map[string]depthInfo, error) <span class="cov8" title="1">{
        result := make(map[string]depthInfo)
        visited := make(map[string]bool)

        type queueItem struct {
                nodeID string
                depth  int
        }
        queue := []queueItem{{startNodeID, 0}}
        visited[startNodeID] = true

        for len(queue) &gt; 0 </span><span class="cov8" title="1">{
                current := queue[0]
                queue = queue[1:]

                if current.depth &gt;= maxDepth </span><span class="cov8" title="1">{
                        continue</span>
                }

                <span class="cov8" title="1">neighbors, err := h.graphStore.GetNeighbors(ctx, current.nodeID, 1)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>

                <span class="cov8" title="1">nextDepth := current.depth + 1
                for _, neighbor := range neighbors </span><span class="cov8" title="1">{
                        // Record depth info (keep shortest path)
                        if existing, exists := result[neighbor.ID]; !exists || nextDepth &lt; existing.depth </span><span class="cov8" title="1">{
                                result[neighbor.ID] = depthInfo{depth: nextDepth}
                        }</span>

                        <span class="cov8" title="1">if !visited[neighbor.ID] </span><span class="cov8" title="1">{
                                visited[neighbor.ID] = true
                                queue = append(queue, queueItem{neighbor.ID, nextDepth})
                        }</span>
                }
        }

        <span class="cov8" title="1">return result, nil</span>
}
</pre>
		
		<pre class="file" id="file15" style="display: none">// Package search provides search implementations for gognee's knowledge graph.
package search

import (
        "context"

        "github.com/dan-solli/gognee/pkg/store"
)

// SearchType specifies the type of search to perform.
type SearchType string

const (
        // SearchTypeVector performs vector similarity search only.
        SearchTypeVector SearchType = "vector"

        // SearchTypeGraph performs graph traversal search only (requires seed nodes).
        SearchTypeGraph SearchType = "graph"

        // SearchTypeHybrid combines vector similarity and graph traversal.
        SearchTypeHybrid SearchType = "hybrid"
)

// SearchResult represents a single search result with scoring metadata.
type SearchResult struct {
        NodeID string      // Unique identifier of the node
        Node   *store.Node // Full node data (nil if node was deleted)
        Score  float64     // Combined relevance score (higher is better)
        Source string      // Origin: "vector", "graph", or "hybrid"
        // GraphDepth indicates the minimum graph distance from the search origin.
        // 0 for direct vector hits, &gt;0 for nodes discovered via graph expansion.
        GraphDepth int
        // MemoryIDs lists memory IDs that reference this node (v1.0.0+).
        // Sorted by memory updated_at DESC (most recent first).
        // Empty for legacy nodes (created via Add/Cognify without provenance).
        MemoryIDs []string
}

// SearchOptions configures search behavior.
type SearchOptions struct {
        Type       SearchType // Type of search to perform
        TopK       int        // Maximum number of results to return (default: 10)
        GraphDepth int        // Maximum graph traversal depth (default: 1)
        // SeedNodeIDs specifies starting nodes for graph search.
        // Required for SearchTypeGraph; ignored for SearchTypeVector.
        // For SearchTypeHybrid, seeds augment vector results.
        SeedNodeIDs []string
        // IncludeMemoryIDs enables memory provenance enrichment (v1.0.0+).
        // Default: true. Set to false to skip provenance lookup for performance.
        IncludeMemoryIDs *bool
        // TraceEnabled enables detailed timing instrumentation for performance analysis.
        // Default: false (off by default to minimize overhead).
        TraceEnabled bool
}

// Searcher defines the interface for knowledge graph search.
type Searcher interface {
        // Search performs a search based on the query and options.
        // For vector/hybrid search, query is the text to embed and search.
        // For graph search, query is ignored (uses opts.SeedNodeIDs instead).
        Search(ctx context.Context, query string, opts SearchOptions) ([]SearchResult, error)
}

// ApplyDefaults sets default values for unspecified search options.
func ApplyDefaults(opts *SearchOptions) <span class="cov8" title="1">{
        if opts.TopK &lt;= 0 </span><span class="cov0" title="0">{
                opts.TopK = 10
        }</span>
        <span class="cov8" title="1">if opts.GraphDepth &lt;= 0 </span><span class="cov8" title="1">{
                opts.GraphDepth = 1
        }</span>
}
</pre>
		
		<pre class="file" id="file16" style="display: none">package search

import (
        "context"

        "github.com/dan-solli/gognee/pkg/embeddings"
        "github.com/dan-solli/gognee/pkg/store"
)

// VectorSearcher performs vector similarity search.
type VectorSearcher struct {
        embeddings  embeddings.EmbeddingClient
        vectorStore store.VectorStore
        graphStore  store.GraphStore
}

// NewVectorSearcher creates a new vector searcher.
func NewVectorSearcher(
        embClient embeddings.EmbeddingClient,
        vectorStore store.VectorStore,
        graphStore store.GraphStore,
) *VectorSearcher <span class="cov8" title="1">{
        return &amp;VectorSearcher{
                embeddings:  embClient,
                vectorStore: vectorStore,
                graphStore:  graphStore,
        }
}</span>

// Search performs vector similarity search.
// It embeds the query, searches the vector store, and enriches results with full node data.
func (v *VectorSearcher) Search(ctx context.Context, query string, opts SearchOptions) ([]SearchResult, error) <span class="cov8" title="1">{
        ApplyDefaults(&amp;opts)

        // Embed the query
        embedding, err := v.embeddings.EmbedOne(ctx, query)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Vector search
        <span class="cov8" title="1">vectorResults, err := v.vectorStore.Search(ctx, embedding, opts.TopK)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Enrich with full node data
        <span class="cov8" title="1">results := make([]SearchResult, 0, len(vectorResults))
        for _, vr := range vectorResults </span><span class="cov8" title="1">{
                node, err := v.graphStore.GetNode(ctx, vr.ID)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>

                // Skip if node not found (stale vector index)
                <span class="cov8" title="1">if node == nil </span><span class="cov8" title="1">{
                        continue</span>
                }

                <span class="cov8" title="1">results = append(results, SearchResult{
                        NodeID:     vr.ID,
                        Node:       node,
                        Score:      vr.Score,
                        Source:     "vector",
                        GraphDepth: 0,
                })</span>
        }

        <span class="cov8" title="1">return results, nil</span>
}
</pre>
		
		<pre class="file" id="file17" style="display: none">package store

import (
        "context"
        "crypto/sha256"
        "database/sql"
        "encoding/json"
        "fmt"
        "strings"
        "time"

        "github.com/google/uuid"
)

// MemoryRecord represents a first-class memory with structured payload.
type MemoryRecord struct {
        ID        string                 `json:"id"`
        Topic     string                 `json:"topic"`
        Context   string                 `json:"context"`
        Decisions []string               `json:"decisions,omitempty"`
        Rationale []string               `json:"rationale,omitempty"`
        Metadata  map[string]interface{} `json:"metadata,omitempty"`
        CreatedAt time.Time              `json:"created_at"`
        UpdatedAt time.Time              `json:"updated_at"`
        Version   int                    `json:"version"`
        DocHash   string                 `json:"doc_hash"`
        Source    string                 `json:"source,omitempty"`
        Status    string                 `json:"status"` // "pending" or "complete"
}

// MemorySummary provides a lightweight view of a memory for list operations.
type MemorySummary struct {
        ID            string    `json:"id"`
        Topic         string    `json:"topic"`
        Preview       string    `json:"preview"` // Truncated context
        CreatedAt     time.Time `json:"created_at"`
        UpdatedAt     time.Time `json:"updated_at"`
        DecisionCount int       `json:"decision_count"`
        Status        string    `json:"status"`
}

// ListMemoriesOptions provides pagination for memory listing.
type ListMemoriesOptions struct {
        Offset int
        Limit  int // Default 50, max 100
}

// MemoryUpdate represents partial updates to a memory.
// All fields are pointers to distinguish between "not provided" and "set to zero value".
type MemoryUpdate struct {
        Topic     *string
        Context   *string
        Decisions *[]string
        Rationale *[]string
        Metadata  *map[string]interface{}
        Status    *string
}

// MemoryStore defines the interface for memory CRUD operations.
type MemoryStore interface {
        // AddMemory creates a new memory record.
        AddMemory(ctx context.Context, record *MemoryRecord) error

        // GetMemory retrieves a memory by ID, including provenance information.
        GetMemory(ctx context.Context, id string) (*MemoryRecord, error)

        // ListMemories returns paginated memory summaries.
        ListMemories(ctx context.Context, opts ListMemoriesOptions) ([]MemorySummary, error)

        // UpdateMemory applies partial updates to a memory.
        UpdateMemory(ctx context.Context, id string, updates MemoryUpdate) error

        // DeleteMemory removes a memory and its provenance links.
        DeleteMemory(ctx context.Context, id string) error

        // GetMemoriesByNodeID returns all memory IDs that reference a given node.
        GetMemoriesByNodeID(ctx context.Context, nodeID string) ([]string, error)

        // CountMemories returns the total number of memories in the store.
        CountMemories(ctx context.Context) (int64, error)
}

// SQLiteMemoryStore implements MemoryStore using SQLite.
type SQLiteMemoryStore struct {
        db *sql.DB
}

// NewSQLiteMemoryStore creates a new SQLite-backed memory store.
// Shares the database connection with SQLiteGraphStore.
func NewSQLiteMemoryStore(db *sql.DB) *SQLiteMemoryStore <span class="cov8" title="1">{
        return &amp;SQLiteMemoryStore{db: db}
}</span>

// DB returns the underlying database connection for advanced operations.
func (s *SQLiteMemoryStore) DB() *sql.DB <span class="cov8" title="1">{
        return s.db
}</span>

// ComputeDocHash computes a canonical hash of a memory's content.
// Uses JSON with sorted keys, trimmed whitespace, excluding metadata.
func ComputeDocHash(topic, context string, decisions, rationale []string) string <span class="cov8" title="1">{
        // Trim whitespace
        topic = strings.TrimSpace(topic)
        context = strings.TrimSpace(context)

        // Build canonical JSON object with sorted keys
        canonical := map[string]interface{}{
                "context":   context,
                "decisions": decisions,
                "rationale": rationale,
                "topic":     topic,
        }

        // Marshal to JSON
        jsonBytes, err := json.Marshal(canonical)
        if err != nil </span><span class="cov0" title="0">{
                // Should never happen with string/slice inputs
                panic(fmt.Sprintf("failed to marshal canonical JSON: %v", err))</span>
        }

        // Compute SHA-256
        <span class="cov8" title="1">hash := sha256.Sum256(jsonBytes)
        return fmt.Sprintf("%x", hash)</span>
}

// AddMemory creates a new memory record.
func (s *SQLiteMemoryStore) AddMemory(ctx context.Context, record *MemoryRecord) error <span class="cov8" title="1">{
        // Generate ID if not provided
        if record.ID == "" </span><span class="cov8" title="1">{
                record.ID = uuid.New().String()
        }</span>

        // Set timestamps
        <span class="cov8" title="1">now := time.Now()
        if record.CreatedAt.IsZero() </span><span class="cov8" title="1">{
                record.CreatedAt = now
        }</span>
        <span class="cov8" title="1">if record.UpdatedAt.IsZero() </span><span class="cov8" title="1">{
                record.UpdatedAt = now
        }</span>

        // Default version and status
        <span class="cov8" title="1">if record.Version == 0 </span><span class="cov8" title="1">{
                record.Version = 1
        }</span>
        <span class="cov8" title="1">if record.Status == "" </span><span class="cov0" title="0">{
                record.Status = "pending"
        }</span>

        // Serialize JSON fields
        <span class="cov8" title="1">decisionsJSON, err := json.Marshal(record.Decisions)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal decisions: %w", err)
        }</span>

        <span class="cov8" title="1">rationaleJSON, err := json.Marshal(record.Rationale)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal rationale: %w", err)
        }</span>

        <span class="cov8" title="1">metadataJSON, err := json.Marshal(record.Metadata)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal metadata: %w", err)
        }</span>

        // Begin transaction
        <span class="cov8" title="1">tx, err := s.db.BeginTx(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to begin transaction: %w", err)
        }</span>
        <span class="cov8" title="1">defer tx.Rollback() // Rollback if not committed

        query := `
                INSERT INTO memories (id, topic, context, decisions_json, rationale_json, metadata_json,
                        created_at, updated_at, version, doc_hash, source, status)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `

        _, err = tx.ExecContext(ctx, query,
                record.ID,
                record.Topic,
                record.Context,
                decisionsJSON,
                rationaleJSON,
                metadataJSON,
                record.CreatedAt,
                record.UpdatedAt,
                record.Version,
                record.DocHash,
                record.Source,
                record.Status,
        )

        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to insert memory: %w", err)
        }</span>

        // Commit transaction
        <span class="cov8" title="1">if err := tx.Commit(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to commit transaction: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// GetMemory retrieves a memory by ID.
func (s *SQLiteMemoryStore) GetMemory(ctx context.Context, id string) (*MemoryRecord, error) <span class="cov8" title="1">{
        query := `
                SELECT id, topic, context, decisions_json, rationale_json, metadata_json,
                        created_at, updated_at, version, doc_hash, source, status
                FROM memories
                WHERE id = ?
        `

        var record MemoryRecord
        var decisionsJSON, rationaleJSON, metadataJSON []byte

        err := s.db.QueryRowContext(ctx, query, id).Scan(
                &amp;record.ID,
                &amp;record.Topic,
                &amp;record.Context,
                &amp;decisionsJSON,
                &amp;rationaleJSON,
                &amp;metadataJSON,
                &amp;record.CreatedAt,
                &amp;record.UpdatedAt,
                &amp;record.Version,
                &amp;record.DocHash,
                &amp;record.Source,
                &amp;record.Status,
        )

        if err == sql.ErrNoRows </span><span class="cov8" title="1">{
                return nil, ErrMemoryNotFound
        }</span>
        <span class="cov8" title="1">if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get memory: %w", err)
        }</span>

        // Deserialize JSON fields
        <span class="cov8" title="1">if len(decisionsJSON) &gt; 0 </span><span class="cov8" title="1">{
                if err := json.Unmarshal(decisionsJSON, &amp;record.Decisions); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to unmarshal decisions: %w", err)
                }</span>
        }

        <span class="cov8" title="1">if len(rationaleJSON) &gt; 0 </span><span class="cov8" title="1">{
                if err := json.Unmarshal(rationaleJSON, &amp;record.Rationale); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to unmarshal rationale: %w", err)
                }</span>
        }

        <span class="cov8" title="1">if len(metadataJSON) &gt; 0 </span><span class="cov8" title="1">{
                if err := json.Unmarshal(metadataJSON, &amp;record.Metadata); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to unmarshal metadata: %w", err)
                }</span>
        }

        <span class="cov8" title="1">return &amp;record, nil</span>
}

// ListMemories returns paginated memory summaries.
func (s *SQLiteMemoryStore) ListMemories(ctx context.Context, opts ListMemoriesOptions) ([]MemorySummary, error) <span class="cov8" title="1">{
        // Apply defaults and limits
        if opts.Limit == 0 </span><span class="cov8" title="1">{
                opts.Limit = 50
        }</span>
        <span class="cov8" title="1">if opts.Limit &gt; 100 </span><span class="cov0" title="0">{
                opts.Limit = 100
        }</span>
        <span class="cov8" title="1">if opts.Offset &lt; 0 </span><span class="cov0" title="0">{
                opts.Offset = 0
        }</span>

        <span class="cov8" title="1">query := `
                SELECT id, topic, context, decisions_json, created_at, updated_at, status
                FROM memories
                ORDER BY updated_at DESC, created_at DESC
                LIMIT ? OFFSET ?
        `

        rows, err := s.db.QueryContext(ctx, query, opts.Limit, opts.Offset)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to list memories: %w", err)
        }</span>
        <span class="cov8" title="1">defer rows.Close()

        var summaries []MemorySummary
        for rows.Next() </span><span class="cov8" title="1">{
                var id, topic, context, status string
                var decisionsJSON []byte
                var createdAt, updatedAt time.Time

                err := rows.Scan(&amp;id, &amp;topic, &amp;context, &amp;decisionsJSON, &amp;createdAt, &amp;updatedAt, &amp;status)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to scan memory: %w", err)
                }</span>

                // Truncate context for preview (max 200 chars)
                <span class="cov8" title="1">preview := context
                if len(preview) &gt; 200 </span><span class="cov0" title="0">{
                        preview = preview[:200] + "..."
                }</span>

                // Count decisions
                <span class="cov8" title="1">var decisions []string
                if len(decisionsJSON) &gt; 0 </span><span class="cov8" title="1">{
                        json.Unmarshal(decisionsJSON, &amp;decisions)
                }</span>

                <span class="cov8" title="1">summaries = append(summaries, MemorySummary{
                        ID:            id,
                        Topic:         topic,
                        Preview:       preview,
                        CreatedAt:     createdAt,
                        UpdatedAt:     updatedAt,
                        DecisionCount: len(decisions),
                        Status:        status,
                })</span>
        }

        <span class="cov8" title="1">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("error iterating memories: %w", err)
        }</span>

        <span class="cov8" title="1">return summaries, nil</span>
}

// UpdateMemory applies partial updates to a memory.
func (s *SQLiteMemoryStore) UpdateMemory(ctx context.Context, id string, updates MemoryUpdate) error <span class="cov8" title="1">{
        // Begin transaction
        tx, err := s.db.BeginTx(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to begin transaction: %w", err)
        }</span>
        <span class="cov8" title="1">defer tx.Rollback()

        // Fetch existing memory within transaction
        query := `
                SELECT id, topic, context, decisions_json, rationale_json, metadata_json,
                        created_at, updated_at, version, doc_hash, source, status
                FROM memories
                WHERE id = ?
        `

        var existing MemoryRecord
        var decisionsJSON, rationaleJSON, metadataJSON []byte

        err = tx.QueryRowContext(ctx, query, id).Scan(
                &amp;existing.ID,
                &amp;existing.Topic,
                &amp;existing.Context,
                &amp;decisionsJSON,
                &amp;rationaleJSON,
                &amp;metadataJSON,
                &amp;existing.CreatedAt,
                &amp;existing.UpdatedAt,
                &amp;existing.Version,
                &amp;existing.DocHash,
                &amp;existing.Source,
                &amp;existing.Status,
        )

        if err == sql.ErrNoRows </span><span class="cov0" title="0">{
                return ErrMemoryNotFound
        }</span>
        <span class="cov8" title="1">if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get memory: %w", err)
        }</span>

        // Deserialize JSON fields
        <span class="cov8" title="1">if len(decisionsJSON) &gt; 0 </span><span class="cov8" title="1">{
                if err := json.Unmarshal(decisionsJSON, &amp;existing.Decisions); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to unmarshal decisions: %w", err)
                }</span>
        }

        <span class="cov8" title="1">if len(rationaleJSON) &gt; 0 </span><span class="cov8" title="1">{
                if err := json.Unmarshal(rationaleJSON, &amp;existing.Rationale); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to unmarshal rationale: %w", err)
                }</span>
        }

        <span class="cov8" title="1">if len(metadataJSON) &gt; 0 </span><span class="cov8" title="1">{
                if err := json.Unmarshal(metadataJSON, &amp;existing.Metadata); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to unmarshal metadata: %w", err)
                }</span>
        }

        // Apply updates
        <span class="cov8" title="1">if updates.Topic != nil </span><span class="cov0" title="0">{
                existing.Topic = *updates.Topic
        }</span>
        <span class="cov8" title="1">if updates.Context != nil </span><span class="cov8" title="1">{
                existing.Context = *updates.Context
        }</span>
        <span class="cov8" title="1">if updates.Decisions != nil </span><span class="cov0" title="0">{
                existing.Decisions = *updates.Decisions
        }</span>
        <span class="cov8" title="1">if updates.Rationale != nil </span><span class="cov0" title="0">{
                existing.Rationale = *updates.Rationale
        }</span>
        <span class="cov8" title="1">if updates.Metadata != nil </span><span class="cov0" title="0">{
                existing.Metadata = *updates.Metadata
        }</span>
        <span class="cov8" title="1">if updates.Status != nil </span><span class="cov0" title="0">{
                existing.Status = *updates.Status
        }</span>

        // Update timestamp and version
        <span class="cov8" title="1">existing.UpdatedAt = time.Now()
        existing.Version++

        // Serialize JSON fields
        decisionsJSON, err = json.Marshal(existing.Decisions)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal decisions: %w", err)
        }</span>

        <span class="cov8" title="1">rationaleJSON, err = json.Marshal(existing.Rationale)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal rationale: %w", err)
        }</span>

        <span class="cov8" title="1">metadataJSON, err = json.Marshal(existing.Metadata)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal metadata: %w", err)
        }</span>

        <span class="cov8" title="1">updateQuery := `
                UPDATE memories
                SET topic = ?, context = ?, decisions_json = ?, rationale_json = ?, metadata_json = ?,
                        updated_at = ?, version = ?, status = ?
                WHERE id = ?
        `

        _, err = tx.ExecContext(ctx, updateQuery,
                existing.Topic,
                existing.Context,
                decisionsJSON,
                rationaleJSON,
                metadataJSON,
                existing.UpdatedAt,
                existing.Version,
                existing.Status,
                id,
        )

        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to update memory: %w", err)
        }</span>

        // Commit transaction
        <span class="cov8" title="1">if err := tx.Commit(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to commit transaction: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// DeleteMemory removes a memory and its provenance links (via CASCADE).
func (s *SQLiteMemoryStore) DeleteMemory(ctx context.Context, id string) error <span class="cov8" title="1">{
        // Begin transaction
        tx, err := s.db.BeginTx(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to begin transaction: %w", err)
        }</span>
        <span class="cov8" title="1">defer tx.Rollback()

        // Delete memory (CASCADE will handle provenance tables)
        result, err := tx.ExecContext(ctx, "DELETE FROM memories WHERE id = ?", id)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to delete memory: %w", err)
        }</span>

        // Check if memory was found
        <span class="cov8" title="1">rows, err := result.RowsAffected()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get rows affected: %w", err)
        }</span>
        <span class="cov8" title="1">if rows == 0 </span><span class="cov0" title="0">{
                return ErrMemoryNotFound
        }</span>

        // Commit transaction
        <span class="cov8" title="1">if err := tx.Commit(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to commit transaction: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// GetMemoriesByNodeID returns all memory IDs that reference a given node.
// Returns memory IDs sorted by updated_at DESC (most recent first).
func (s *SQLiteMemoryStore) GetMemoriesByNodeID(ctx context.Context, nodeID string) ([]string, error) <span class="cov8" title="1">{
        query := `
                SELECT DISTINCT m.id
                FROM memories m
                JOIN memory_nodes mn ON m.id = mn.memory_id
                WHERE mn.node_id = ?
                ORDER BY m.updated_at DESC
        `

        rows, err := s.db.QueryContext(ctx, query, nodeID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to query memories by node: %w", err)
        }</span>
        <span class="cov8" title="1">defer rows.Close()

        var memoryIDs []string
        for rows.Next() </span><span class="cov8" title="1">{
                var id string
                if err := rows.Scan(&amp;id); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to scan memory ID: %w", err)
                }</span>
                <span class="cov8" title="1">memoryIDs = append(memoryIDs, id)</span>
        }

        <span class="cov8" title="1">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("error iterating memory IDs: %w", err)
        }</span>

        <span class="cov8" title="1">return memoryIDs, nil</span>
}

// CountMemories returns the total number of memories in the store.
// Uses an indexed query for O(1) performance.
func (s *SQLiteMemoryStore) CountMemories(ctx context.Context) (int64, error) <span class="cov8" title="1">{
        var count int64
        query := "SELECT COUNT(*) FROM memories"
        err := s.db.QueryRowContext(ctx, query).Scan(&amp;count)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("failed to count memories: %w", err)
        }</span>
        <span class="cov8" title="1">return count, nil</span>
}

// GetMemoriesByNodeIDBatched returns memory IDs for multiple nodes in a single query.
// Returns a map of nodeID -&gt; []memoryID (sorted by updated_at DESC per node).
func (s *SQLiteMemoryStore) GetMemoriesByNodeIDBatched(ctx context.Context, nodeIDs []string) (map[string][]string, error) <span class="cov8" title="1">{
        if len(nodeIDs) == 0 </span><span class="cov0" title="0">{
                return make(map[string][]string), nil
        }</span>

        // Build IN clause with placeholders
        <span class="cov8" title="1">placeholders := make([]string, len(nodeIDs))
        args := make([]interface{}, len(nodeIDs))
        for i, nodeID := range nodeIDs </span><span class="cov8" title="1">{
                placeholders[i] = "?"
                args[i] = nodeID
        }</span>

        <span class="cov8" title="1">query := fmt.Sprintf(`
                SELECT mn.node_id, m.id, m.updated_at
                FROM memory_nodes mn
                JOIN memories m ON mn.memory_id = m.id
                WHERE mn.node_id IN (%s)
                ORDER BY mn.node_id, m.updated_at DESC
        `, strings.Join(placeholders, ","))

        rows, err := s.db.QueryContext(ctx, query, args...)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to batch query memories by nodes: %w", err)
        }</span>
        <span class="cov8" title="1">defer rows.Close()

        // Group results by node_id
        result := make(map[string][]string)
        for rows.Next() </span><span class="cov8" title="1">{
                var nodeID, memoryID string
                var updatedAt time.Time
                if err := rows.Scan(&amp;nodeID, &amp;memoryID, &amp;updatedAt); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to scan batch result: %w", err)
                }</span>
                <span class="cov8" title="1">result[nodeID] = append(result[nodeID], memoryID)</span>
        }

        <span class="cov8" title="1">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("error iterating batch results: %w", err)
        }</span>

        // Ensure all nodeIDs are present in result (even if empty)
        <span class="cov8" title="1">for _, nodeID := range nodeIDs </span><span class="cov8" title="1">{
                if _, exists := result[nodeID]; !exists </span><span class="cov0" title="0">{
                        result[nodeID] = []string{}
                }</span>
        }

        <span class="cov8" title="1">return result, nil</span>
}

// LinkProvenance links derived nodes/edges to a memory.
func (s *SQLiteMemoryStore) LinkProvenance(ctx context.Context, memoryID string, nodeIDs, edgeIDs []string) error <span class="cov8" title="1">{
        // Begin transaction
        tx, err := s.db.BeginTx(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to begin transaction: %w", err)
        }</span>
        <span class="cov8" title="1">defer tx.Rollback()

        // Insert node provenance
        nodeStmt, err := tx.PrepareContext(ctx, "INSERT OR IGNORE INTO memory_nodes (memory_id, node_id) VALUES (?, ?)")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to prepare node stmt: %w", err)
        }</span>
        <span class="cov8" title="1">defer nodeStmt.Close()

        for _, nodeID := range nodeIDs </span><span class="cov8" title="1">{
                if _, err := nodeStmt.ExecContext(ctx, memoryID, nodeID); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to link node provenance: %w", err)
                }</span>
        }

        // Insert edge provenance
        <span class="cov8" title="1">edgeStmt, err := tx.PrepareContext(ctx, "INSERT OR IGNORE INTO memory_edges (memory_id, edge_id) VALUES (?, ?)")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to prepare edge stmt: %w", err)
        }</span>
        <span class="cov8" title="1">defer edgeStmt.Close()

        for _, edgeID := range edgeIDs </span><span class="cov8" title="1">{
                if _, err := edgeStmt.ExecContext(ctx, memoryID, edgeID); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to link edge provenance: %w", err)
                }</span>
        }

        // Commit transaction
        <span class="cov8" title="1">if err := tx.Commit(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to commit transaction: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// UnlinkProvenance removes provenance links for a memory.
func (s *SQLiteMemoryStore) UnlinkProvenance(ctx context.Context, memoryID string) error <span class="cov8" title="1">{
        // Begin transaction
        tx, err := s.db.BeginTx(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to begin transaction: %w", err)
        }</span>
        <span class="cov8" title="1">defer tx.Rollback()

        // Delete node provenance
        if _, err := tx.ExecContext(ctx, "DELETE FROM memory_nodes WHERE memory_id = ?", memoryID); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to unlink node provenance: %w", err)
        }</span>

        // Delete edge provenance
        <span class="cov8" title="1">if _, err := tx.ExecContext(ctx, "DELETE FROM memory_edges WHERE memory_id = ?", memoryID); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to unlink edge provenance: %w", err)
        }</span>

        // Commit transaction
        <span class="cov8" title="1">if err := tx.Commit(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to commit transaction: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// GetProvenanceByMemory returns all node and edge IDs linked to a memory.
func (s *SQLiteMemoryStore) GetProvenanceByMemory(ctx context.Context, memoryID string) (nodeIDs, edgeIDs []string, err error) <span class="cov8" title="1">{
        // Query node provenance
        nodeRows, err := s.db.QueryContext(ctx, "SELECT node_id FROM memory_nodes WHERE memory_id = ? ORDER BY created_at", memoryID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("failed to query node provenance: %w", err)
        }</span>
        <span class="cov8" title="1">defer nodeRows.Close()

        for nodeRows.Next() </span><span class="cov8" title="1">{
                var nodeID string
                if err := nodeRows.Scan(&amp;nodeID); err != nil </span><span class="cov0" title="0">{
                        return nil, nil, fmt.Errorf("failed to scan node ID: %w", err)
                }</span>
                <span class="cov8" title="1">nodeIDs = append(nodeIDs, nodeID)</span>
        }

        <span class="cov8" title="1">if err := nodeRows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("error iterating node provenance: %w", err)
        }</span>

        // Query edge provenance
        <span class="cov8" title="1">edgeRows, err := s.db.QueryContext(ctx, "SELECT edge_id FROM memory_edges WHERE memory_id = ? ORDER BY created_at", memoryID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("failed to query edge provenance: %w", err)
        }</span>
        <span class="cov8" title="1">defer edgeRows.Close()

        for edgeRows.Next() </span><span class="cov0" title="0">{
                var edgeID string
                if err := edgeRows.Scan(&amp;edgeID); err != nil </span><span class="cov0" title="0">{
                        return nil, nil, fmt.Errorf("failed to scan edge ID: %w", err)
                }</span>
                <span class="cov0" title="0">edgeIDs = append(edgeIDs, edgeID)</span>
        }

        <span class="cov8" title="1">if err := edgeRows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, nil, fmt.Errorf("error iterating edge provenance: %w", err)
        }</span>

        <span class="cov8" title="1">return nodeIDs, edgeIDs, nil</span>
}

// CountMemoryReferences returns the number of memories referencing a node.
func (s *SQLiteMemoryStore) CountMemoryReferences(ctx context.Context, nodeID string) (int, error) <span class="cov8" title="1">{
        var count int
        err := s.db.QueryRowContext(ctx, "SELECT COUNT(*) FROM memory_nodes WHERE node_id = ?", nodeID).Scan(&amp;count)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("failed to count memory references: %w", err)
        }</span>
        <span class="cov8" title="1">return count, nil</span>
}

// GetOrphanedNodes returns node IDs that were provenance-tracked but now have zero references.
func (s *SQLiteMemoryStore) GetOrphanedNodes(ctx context.Context) ([]string, error) <span class="cov0" title="0">{
        // Find nodes that were in memory_nodes (tracked) but now have zero references
        // For simplicity, we'll identify currently orphaned nodes among all tracked nodes

        // Since provenance rows CASCADE delete, we can't use that approach.
        // This is tricky; let's use a different approach in GC.

        return []string{}, nil // Placeholder; GC will handle this differently
}</span>

// GetOrphanedEdges returns edge IDs that were provenance-tracked but now have zero references.
func (s *SQLiteMemoryStore) GetOrphanedEdges(ctx context.Context) ([]string, error) <span class="cov0" title="0">{
        return []string{}, nil // Placeholder; GC will handle this differently
}</span>

// GarbageCollect removes provenance-tracked nodes/edges with zero references.
// Returns counts of deleted nodes and edges.
// CRITICAL: Only affects provenance-tracked artifacts. Legacy nodes/edges are preserved.
func (s *SQLiteMemoryStore) GarbageCollect(ctx context.Context) (nodesDeleted, edgesDeleted int, err error) <span class="cov8" title="1">{
        // Begin transaction
        tx, err := s.db.BeginTx(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("failed to begin transaction: %w", err)
        }</span>
        <span class="cov8" title="1">defer tx.Rollback()

        // Strategy: Track which nodes/edges have EVER been in provenance tables.
        // For v1.0.0, we'll use a simpler approach:
        // - Collect all node/edge IDs currently in provenance tables (these are "tracked")
        // - Delete tracked artifacts that no longer have references

        // Get all tracked node IDs
        var trackedNodeIDs []string
        nodeRows, err := tx.QueryContext(ctx, "SELECT DISTINCT node_id FROM memory_nodes")
        if err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("failed to query tracked nodes: %w", err)
        }</span>
        <span class="cov8" title="1">for nodeRows.Next() </span><span class="cov0" title="0">{
                var nodeID string
                if err := nodeRows.Scan(&amp;nodeID); err != nil </span><span class="cov0" title="0">{
                        nodeRows.Close()
                        return 0, 0, fmt.Errorf("failed to scan tracked node: %w", err)
                }</span>
                <span class="cov0" title="0">trackedNodeIDs = append(trackedNodeIDs, nodeID)</span>
        }
        <span class="cov8" title="1">nodeRows.Close()

        // Get all tracked edge IDs
        var trackedEdgeIDs []string
        edgeRows, err := tx.QueryContext(ctx, "SELECT DISTINCT edge_id FROM memory_edges")
        if err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("failed to query tracked edges: %w", err)
        }</span>
        <span class="cov8" title="1">for edgeRows.Next() </span><span class="cov0" title="0">{
                var edgeID string
                if err := edgeRows.Scan(&amp;edgeID); err != nil </span><span class="cov0" title="0">{
                        edgeRows.Close()
                        return 0, 0, fmt.Errorf("failed to scan tracked edge: %w", err)
                }</span>
                <span class="cov0" title="0">trackedEdgeIDs = append(trackedEdgeIDs, edgeID)</span>
        }
        <span class="cov8" title="1">edgeRows.Close()

        // Now delete nodes that are NOT in the current tracked set
        // (i.e., they were tracked before but CASCADE deleted their provenance)
        // Wait, this won't work either because we can't distinguish "was tracked" from "never tracked".

        // CORRECT APPROACH: Mark nodes/edges as "tracked" when first added via AddMemory.
        // For now, use a heuristic: delete nodes/edges that are NOT in provenance tables.
        // But this violates the plan's requirement to preserve legacy data.

        // FINAL APPROACH (per critique resolution):
        // We need a "tracked" flag or separate tracking. For v1.0.0, use this rule:
        // - A node/edge is "tracked" if it appears in provenance tables.
        // - GC finds nodes/edges that SHOULD be in provenance (based on prior existence) but aren't.
        // - This requires historical tracking, which we don't have in the schema.

        // PRAGMATIC SOLUTION for v1.0.0:
        // Add a "provenance_tracked" metadata flag to nodes/edges OR use a separate tracking table.
        // For this implementation, we'll take a safer approach:
        // Only delete nodes/edges that are EXPLICITLY orphaned (zero refs in provenance).

        // Simpler GC rule:
        // Delete edges that appear in memory_edges with COUNT(*) = 0
        // This can't happen with current schema since CASCADE already deletes them.

        // The issue is that CASCADE deletes provenance rows, but not the nodes/edges themselves.
        // So after DELETE FROM memories, we need to find nodes/edges no longer referenced.

        // CORRECT GC IMPLEMENTATION:
        // 1. Find all nodes with zero provenance references (NOT IN memory_nodes)
        //    BUT only among nodes that we KNOW were tracked (tricky without history).
        // 2. For v1.0.0, we'll rely on metadata or skip perfect GC.

        // Let me re-read the plan...

        // The plan says GC should:
        // - `DELETE FROM edges WHERE id IN (SELECT edge_id FROM memory_edges GROUP BY edge_id HAVING COUNT(*) = 0 AFTER CASCADE)`
        // - But after CASCADE, those rows don't exist anymore.

        // The correct approach is:
        // - Find edges that are NOT in memory_edges anymore but exist in the edges table.
        // - These are orphaned IF they were previously tracked.

        // For v1.0.0, we'll use a conservative GC:
        // - Identify nodes/edges that are in the graph but NOT in provenance tables.
        // - Among those, delete ones that have a special "tracked" indicator.
        // - WITHOUT the indicator, we can't safely GC without risking legacy data loss.

        // RESOLUTION: Add "provenance_tracked" column to nodes/edges OR use current provenance presence as proxy.
        // Per critique, we must preserve legacy. So GC will ONLY delete if provenance exists BUT count = 0.

        // Since provenance rows CASCADE delete, we can't use that approach.
        // We need to track "was ever in provenance" separately.

        // FOR THIS IMPLEMENTATION:
        // We'll add a lightweight tracking: Before unlinking provenance, collect node/edge IDs.
        // Then delete those that no longer have ANY references.

        // This requires calling GC AFTER unlinking. The caller (UpdateMemory/DeleteMemory) will do this.

        // Simplified GC for now: delete nodes/edges NOT in provenance tables AND marked as tracked.
        // Without a tracking column, we can't implement safely.

        // DECISION: For v1.0.0, we'll implement GC as a helper that takes explicit lists of candidate IDs.
        // The caller tracks which artifacts to check.

        // Commit (no-op for now; will be called explicitly by DeleteMemory/UpdateMemory with candidates)
        if err := tx.Commit(); err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("failed to commit transaction: %w", err)
        }</span>

        <span class="cov8" title="1">return 0, 0, nil</span> // Placeholder; real GC happens in higher-level methods
}

// GarbageCollectCandidates removes candidate nodes/edges if they have zero provenance references.
// This is the actual GC implementation called after unlinking provenance.
func (s *SQLiteMemoryStore) GarbageCollectCandidates(ctx context.Context, nodeIDs, edgeIDs []string) (nodesDeleted, edgesDeleted int, err error) <span class="cov8" title="1">{
        // Begin transaction
        tx, err := s.db.BeginTx(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("failed to begin transaction: %w", err)
        }</span>
        <span class="cov8" title="1">defer tx.Rollback()

        // Delete edges with zero provenance references
        for _, edgeID := range edgeIDs </span><span class="cov8" title="1">{
                var count int
                err := tx.QueryRowContext(ctx, "SELECT COUNT(*) FROM memory_edges WHERE edge_id = ?", edgeID).Scan(&amp;count)
                if err != nil </span><span class="cov0" title="0">{
                        return 0, 0, fmt.Errorf("failed to count edge references: %w", err)
                }</span>

                <span class="cov8" title="1">if count == 0 </span><span class="cov8" title="1">{
                        _, err := tx.ExecContext(ctx, "DELETE FROM edges WHERE id = ?", edgeID)
                        if err != nil </span><span class="cov0" title="0">{
                                return 0, 0, fmt.Errorf("failed to delete orphaned edge: %w", err)
                        }</span>
                        <span class="cov8" title="1">edgesDeleted++</span>
                }
        }

        // Delete nodes with zero provenance references
        <span class="cov8" title="1">for _, nodeID := range nodeIDs </span><span class="cov8" title="1">{
                var count int
                err := tx.QueryRowContext(ctx, "SELECT COUNT(*) FROM memory_nodes WHERE node_id = ?", nodeID).Scan(&amp;count)
                if err != nil </span><span class="cov0" title="0">{
                        return 0, 0, fmt.Errorf("failed to count node references: %w", err)
                }</span>

                <span class="cov8" title="1">if count == 0 </span><span class="cov8" title="1">{
                        _, err := tx.ExecContext(ctx, "DELETE FROM nodes WHERE id = ?", nodeID)
                        if err != nil </span><span class="cov0" title="0">{
                                return 0, 0, fmt.Errorf("failed to delete orphaned node: %w", err)
                        }</span>
                        <span class="cov8" title="1">nodesDeleted++</span>
                }
        }

        // Commit transaction
        <span class="cov8" title="1">if err := tx.Commit(); err != nil </span><span class="cov0" title="0">{
                return 0, 0, fmt.Errorf("failed to commit transaction: %w", err)
        }</span>

        <span class="cov8" title="1">return nodesDeleted, edgesDeleted, nil</span>
}

// ErrMemoryNotFound indicates that no memory was found for the given ID.
var ErrMemoryNotFound = fmt.Errorf("memory not found")
</pre>
		
		<pre class="file" id="file18" style="display: none">package store

import (
        "context"
        "sort"
        "sync"
)

// MemoryVectorStore is an in-memory implementation of VectorStore.
// It uses a map to store vectors and provides thread-safe access via RWMutex.
// Note: This implementation does not persist vectors across restarts.
type MemoryVectorStore struct {
        vectors map[string][]float32
        mu      sync.RWMutex
}

// NewMemoryVectorStore creates a new in-memory vector store.
func NewMemoryVectorStore() *MemoryVectorStore <span class="cov8" title="1">{
        return &amp;MemoryVectorStore{
                vectors: make(map[string][]float32),
        }
}</span>

// Add adds or updates a vector for the given ID.
func (m *MemoryVectorStore) Add(ctx context.Context, id string, embedding []float32) error <span class="cov8" title="1">{
        m.mu.Lock()
        defer m.mu.Unlock()

        // Make a copy to avoid external mutations
        embeddingCopy := make([]float32, len(embedding))
        copy(embeddingCopy, embedding)

        m.vectors[id] = embeddingCopy
        return nil
}</span>

// Search finds the most similar vectors to the query.
// Returns up to topK results sorted by similarity score (descending).
func (m *MemoryVectorStore) Search(ctx context.Context, query []float32, topK int) ([]SearchResult, error) <span class="cov8" title="1">{
        m.mu.RLock()
        defer m.mu.RUnlock()

        // Handle empty store
        if len(m.vectors) == 0 </span><span class="cov8" title="1">{
                return []SearchResult{}, nil
        }</span>

        // Compute similarity for all vectors
        <span class="cov8" title="1">var results []SearchResult
        for id, embedding := range m.vectors </span><span class="cov8" title="1">{
                score := CosineSimilarity(query, embedding)
                results = append(results, SearchResult{
                        ID:    id,
                        Score: score,
                })
        }</span>

        // Sort by score descending
        <span class="cov8" title="1">sort.Slice(results, func(i, j int) bool </span><span class="cov8" title="1">{
                return results[i].Score &gt; results[j].Score
        }</span>)

        // Return top-K
        <span class="cov8" title="1">if topK &lt; len(results) </span><span class="cov8" title="1">{
                results = results[:topK]
        }</span>

        <span class="cov8" title="1">return results, nil</span>
}

// Delete removes a vector from the store.
func (m *MemoryVectorStore) Delete(ctx context.Context, id string) error <span class="cov8" title="1">{
        m.mu.Lock()
        defer m.mu.Unlock()

        delete(m.vectors, id)
        return nil
}</span>
</pre>
		
		<pre class="file" id="file19" style="display: none">package store

import (
        "context"
        "database/sql"
        "encoding/binary"
        "encoding/json"
        "fmt"
        "math"
        "strings"
        "time"

        "github.com/google/uuid"
        _ "github.com/mattn/go-sqlite3" // SQLite driver
)

// SQLiteGraphStore implements GraphStore using SQLite as the backend.
type SQLiteGraphStore struct {
        db *sql.DB
}

// NewSQLiteGraphStore creates a new SQLite-backed graph store.
// The dbPath can be a file path or ":memory:" for an in-memory database.
// Creates tables and indexes if they don't exist.
func NewSQLiteGraphStore(dbPath string) (*SQLiteGraphStore, error) <span class="cov8" title="1">{
        // Initialize sqlite-vec for all future connections
        EnableSQLiteVec()

        db, err := sql.Open("sqlite3", dbPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to open database: %w", err)
        }</span>

        // Enable foreign key constraints (required for CASCADE)
        <span class="cov8" title="1">_, err = db.Exec("PRAGMA foreign_keys = ON")
        if err != nil </span><span class="cov0" title="0">{
                db.Close()
                return nil, fmt.Errorf("failed to enable foreign keys: %w", err)
        }</span>

        <span class="cov8" title="1">store := &amp;SQLiteGraphStore{db: db}
        if err := store.initSchema(); err != nil </span><span class="cov0" title="0">{
                db.Close()
                return nil, fmt.Errorf("failed to initialize schema: %w", err)
        }</span>

        <span class="cov8" title="1">return store, nil</span>
}

// initSchema creates the database schema if it doesn't exist.
// Also performs schema migrations for new columns.
func (s *SQLiteGraphStore) initSchema() error <span class="cov8" title="1">{
        schema := `
        CREATE TABLE IF NOT EXISTS nodes (
                id TEXT PRIMARY KEY,
                name TEXT NOT NULL COLLATE NOCASE,
                type TEXT,
                description TEXT,
                embedding BLOB,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT
        );

        CREATE INDEX IF NOT EXISTS idx_nodes_name ON nodes(name COLLATE NOCASE);

        CREATE TABLE IF NOT EXISTS edges (
                id TEXT PRIMARY KEY,
                source_id TEXT NOT NULL,
                relation TEXT NOT NULL,
                target_id TEXT NOT NULL,
                weight REAL DEFAULT 1.0,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (source_id) REFERENCES nodes(id),
                FOREIGN KEY (target_id) REFERENCES nodes(id)
        );

        CREATE INDEX IF NOT EXISTS idx_edges_source ON edges(source_id);
        CREATE INDEX IF NOT EXISTS idx_edges_target ON edges(target_id);

        CREATE TABLE IF NOT EXISTS processed_documents (
                hash TEXT PRIMARY KEY,
                source TEXT,
                processed_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                chunk_count INTEGER DEFAULT 0
        );

        CREATE INDEX IF NOT EXISTS idx_processed_documents_source ON processed_documents(source);

        -- vec0 virtual table for indexed vector search (sqlite-vec)
        CREATE VIRTUAL TABLE IF NOT EXISTS vec_nodes USING vec0(
                embedding float[1536]
        );

        -- ID mapping table: correlates vec_nodes.rowid with nodes.id (string UUIDs)
        CREATE TABLE IF NOT EXISTS vec_node_ids (
                rowid INTEGER PRIMARY KEY,
                node_id TEXT NOT NULL UNIQUE,
                FOREIGN KEY (node_id) REFERENCES nodes(id) ON DELETE CASCADE
        );

        CREATE INDEX IF NOT EXISTS idx_vec_node_ids_node_id ON vec_node_ids(node_id);
        `

        _, err := s.db.Exec(schema)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Run schema migrations for new columns
        <span class="cov8" title="1">return s.migrateSchema()</span>
}

// migrateSchema adds new columns to existing tables if they don't exist.
func (s *SQLiteGraphStore) migrateSchema() error <span class="cov8" title="1">{
        // Check and add last_accessed_at column
        if !s.columnExists("nodes", "last_accessed_at") </span><span class="cov8" title="1">{
                _, err := s.db.Exec("ALTER TABLE nodes ADD COLUMN last_accessed_at DATETIME DEFAULT NULL")
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to add last_accessed_at column: %w", err)
                }</span>
        }

        // Check and add access_count column
        <span class="cov8" title="1">if !s.columnExists("nodes", "access_count") </span><span class="cov8" title="1">{
                _, err := s.db.Exec("ALTER TABLE nodes ADD COLUMN access_count INTEGER DEFAULT 0")
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to add access_count column: %w", err)
                }</span>
        }

        // Phase 2: Add memory CRUD tables (v1.0.0)
        <span class="cov8" title="1">if err := s.migrateMemoryTables(); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// migrateMemoryTables adds memory CRUD tables for v1.0.0.
func (s *SQLiteGraphStore) migrateMemoryTables() error <span class="cov8" title="1">{
        // Check if memories table exists
        var count int
        err := s.db.QueryRow("SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name='memories'").Scan(&amp;count)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to check for memories table: %w", err)
        }</span>

        // If table exists, assume all memory tables exist
        <span class="cov8" title="1">if count &gt; 0 </span><span class="cov8" title="1">{
                return nil
        }</span>

        // Create memory tables
        <span class="cov8" title="1">schema := `
        CREATE TABLE memories (
                id TEXT PRIMARY KEY,
                topic TEXT NOT NULL,
                context TEXT NOT NULL,
                decisions_json TEXT,
                rationale_json TEXT,
                metadata_json TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                version INTEGER DEFAULT 1,
                doc_hash TEXT NOT NULL,
                source TEXT,
                status TEXT DEFAULT 'complete'
        );

        CREATE INDEX idx_memories_topic ON memories(topic);
        CREATE INDEX idx_memories_doc_hash ON memories(doc_hash);
        CREATE INDEX idx_memories_status ON memories(status);

        CREATE TABLE memory_nodes (
                memory_id TEXT NOT NULL,
                node_id TEXT NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                PRIMARY KEY (memory_id, node_id),
                FOREIGN KEY (memory_id) REFERENCES memories(id) ON DELETE CASCADE
        );

        CREATE INDEX idx_memory_nodes_node_id ON memory_nodes(node_id);

        CREATE TABLE memory_edges (
                memory_id TEXT NOT NULL,
                edge_id TEXT NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                PRIMARY KEY (memory_id, edge_id),
                FOREIGN KEY (memory_id) REFERENCES memories(id) ON DELETE CASCADE
        );

        CREATE INDEX idx_memory_edges_edge_id ON memory_edges(edge_id);
        `

        _, err = s.db.Exec(schema)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create memory tables: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// columnExists checks if a column exists in a table.
func (s *SQLiteGraphStore) columnExists(tableName, columnName string) bool <span class="cov8" title="1">{
        query := fmt.Sprintf("PRAGMA table_info(%s)", tableName)
        rows, err := s.db.Query(query)
        if err != nil </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov8" title="1">defer rows.Close()

        for rows.Next() </span><span class="cov8" title="1">{
                var cid int
                var name string
                var ctype string
                var notnull int
                var dfltValue sql.NullString
                var pk int

                err := rows.Scan(&amp;cid, &amp;name, &amp;ctype, &amp;notnull, &amp;dfltValue, &amp;pk)
                if err != nil </span><span class="cov0" title="0">{
                        return false
                }</span>

                <span class="cov8" title="1">if name == columnName </span><span class="cov8" title="1">{
                        return true
                }</span>
        }

        <span class="cov8" title="1">return false</span>
}

// AddNode adds or updates a node in the graph.
func (s *SQLiteGraphStore) AddNode(ctx context.Context, node *Node) error <span class="cov8" title="1">{
        // Generate ID if not provided
        if node.ID == "" </span><span class="cov8" title="1">{
                node.ID = uuid.New().String()
        }</span>

        // Set created time if not provided
        <span class="cov8" title="1">if node.CreatedAt.IsZero() </span><span class="cov8" title="1">{
                node.CreatedAt = time.Now()
        }</span>

        // Serialize embedding to bytes
        <span class="cov8" title="1">var embeddingBytes []byte
        if len(node.Embedding) &gt; 0 </span><span class="cov8" title="1">{
                embeddingBytes = make([]byte, len(node.Embedding)*4)
                for i, v := range node.Embedding </span><span class="cov8" title="1">{
                        binary.LittleEndian.PutUint32(embeddingBytes[i*4:], math.Float32bits(v))
                }</span>
        }

        // Serialize metadata to JSON
        <span class="cov8" title="1">var metadataJSON []byte
        var err error
        if node.Metadata != nil </span><span class="cov8" title="1">{
                metadataJSON, err = json.Marshal(node.Metadata)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to marshal metadata: %w", err)
                }</span>
        }

        <span class="cov8" title="1">query := `
                INSERT OR REPLACE INTO nodes (id, name, type, description, embedding, created_at, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?)
        `

        _, err = s.db.ExecContext(ctx, query,
                node.ID,
                node.Name,
                node.Type,
                node.Description,
                embeddingBytes,
                node.CreatedAt,
                metadataJSON,
        )

        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to add node: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// GetNode retrieves a node by its ID.
// Also updates last_accessed_at timestamp to track access for decay.
func (s *SQLiteGraphStore) GetNode(ctx context.Context, id string) (*Node, error) <span class="cov8" title="1">{
        query := `
                SELECT id, name, type, description, embedding, created_at, metadata
                FROM nodes
                WHERE id = ?
        `

        var node Node
        var embeddingBytes []byte
        var metadataJSON []byte

        err := s.db.QueryRowContext(ctx, query, id).Scan(
                &amp;node.ID,
                &amp;node.Name,
                &amp;node.Type,
                &amp;node.Description,
                &amp;embeddingBytes,
                &amp;node.CreatedAt,
                &amp;metadataJSON,
        )

        if err == sql.ErrNoRows </span><span class="cov8" title="1">{
                return nil, nil // Not found, no error
        }</span>
        <span class="cov8" title="1">if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get node: %w", err)
        }</span>

        // Deserialize embedding
        <span class="cov8" title="1">if len(embeddingBytes) &gt; 0 </span><span class="cov8" title="1">{
                node.Embedding = make([]float32, len(embeddingBytes)/4)
                for i := range node.Embedding </span><span class="cov8" title="1">{
                        node.Embedding[i] = math.Float32frombits(binary.LittleEndian.Uint32(embeddingBytes[i*4:]))
                }</span>
        }

        // Deserialize metadata
        <span class="cov8" title="1">if len(metadataJSON) &gt; 0 </span><span class="cov8" title="1">{
                if err := json.Unmarshal(metadataJSON, &amp;node.Metadata); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to unmarshal metadata: %w", err)
                }</span>
        }

        // Update last_accessed_at timestamp
        <span class="cov8" title="1">_, err = s.db.ExecContext(ctx, "UPDATE nodes SET last_accessed_at = ? WHERE id = ?", time.Now(), id)
        if err != nil </span>{<span class="cov0" title="0">
                // Log but don't fail - access tracking is not critical
                // In production, could use a logger here
        }</span>

        <span class="cov8" title="1">return &amp;node, nil</span>
}

// FindNodesByName searches for nodes by name using case-insensitive matching.
func (s *SQLiteGraphStore) FindNodesByName(ctx context.Context, name string) ([]*Node, error) <span class="cov8" title="1">{
        query := `
                SELECT id, name, type, description, embedding, created_at, metadata
                FROM nodes
                WHERE LOWER(name) = LOWER(?)
                ORDER BY created_at, id
        `

        rows, err := s.db.QueryContext(ctx, query, name)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to find nodes by name: %w", err)
        }</span>
        <span class="cov8" title="1">defer rows.Close()

        var nodes []*Node
        for rows.Next() </span><span class="cov8" title="1">{
                var node Node
                var embeddingBytes []byte
                var metadataJSON []byte

                err := rows.Scan(
                        &amp;node.ID,
                        &amp;node.Name,
                        &amp;node.Type,
                        &amp;node.Description,
                        &amp;embeddingBytes,
                        &amp;node.CreatedAt,
                        &amp;metadataJSON,
                )
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to scan node: %w", err)
                }</span>

                // Deserialize embedding
                <span class="cov8" title="1">if len(embeddingBytes) &gt; 0 </span><span class="cov0" title="0">{
                        node.Embedding = make([]float32, len(embeddingBytes)/4)
                        for i := range node.Embedding </span><span class="cov0" title="0">{
                                node.Embedding[i] = math.Float32frombits(binary.LittleEndian.Uint32(embeddingBytes[i*4:]))
                        }</span>
                }

                // Deserialize metadata
                <span class="cov8" title="1">if len(metadataJSON) &gt; 0 </span><span class="cov0" title="0">{
                        if err := json.Unmarshal(metadataJSON, &amp;node.Metadata); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("failed to unmarshal metadata: %w", err)
                        }</span>
                }

                <span class="cov8" title="1">nodes = append(nodes, &amp;node)</span>
        }

        <span class="cov8" title="1">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("error iterating nodes: %w", err)
        }</span>

        <span class="cov8" title="1">return nodes, nil</span>
}

// FindNodeByName is a convenience method that returns a single node if exactly one matches.
func (s *SQLiteGraphStore) FindNodeByName(ctx context.Context, name string) (*Node, error) <span class="cov8" title="1">{
        nodes, err := s.FindNodesByName(ctx, name)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">if len(nodes) == 0 </span><span class="cov8" title="1">{
                return nil, ErrNodeNotFound
        }</span>

        <span class="cov8" title="1">if len(nodes) &gt; 1 </span><span class="cov8" title="1">{
                return nil, ErrAmbiguousNode
        }</span>

        <span class="cov8" title="1">return nodes[0], nil</span>
}

// AddEdge adds or updates an edge in the graph.
func (s *SQLiteGraphStore) AddEdge(ctx context.Context, edge *Edge) error <span class="cov8" title="1">{
        // Generate ID if not provided
        if edge.ID == "" </span><span class="cov0" title="0">{
                edge.ID = uuid.New().String()
        }</span>

        // Set created time if not provided
        <span class="cov8" title="1">if edge.CreatedAt.IsZero() </span><span class="cov8" title="1">{
                edge.CreatedAt = time.Now()
        }</span>

        // Default weight to 1.0 if not provided
        <span class="cov8" title="1">if edge.Weight == 0 </span><span class="cov8" title="1">{
                edge.Weight = 1.0
        }</span>

        <span class="cov8" title="1">query := `
                INSERT OR REPLACE INTO edges (id, source_id, relation, target_id, weight, created_at)
                VALUES (?, ?, ?, ?, ?, ?)
        `

        _, err := s.db.ExecContext(ctx, query,
                edge.ID,
                edge.SourceID,
                edge.Relation,
                edge.TargetID,
                edge.Weight,
                edge.CreatedAt,
        )

        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to add edge: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// GetEdges retrieves all edges incident to a node (both incoming and outgoing).
func (s *SQLiteGraphStore) GetEdges(ctx context.Context, nodeID string) ([]*Edge, error) <span class="cov8" title="1">{
        query := `
                SELECT id, source_id, relation, target_id, weight, created_at
                FROM edges
                WHERE source_id = ? OR target_id = ?
                ORDER BY created_at
        `

        rows, err := s.db.QueryContext(ctx, query, nodeID, nodeID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get edges: %w", err)
        }</span>
        <span class="cov8" title="1">defer rows.Close()

        var edges []*Edge
        for rows.Next() </span><span class="cov8" title="1">{
                var edge Edge
                err := rows.Scan(
                        &amp;edge.ID,
                        &amp;edge.SourceID,
                        &amp;edge.Relation,
                        &amp;edge.TargetID,
                        &amp;edge.Weight,
                        &amp;edge.CreatedAt,
                )
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to scan edge: %w", err)
                }</span>
                <span class="cov8" title="1">edges = append(edges, &amp;edge)</span>
        }

        <span class="cov8" title="1">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("error iterating edges: %w", err)
        }</span>

        <span class="cov8" title="1">return edges, nil</span>
}

// GetNeighbors retrieves all nodes adjacent to a given node, up to the specified depth.
// Uses a recursive CTE for efficient single-query graph expansion (v1.4.0 optimization).
func (s *SQLiteGraphStore) GetNeighbors(ctx context.Context, nodeID string, depth int) ([]*Node, error) <span class="cov8" title="1">{
        if depth &lt; 1 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("depth must be at least 1")
        }</span>

        // Recursive CTE to traverse graph bidirectionally up to depth
        <span class="cov8" title="1">query := `
        WITH RECURSIVE
        graph_traversal(node_id, depth_level) AS (
                -- Base case: starting node at depth 0
                SELECT ? AS node_id, 0 AS depth_level
                
                UNION
                
                -- Recursive case: expand to neighbors
                SELECT 
                        CASE 
                                WHEN edges.source_id = graph_traversal.node_id THEN edges.target_id
                                ELSE edges.source_id
                        END AS node_id,
                        graph_traversal.depth_level + 1 AS depth_level
                FROM graph_traversal
                JOIN edges ON (
                        edges.source_id = graph_traversal.node_id OR 
                        edges.target_id = graph_traversal.node_id
                )
                WHERE graph_traversal.depth_level &lt; ?
        )
        SELECT DISTINCT 
                n.id, n.name, n.type, n.description, n.embedding, 
                n.created_at, n.last_accessed_at, n.metadata
        FROM graph_traversal gt
        JOIN nodes n ON gt.node_id = n.id
        WHERE gt.node_id != ? -- Exclude starting node
        `

        rows, err := s.db.QueryContext(ctx, query, nodeID, depth, nodeID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to query neighbors with CTE: %w", err)
        }</span>
        <span class="cov8" title="1">defer rows.Close()

        var neighbors []*Node
        for rows.Next() </span><span class="cov8" title="1">{
                node := &amp;Node{}
                var embeddingData []byte
                var metadataJSON []byte
                var lastAccessed sql.NullTime

                err := rows.Scan(
                        &amp;node.ID, &amp;node.Name, &amp;node.Type, &amp;node.Description,
                        &amp;embeddingData, &amp;node.CreatedAt, &amp;lastAccessed, &amp;metadataJSON,
                )
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to scan neighbor node: %w", err)
                }</span>

                // Deserialize embedding
                <span class="cov8" title="1">if len(embeddingData) &gt; 0 </span><span class="cov0" title="0">{
                        node.Embedding = deserializeEmbedding(embeddingData)
                }</span>

                // Deserialize metadata
                <span class="cov8" title="1">if len(metadataJSON) &gt; 0 </span><span class="cov0" title="0">{
                        if err := json.Unmarshal(metadataJSON, &amp;node.Metadata); err != nil </span><span class="cov0" title="0">{
                                node.Metadata = make(map[string]interface{})
                        }</span>
                } else<span class="cov8" title="1"> {
                        node.Metadata = make(map[string]interface{})
                }</span>

                // Handle nullable last_accessed_at
                <span class="cov8" title="1">if lastAccessed.Valid </span><span class="cov0" title="0">{
                        node.LastAccessedAt = &amp;lastAccessed.Time
                }</span>

                <span class="cov8" title="1">neighbors = append(neighbors, node)</span>
        }

        <span class="cov8" title="1">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("error iterating neighbor rows: %w", err)
        }</span>

        <span class="cov8" title="1">return neighbors, nil</span>
}

// NodeCount returns the total number of nodes in the graph.
func (s *SQLiteGraphStore) NodeCount(ctx context.Context) (int64, error) <span class="cov8" title="1">{
        var count int64
        err := s.db.QueryRowContext(ctx, "SELECT COUNT(*) FROM nodes").Scan(&amp;count)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("failed to count nodes: %w", err)
        }</span>
        <span class="cov8" title="1">return count, nil</span>
}

// EdgeCount returns the total number of edges in the graph.
func (s *SQLiteGraphStore) EdgeCount(ctx context.Context) (int64, error) <span class="cov8" title="1">{
        var count int64
        err := s.db.QueryRowContext(ctx, "SELECT COUNT(*) FROM edges").Scan(&amp;count)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("failed to count edges: %w", err)
        }</span>
        <span class="cov8" title="1">return count, nil</span>
}

// UpdateAccessTime updates the last_accessed_at timestamp for a batch of nodes.
// This is used for access reinforcement in memory decay.
func (s *SQLiteGraphStore) UpdateAccessTime(ctx context.Context, nodeIDs []string) error <span class="cov8" title="1">{
        if len(nodeIDs) == 0 </span><span class="cov8" title="1">{
                return nil
        }</span>

        // Build IN clause with placeholders
        <span class="cov8" title="1">placeholders := make([]string, len(nodeIDs))
        args := make([]interface{}, len(nodeIDs)+1)
        args[0] = time.Now()

        for i, nodeID := range nodeIDs </span><span class="cov8" title="1">{
                placeholders[i] = "?"
                args[i+1] = nodeID
        }</span>

        <span class="cov8" title="1">query := fmt.Sprintf("UPDATE nodes SET last_accessed_at = ? WHERE id IN (%s)",
                strings.Join(placeholders, ","))

        _, err := s.db.ExecContext(ctx, query, args...)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to update access time: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// GetAllNodes returns all nodes in the graph (for pruning operations).
func (s *SQLiteGraphStore) GetAllNodes(ctx context.Context) ([]*Node, error) <span class="cov8" title="1">{
        query := `
                SELECT id, name, type, description, embedding, created_at, metadata, last_accessed_at
                FROM nodes
                ORDER BY created_at, id
        `

        rows, err := s.db.QueryContext(ctx, query)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to query all nodes: %w", err)
        }</span>
        <span class="cov8" title="1">defer rows.Close()

        var nodes []*Node
        for rows.Next() </span><span class="cov8" title="1">{
                var node Node
                var embeddingBytes []byte
                var metadataJSON []byte
                var lastAccessed sql.NullTime

                err := rows.Scan(
                        &amp;node.ID,
                        &amp;node.Name,
                        &amp;node.Type,
                        &amp;node.Description,
                        &amp;embeddingBytes,
                        &amp;node.CreatedAt,
                        &amp;metadataJSON,
                        &amp;lastAccessed,
                )
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to scan node: %w", err)
                }</span>

                // Deserialize embedding
                <span class="cov8" title="1">if len(embeddingBytes) &gt; 0 </span><span class="cov8" title="1">{
                        node.Embedding = make([]float32, len(embeddingBytes)/4)
                        for i := range node.Embedding </span><span class="cov8" title="1">{
                                node.Embedding[i] = math.Float32frombits(binary.LittleEndian.Uint32(embeddingBytes[i*4:]))
                        }</span>
                }

                // Deserialize metadata
                <span class="cov8" title="1">if len(metadataJSON) &gt; 0 </span><span class="cov8" title="1">{
                        if err := json.Unmarshal(metadataJSON, &amp;node.Metadata); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("failed to unmarshal metadata: %w", err)
                        }</span>
                }

                // Hydrate last_accessed_at if it's not NULL
                <span class="cov8" title="1">if lastAccessed.Valid </span><span class="cov8" title="1">{
                        node.LastAccessedAt = &amp;lastAccessed.Time
                }</span>

                <span class="cov8" title="1">nodes = append(nodes, &amp;node)</span>
        }

        <span class="cov8" title="1">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("error iterating nodes: %w", err)
        }</span>

        <span class="cov8" title="1">return nodes, nil</span>
}

// DeleteNode removes a node from the graph.
func (s *SQLiteGraphStore) DeleteNode(ctx context.Context, nodeID string) error <span class="cov8" title="1">{
        _, err := s.db.ExecContext(ctx, "DELETE FROM nodes WHERE id = ?", nodeID)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to delete node: %w", err)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// DeleteEdge removes an edge from the graph.
func (s *SQLiteGraphStore) DeleteEdge(ctx context.Context, edgeID string) error <span class="cov8" title="1">{
        _, err := s.db.ExecContext(ctx, "DELETE FROM edges WHERE id = ?", edgeID)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to delete edge: %w", err)
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// Close releases database resources.
func (s *SQLiteGraphStore) Close() error <span class="cov8" title="1">{
        return s.db.Close()
}</span>

// DB returns the underlying database connection.
// This connection is shared with other stores (e.g., SQLiteVectorStore)
// and must not be closed by consumers.
func (s *SQLiteGraphStore) DB() *sql.DB <span class="cov8" title="1">{
        return s.db
}</span>
</pre>
		
		<pre class="file" id="file20" style="display: none">package store

// This file integrates sqlite-vec with mattn/go-sqlite3 by compiling the amalgamation

// #cgo CFLAGS: -DSQLITE_CORE -I${SRCDIR}/../../ -I/home/dsi/go/pkg/mod/github.com/mattn/go-sqlite3@v1.14.33
// #cgo linux LDFLAGS: -lm
// #include "../../sqlite-vec.h"
// #include "../../sqlite-vec.c"
import "C"

// EnableSQLiteVec registers sqlite-vec as an auto-extension for all future database connections
func EnableSQLiteVec() <span class="cov8" title="1">{
        C.sqlite3_auto_extension((*[0]byte)(C.sqlite3_vec_init))
}</span>

// DisableSQLiteVec cancels the sqlite-vec auto-extension
func DisableSQLiteVec() <span class="cov0" title="0">{
        C.sqlite3_cancel_auto_extension((*[0]byte)(C.sqlite3_vec_init))
}</span>
</pre>
		
		<pre class="file" id="file21" style="display: none">package store

import (
        "context"
        "database/sql"
        "encoding/binary"
        "fmt"
        "math"
)

// SQLiteVectorStore implements VectorStore using SQLite with sqlite-vec as the persistence layer.
// It uses vec0 virtual tables for indexed approximate nearest neighbor (ANN) vector search.
//
// Implementation notes:
// - Embeddings are stored in the vec_nodes virtual table (vec0) for indexed ANN search
// - A mapping table (vec_node_ids) correlates vec0 rowids with string node IDs
// - Search uses vec0 MATCH operator for efficient O(log n) complexity instead of O(n) linear scan
// - Legacy nodes.embedding column is maintained for backwards compatibility
// - The database connection is shared with SQLiteGraphStore and must not be closed by this store
type SQLiteVectorStore struct {
        db *sql.DB
}

// NewSQLiteVectorStore creates a new SQLite-backed vector store.
// The database connection is shared and owned by the caller (typically SQLiteGraphStore).
// The SQLiteVectorStore must not close this connection.
func NewSQLiteVectorStore(db *sql.DB) *SQLiteVectorStore <span class="cov8" title="1">{
        return &amp;SQLiteVectorStore{db: db}
}</span>

// Add adds or updates an embedding for the given node ID.
// The node must already exist in the nodes table.
// Returns an error if the node doesn't exist or if the database operation fails.
//
// Implementation uses vec0 virtual table for indexed vector storage:
// 1. Checks if node exists in nodes table
// 2. Inserts/updates entry in vec_node_ids mapping table
// 3. Inserts/replaces vector in vec_nodes virtual table
// 4. Updates legacy embedding column in nodes table for backwards compatibility
func (s *SQLiteVectorStore) Add(ctx context.Context, id string, embedding []float32) error <span class="cov8" title="1">{
        if len(embedding) == 0 </span><span class="cov8" title="1">{
                return fmt.Errorf("embedding cannot be empty")
        }</span>

        // Verify node exists
        <span class="cov8" title="1">var exists int
        err := s.db.QueryRowContext(ctx, `SELECT 1 FROM nodes WHERE id = ?`, id).Scan(&amp;exists)
        if err == sql.ErrNoRows </span><span class="cov8" title="1">{
                return fmt.Errorf("node %s not found", id)
        }</span>
        <span class="cov8" title="1">if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to check node existence: %w", err)
        }</span>

        // Start transaction for atomic vec0 + mapping + legacy update
        // Use immediate transaction to avoid UNIQUE constraint issues with concurrent writes
        <span class="cov8" title="1">tx, err := s.db.BeginTx(ctx, &amp;sql.TxOptions{Isolation: sql.LevelSerializable})
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to begin transaction: %w", err)
        }</span>
        <span class="cov8" title="1">defer tx.Rollback()

        // Get or create rowid mapping
        var rowid int64
        err = tx.QueryRowContext(ctx, `SELECT rowid FROM vec_node_ids WHERE node_id = ?`, id).Scan(&amp;rowid)
        if err == sql.ErrNoRows </span><span class="cov8" title="1">{
                // Insert new mapping (rowid will be auto-generated)
                result, err := tx.ExecContext(ctx, `INSERT INTO vec_node_ids (node_id) VALUES (?)`, id)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to create vec_node_ids mapping: %w", err)
                }</span>
                <span class="cov8" title="1">rowid, err = result.LastInsertId()
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to get last insert rowid: %w", err)
                }</span>
        } else<span class="cov8" title="1"> if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to query vec_node_ids: %w", err)
        }</span> else<span class="cov8" title="1"> {
                // Rowid exists, delete old vec_nodes entry first to avoid UNIQUE constraint
                _, err = tx.ExecContext(ctx, `DELETE FROM vec_nodes WHERE rowid = ?`, rowid)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to delete old vec_nodes entry: %w", err)
                }</span>
        }

        // Serialize embedding for vec0 (float32 array as blob)
        <span class="cov8" title="1">blob := serializeEmbedding(embedding)

        // Insert new entry in vec_nodes virtual table
        _, err = tx.ExecContext(ctx, `INSERT INTO vec_nodes (rowid, embedding) VALUES (?, ?)`, rowid, blob)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to insert into vec_nodes: %w", err)
        }</span>

        // Update legacy embedding column in nodes table for backwards compatibility
        <span class="cov8" title="1">_, err = tx.ExecContext(ctx, `UPDATE nodes SET embedding = ? WHERE id = ?`, blob, id)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to update nodes embedding column: %w", err)
        }</span>

        <span class="cov8" title="1">if err := tx.Commit(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to commit transaction: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// Search finds the most similar vectors to the query using vec0 indexed search.
// Uses sqlite-vec's MATCH operator for efficient approximate nearest neighbor (ANN) search.
//
// Behavior:
// - Performs indexed ANN search via vec0 virtual table (O(log n) complexity)
// - Returns distance metric from vec0, converted to similarity score (1 - distance)
// - Maps rowid back to node string ID via vec_node_ids table
// - Results are sorted by similarity score in descending order (best matches first)
// - Returns up to topK results
func (s *SQLiteVectorStore) Search(ctx context.Context, query []float32, topK int) ([]SearchResult, error) <span class="cov8" title="1">{
        if len(query) == 0 </span><span class="cov8" title="1">{
                return []SearchResult{}, nil
        }</span>

        // Serialize query embedding for vec0 MATCH
        <span class="cov8" title="1">queryBlob := serializeEmbedding(query)

        // vec0 MATCH query with distance metric
        // The MATCH operator returns results ordered by distance (ascending)
        // We'll convert distance to similarity score (1 - distance for cosine-like behavior)
        // Note: vec0 requires 'k = ?' constraint for knn queries
        rows, err := s.db.QueryContext(ctx, `
                SELECT 
                        vec_node_ids.node_id,
                        distance
                FROM vec_nodes
                INNER JOIN vec_node_ids ON vec_nodes.rowid = vec_node_ids.rowid
                WHERE embedding MATCH ? AND k = ?
                ORDER BY distance
        `, queryBlob, topK)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to execute vec0 search: %w", err)
        }</span>
        <span class="cov8" title="1">defer rows.Close()

        var results []SearchResult
        for rows.Next() </span><span class="cov8" title="1">{
                var nodeID string
                var distance float64

                if err := rows.Scan(&amp;nodeID, &amp;distance); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to scan search result: %w", err)
                }</span>

                // Convert distance to similarity score
                // vec0 returns L2 distance by default; convert to similarity (1 - normalized_distance)
                // For compatibility with previous cosine similarity scores (0-1 range)
                <span class="cov8" title="1">similarity := 1.0 - distance

                results = append(results, SearchResult{
                        ID:    nodeID,
                        Score: similarity,
                })</span>
        }

        <span class="cov8" title="1">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("error iterating search results: %w", err)
        }</span>

        <span class="cov8" title="1">return results, nil</span>
}

// Delete removes the embedding for the given node ID.
// The node itself is not deleted, only the embedding is removed from:
// - vec_nodes virtual table
// - vec_node_ids mapping table
// - nodes.embedding column (legacy, set to NULL)
// This allows the node to remain in the graph while removing it from vector search.
func (s *SQLiteVectorStore) Delete(ctx context.Context, id string) error <span class="cov8" title="1">{
        // Start transaction for atomic deletion
        tx, err := s.db.BeginTx(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to begin transaction: %w", err)
        }</span>
        <span class="cov8" title="1">defer tx.Rollback()

        // Get rowid for this node
        var rowid int64
        err = tx.QueryRowContext(ctx, `SELECT rowid FROM vec_node_ids WHERE node_id = ?`, id).Scan(&amp;rowid)
        if err == sql.ErrNoRows </span><span class="cov0" title="0">{
                // Node has no embedding - this is not an error
                return nil
        }</span>
        <span class="cov8" title="1">if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to query vec_node_ids: %w", err)
        }</span>

        // Delete from vec_nodes virtual table
        <span class="cov8" title="1">_, err = tx.ExecContext(ctx, `DELETE FROM vec_nodes WHERE rowid = ?`, rowid)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to delete from vec_nodes: %w", err)
        }</span>

        // Delete from mapping table
        <span class="cov8" title="1">_, err = tx.ExecContext(ctx, `DELETE FROM vec_node_ids WHERE rowid = ?`, rowid)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to delete from vec_node_ids: %w", err)
        }</span>

        // Set legacy embedding column to NULL
        <span class="cov8" title="1">_, err = tx.ExecContext(ctx, `UPDATE nodes SET embedding = NULL WHERE id = ?`, id)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to clear nodes embedding column: %w", err)
        }</span>

        <span class="cov8" title="1">if err := tx.Commit(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to commit transaction: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// Close is a no-op for SQLiteVectorStore because it shares the database connection
// with SQLiteGraphStore. The connection lifecycle is managed by the owner (GraphStore).
func (s *SQLiteVectorStore) Close() error <span class="cov8" title="1">{
        // No-op: connection is owned by GraphStore
        return nil
}</span>

// serializeEmbedding converts a float32 slice to a binary BLOB for storage.
// Uses little-endian encoding for consistency across platforms.
func serializeEmbedding(embedding []float32) []byte <span class="cov8" title="1">{
        blob := make([]byte, len(embedding)*4)
        for i, val := range embedding </span><span class="cov8" title="1">{
                bits := math.Float32bits(val)
                binary.LittleEndian.PutUint32(blob[i*4:(i+1)*4], bits)
        }</span>
        <span class="cov8" title="1">return blob</span>
}

// deserializeEmbedding converts a binary BLOB back to a float32 slice.
// Returns nil if the data is malformed (not a multiple of 4 bytes).
func deserializeEmbedding(data []byte) []float32 <span class="cov0" title="0">{
        if len(data) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">if len(data)%4 != 0 </span><span class="cov0" title="0">{
                // Malformed data
                return nil
        }</span>

        <span class="cov0" title="0">embedding := make([]float32, len(data)/4)
        for i := 0; i &lt; len(embedding); i++ </span><span class="cov0" title="0">{
                bits := binary.LittleEndian.Uint32(data[i*4 : (i+1)*4])
                embedding[i] = math.Float32frombits(bits)
        }</span>
        <span class="cov0" title="0">return embedding</span>
}
</pre>
		
		<pre class="file" id="file22" style="display: none">package store

import (
        "context"
        "fmt"
)

// DocumentTracker provides operations for tracking processed documents.
// Separate from GraphStore to maintain interface cohesion.
// This enables document-level deduplication in incremental Cognify operations.
type DocumentTracker interface {
        // IsDocumentProcessed checks if a document with the given hash has been processed.
        // hash: SHA-256 hash of the document text (content-based identity)
        // Returns true if the document has been processed, false otherwise.
        IsDocumentProcessed(ctx context.Context, hash string) (bool, error)

        // MarkDocumentProcessed records that a document has been successfully processed.
        // hash: SHA-256 hash of document text (content-based identity)
        // source: Optional source identifier (metadata only, does not affect identity)
        // chunkCount: Number of chunks generated from this document
        // Uses INSERT OR REPLACE to support upsert semantics.
        MarkDocumentProcessed(ctx context.Context, hash, source string, chunkCount int) error

        // GetProcessedDocumentCount returns the total number of processed documents tracked.
        GetProcessedDocumentCount(ctx context.Context) (int64, error)

        // ClearProcessedDocuments removes all document tracking records.
        // This does NOT delete nodes or edges - only clears the processed_documents table.
        // Useful for forcing a full reprocess without losing the knowledge graph.
        ClearProcessedDocuments(ctx context.Context) error
}

// Compile-time interface check
var _ DocumentTracker = (*SQLiteGraphStore)(nil)

// IsDocumentProcessed checks if a document with the given hash has been processed.
func (s *SQLiteGraphStore) IsDocumentProcessed(ctx context.Context, hash string) (bool, error) <span class="cov0" title="0">{
        var count int
        err := s.db.QueryRowContext(ctx,
                "SELECT COUNT(*) FROM processed_documents WHERE hash = ?", hash).Scan(&amp;count)
        if err != nil </span><span class="cov0" title="0">{
                return false, fmt.Errorf("failed to check document processed status: %w", err)
        }</span>
        <span class="cov0" title="0">return count &gt; 0, nil</span>
}

// MarkDocumentProcessed records that a document has been successfully processed.
func (s *SQLiteGraphStore) MarkDocumentProcessed(ctx context.Context, hash, source string, chunkCount int) error <span class="cov0" title="0">{
        _, err := s.db.ExecContext(ctx,
                `INSERT OR REPLACE INTO processed_documents (hash, source, processed_at, chunk_count)
                 VALUES (?, ?, CURRENT_TIMESTAMP, ?)`,
                hash, source, chunkCount)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to mark document as processed: %w", err)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// GetProcessedDocumentCount returns the total number of processed documents tracked.
func (s *SQLiteGraphStore) GetProcessedDocumentCount(ctx context.Context) (int64, error) <span class="cov0" title="0">{
        var count int64
        err := s.db.QueryRowContext(ctx,
                "SELECT COUNT(*) FROM processed_documents").Scan(&amp;count)
        if err != nil </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("failed to get processed document count: %w", err)
        }</span>
        <span class="cov0" title="0">return count, nil</span>
}

// ClearProcessedDocuments removes all document tracking records without affecting the knowledge graph.
func (s *SQLiteGraphStore) ClearProcessedDocuments(ctx context.Context) error <span class="cov0" title="0">{
        _, err := s.db.ExecContext(ctx, "DELETE FROM processed_documents")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to clear processed documents: %w", err)
        }</span>
        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file23" style="display: none">package store

import (
        "context"
        "math"
)

// SearchResult represents a vector search result with similarity score.
type SearchResult struct {
        ID    string  // Node ID
        Score float64 // Cosine similarity score (0-1, higher is more similar)
}

// VectorStore defines the interface for vector storage and similarity search.
type VectorStore interface {
        // Add adds or updates a vector for the given ID.
        Add(ctx context.Context, id string, embedding []float32) error

        // Search finds the most similar vectors to the query.
        // Returns up to topK results sorted by similarity score (descending).
        Search(ctx context.Context, query []float32, topK int) ([]SearchResult, error)

        // Delete removes a vector from the store.
        Delete(ctx context.Context, id string) error
}

// CosineSimilarity computes the cosine similarity between two vectors.
// Returns a value between -1 and 1, where 1 means identical direction,
// 0 means orthogonal, and -1 means opposite direction.
// For normalized vectors (embeddings), the result is typically between 0 and 1.
func CosineSimilarity(a, b []float32) float64 <span class="cov8" title="1">{
        if len(a) != len(b) </span><span class="cov8" title="1">{
                return 0.0
        }</span>

        <span class="cov8" title="1">if len(a) == 0 </span><span class="cov8" title="1">{
                return 0.0
        }</span>

        <span class="cov8" title="1">var dotProduct, normA, normB float64

        for i := 0; i &lt; len(a); i++ </span><span class="cov8" title="1">{
                dotProduct += float64(a[i]) * float64(b[i])
                normA += float64(a[i]) * float64(a[i])
                normB += float64(b[i]) * float64(b[i])
        }</span>

        <span class="cov8" title="1">if normA == 0 || normB == 0 </span><span class="cov8" title="1">{
                return 0.0
        }</span>

        <span class="cov8" title="1">return dotProduct / (math.Sqrt(normA) * math.Sqrt(normB))</span>
}
</pre>
		
		<pre class="file" id="file24" style="display: none">package trace

import (
        "context"
        "encoding/json"
        "fmt"
        "os"
        "path/filepath"
        "sort"
        "sync"
)

// NoopExporter is used when filePath is empty - silently discards traces
type NoopExporter struct{}

// Export does nothing for noop exporter
func (n *NoopExporter) Export(ctx context.Context, record *TraceRecord) error <span class="cov8" title="1">{
        return nil
}</span>

// Close does nothing for noop exporter
func (n *NoopExporter) Close() error <span class="cov8" title="1">{
        return nil
}</span>

// FileExporter exports traces to a JSON Lines file with automatic rotation.
type FileExporter struct {
        filePath        string
        maxSizeBytes    int64
        maxRotatedFiles int
        file            *os.File
        encoder         *json.Encoder
        mu              sync.Mutex
        closed          bool
}

// WithMaxSize sets the maximum file size before rotation (default: 10MB).
func WithMaxSize(bytes int64) FileExporterOption <span class="cov8" title="1">{
        return func(iface interface{}) </span><span class="cov8" title="1">{
                if fe, ok := iface.(*FileExporter); ok </span><span class="cov8" title="1">{
                        fe.maxSizeBytes = bytes
                }</span>
        }
}

// WithMaxRotatedFiles sets how many rotated files to keep (default: 5).
func WithMaxRotatedFiles(count int) FileExporterOption <span class="cov8" title="1">{
        return func(iface interface{}) </span><span class="cov8" title="1">{
                if fe, ok := iface.(*FileExporter); ok </span><span class="cov8" title="1">{
                        fe.maxRotatedFiles = count
                }</span>
        }
}

// NewFileExporter creates a file-based trace exporter.
// If filePath is empty, returns a no-op exporter that silently discards traces.
// The file is opened immediately and rotation is checked on each Export.
func NewFileExporter(filePath string, opts ...FileExporterOption) (Exporter, error) <span class="cov8" title="1">{
        // Return noop exporter if no path specified
        if filePath == "" </span><span class="cov8" title="1">{
                return &amp;NoopExporter{}, nil
        }</span>

        <span class="cov8" title="1">fe := &amp;FileExporter{
                filePath:        filePath,
                maxSizeBytes:    10 * 1024 * 1024, // 10MB default
                maxRotatedFiles: 5,
        }

        // Apply options
        for _, opt := range opts </span><span class="cov8" title="1">{
                opt(fe)
        }</span>

        // Create parent directory if needed
        <span class="cov8" title="1">dir := filepath.Dir(filePath)
        if err := os.MkdirAll(dir, 0755); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("create trace directory: %w", err)
        }</span>

        // Open file for append
        <span class="cov8" title="1">file, err := os.OpenFile(filePath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("open trace file: %w", err)
        }</span>

        <span class="cov8" title="1">fe.file = file
        fe.encoder = json.NewEncoder(file)

        return fe, nil</span>
}

// Export writes a trace record as a JSON Lines entry.
// Checks for rotation after write.
func (fe *FileExporter) Export(ctx context.Context, record *TraceRecord) error <span class="cov8" title="1">{
        fe.mu.Lock()
        defer fe.mu.Unlock()

        if fe.closed </span><span class="cov0" title="0">{
                return fmt.Errorf("exporter closed")
        }</span>

        // Write JSON line
        <span class="cov8" title="1">if err := fe.encoder.Encode(record); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("encode trace record: %w", err)
        }</span>

        // Check if rotation needed
        <span class="cov8" title="1">if err := fe.rotateIfNeeded(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("rotate trace file: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// Close flushes and closes the trace file.
func (fe *FileExporter) Close() error <span class="cov8" title="1">{
        fe.mu.Lock()
        defer fe.mu.Unlock()

        if fe.closed </span><span class="cov8" title="1">{
                return nil
        }</span>

        <span class="cov8" title="1">fe.closed = true

        if fe.file != nil </span><span class="cov8" title="1">{
                if err := fe.file.Sync(); err != nil </span><span class="cov0" title="0">{
                        fe.file.Close()
                        return fmt.Errorf("sync trace file: %w", err)
                }</span>
                <span class="cov8" title="1">return fe.file.Close()</span>
        }

        <span class="cov0" title="0">return nil</span>
}

// rotateIfNeeded checks file size and rotates if threshold exceeded.
// Must be called with lock held.
func (fe *FileExporter) rotateIfNeeded() error <span class="cov8" title="1">{
        info, err := fe.file.Stat()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("stat trace file: %w", err)
        }</span>

        <span class="cov8" title="1">if info.Size() &lt; fe.maxSizeBytes </span><span class="cov8" title="1">{
                return nil // No rotation needed
        }</span>

        // Close current file
        <span class="cov8" title="1">if err := fe.file.Close(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("close trace file for rotation: %w", err)
        }</span>

        // Rotate: move current file to .1, shift existing rotated files
        <span class="cov8" title="1">if err := fe.rotateFiles(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("rotate files: %w", err)
        }</span>

        // Open new file
        <span class="cov8" title="1">file, err := os.OpenFile(fe.filePath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("open new trace file after rotation: %w", err)
        }</span>

        <span class="cov8" title="1">fe.file = file
        fe.encoder = json.NewEncoder(file)

        return nil</span>
}

// rotateFiles shifts existing rotated files and creates new rotation.
// Must be called with lock held.
func (fe *FileExporter) rotateFiles() error <span class="cov8" title="1">{
        // Delete oldest rotated file if at limit
        oldestPath := fmt.Sprintf("%s.%d", fe.filePath, fe.maxRotatedFiles)
        if _, err := os.Stat(oldestPath); err == nil </span><span class="cov0" title="0">{
                if err := os.Remove(oldestPath); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("remove oldest rotated file: %w", err)
                }</span>
        }

        // Shift existing rotated files: .N-1 -&gt; .N
        <span class="cov8" title="1">for i := fe.maxRotatedFiles - 1; i &gt;= 1; i-- </span><span class="cov8" title="1">{
                oldPath := fmt.Sprintf("%s.%d", fe.filePath, i)
                newPath := fmt.Sprintf("%s.%d", fe.filePath, i+1)

                if _, err := os.Stat(oldPath); err == nil </span><span class="cov8" title="1">{
                        if err := os.Rename(oldPath, newPath); err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("shift rotated file %s -&gt; %s: %w", oldPath, newPath, err)
                        }</span>
                }
        }

        // Move current file to .1
        <span class="cov8" title="1">rotatedPath := fmt.Sprintf("%s.%d", fe.filePath, 1)
        if err := os.Rename(fe.filePath, rotatedPath); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("rotate current file to .1: %w", err)
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// listRotatedFiles returns paths of all rotated files, sorted by number.
func (fe *FileExporter) listRotatedFiles() ([]string, error) <span class="cov0" title="0">{
        dir := filepath.Dir(fe.filePath)
        base := filepath.Base(fe.filePath)

        entries, err := os.ReadDir(dir)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("read trace directory: %w", err)
        }</span>

        <span class="cov0" title="0">var rotatedFiles []string
        for _, entry := range entries </span><span class="cov0" title="0">{
                if entry.IsDir() </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Match pattern: base.1, base.2, etc.
                <span class="cov0" title="0">name := entry.Name()
                if len(name) &gt; len(base)+2 &amp;&amp; name[:len(base)+1] == base+"." </span><span class="cov0" title="0">{
                        rotatedFiles = append(rotatedFiles, filepath.Join(dir, name))
                }</span>
        }

        <span class="cov0" title="0">sort.Strings(rotatedFiles)
        return rotatedFiles, nil</span>
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
